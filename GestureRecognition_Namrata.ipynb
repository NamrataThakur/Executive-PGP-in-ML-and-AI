{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fg19nZpzrcxw"
      },
      "source": [
        "# Gesture Recognition\n",
        "In this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xilwJ7lRrcx1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import datetime\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoR1KKxtrcx3"
      },
      "source": [
        "We set the random seed so that the results don't vary drastically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQYgANwxrcx4"
      },
      "outputs": [],
      "source": [
        "np.random.seed(30)\n",
        "import random as rn\n",
        "rn.seed(30)\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9yIELnIrcx5"
      },
      "outputs": [],
      "source": [
        "from skimage.transform import rescale,resize\n",
        "from skimage import io\n",
        "import os\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout,LSTM\n",
        "from keras.layers.convolutional import Conv3D, MaxPooling3D\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras import optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_y2422eWrcx5"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Flatten,Dense,TimeDistributed,GRU,Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.vgg16 import VGG16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rs3rFRqXrcx6"
      },
      "source": [
        "Load the data path and set the batch size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKNmb_Rlrcx7"
      },
      "outputs": [],
      "source": [
        "# train_doc = np.random.permutation(open('/notebooks/storage/Final_data/Collated_training/train.csv').readlines())\n",
        "# val_doc = np.random.permutation(open('/notebooks/storage/Final_data/Collated_training/val.csv').readlines())\n",
        "\n",
        "train_doc = np.random.permutation(open('Project_data/train.csv').readlines())\n",
        "val_doc = np.random.permutation(open('Project_data/val.csv').readlines())\n",
        "batch_size =  10  #experiment with the batch size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCwWxJeYrcx8",
        "outputId": "3ec445ff-f5db-44e8-f320-348d13e6d90a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(663,)\n",
            "(100,)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array(['WIN_20180926_16_54_08_Pro_Right_Swipe_new;Right_Swipe_new;1\\n',\n",
              "       'WIN_20180925_18_02_58_Pro_Thumbs_Down_new;Thumbs_Down_new;3\\n',\n",
              "       'WIN_20180925_17_33_08_Pro_Left_Swipe_new;Left_Swipe_new;0\\n',\n",
              "       'WIN_20180925_17_51_17_Pro_Thumbs_Up_new;Thumbs_Up_new;4\\n',\n",
              "       'WIN_20180926_17_17_35_Pro_Left_Swipe_new;Left_Swipe_new;0\\n'],\n",
              "      dtype='<U88')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(train_doc.shape)\n",
        "print(val_doc.shape)\n",
        "train_doc[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "g9Av-A1zrcx9",
        "outputId": "323b3b77-4025-435d-95ac-1fc3c7dd3dae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(120, 160, 3)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x2050b17bee0>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# import a sample image and visualise\n",
        "from glob import glob\n",
        "source_path = './Project_data/train'\n",
        "path = os.path.join(source_path,train_doc[1].split(';')[0],'*')\n",
        "vid_img_path = glob(path)\n",
        "print(io.imread(vid_img_path[6]).shape)\n",
        "f, axes = plt.subplots(1,2)\n",
        "axes[0].imshow(io.imread(vid_img_path[1]))\n",
        "axes[1].imshow(resize(io.imread(vid_img_path[1]), (180,180)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OW9fB4jFrcx-"
      },
      "source": [
        "## Generator\n",
        "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "810xIUGBrcx_"
      },
      "source": [
        "1) Batch size\n",
        "2) num of frames\n",
        "3) crop and resize\n",
        "4) normalisation\n",
        "5) handles extra samples (yield one extra batch with lessed samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfKSsRZYrcx_"
      },
      "outputs": [],
      "source": [
        "def generator(source_path, folder_list, batch_size, exp_img_shape):\n",
        "    #print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
        "    img_idx = np.arange(0,30,2)\n",
        "    #print(img_idx) #create a list of image numbers you want to use for a particular video\n",
        "    x = len(img_idx)\n",
        "    y,z = exp_img_shape # desired image shape\n",
        "    while True:\n",
        "        t = np.random.permutation(folder_list)\n",
        "        num_batches = len(t)//batch_size # calculate the number of batches\n",
        "        \n",
        "        # Take each batch of video for further processing \n",
        "        for batch in range(num_batches): # we iterate over the number of batches\n",
        "            \n",
        "            batch_data = np.zeros((batch_size,x,y,z,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
        "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
        "           \n",
        "        # treat the frames in each video\n",
        "            for folder in range(batch_size): # iterate over the batch_size\n",
        "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
        "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
        "                    image = io.imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
        "                    \n",
        "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
        "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
        "                    image = resize(image, (y,z))\n",
        "                    \n",
        "                    batch_data[folder,idx,:,:,0] = image[:,:,0]/255 #normalise and feed in the image\n",
        "                    batch_data[folder,idx,:,:,1] = image[:,:,1]/255 #normalise and feed in the image\n",
        "                    batch_data[folder,idx,:,:,2] = image[:,:,2]/255 #normalise and feed in the image\n",
        "                    \n",
        "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
        "            print(\"-----Batch{0}: size: {1}\".format(batch,batch_size))\n",
        "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
        "\n",
        "\n",
        "        if ((len(t) % batch_size) != 0) and (batch == num_batches-1):\n",
        "            bs = len(t) - (num_batches*batch_size)\n",
        "            batch_data = np.zeros((bs,x,y,z,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
        "            batch_labels = np.zeros((bs,5)) # batch_labels is the one hot representation of the output\n",
        "        # treat the frames in each video\n",
        "            for folder in range(bs): # iterate over the batch_size\n",
        "                imgs = os.listdir(source_path+'/'+ t[folder + num_batches*batch_size].split(';')[0]) # read all the images in the folder\n",
        "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
        "                    image = io.imread(source_path+'/'+ t[folder + (num_batches*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
        "                    \n",
        "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
        "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
        "                    image = resize(image, (y,z))\n",
        "                    \n",
        "                    batch_data[folder,idx,:,:,0] = image[:,:,0]/255 #normalise and feed in the image\n",
        "                    batch_data[folder,idx,:,:,1] = image[:,:,1]/255 #normalise and feed in the image\n",
        "                    batch_data[folder,idx,:,:,2] = image[:,:,2]/255 #normalise and feed in the image\n",
        "                    \n",
        "                batch_labels[folder, int(t[folder + (num_batches*batch_size)].strip().split(';')[2])] = 1\n",
        "            print(\"-----last Batch size: {0}\".format(bs))\n",
        "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
        "\n",
        "            \n",
        "        # write the code for the remaining data points which are left after full batches\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3wXWr4lrcyB"
      },
      "source": [
        "Note here that a video is represented above in the generator as (number of images, height, width, number of channels). Take this into consideration while creating the model architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_Ia6D7HrcyB",
        "outputId": "b50a3484-0209-4102-f369-84597d5e50b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# training sequences = 663\n",
            "# validation sequences = 100\n",
            "# epochs = 16\n"
          ]
        }
      ],
      "source": [
        "curr_dt_time = datetime.datetime.now()\n",
        "# train_path = '/notebooks/storage/Final_data/Collated_training/train'\n",
        "# val_path = '/notebooks/storage/Final_data/Collated_training/val'\n",
        "\n",
        "train_path = './Project_data/train'\n",
        "val_path = './Project_data/val'\n",
        "num_train_sequences = len(train_doc)\n",
        "print('# training sequences =', num_train_sequences)\n",
        "num_val_sequences = len(val_doc)\n",
        "print('# validation sequences =', num_val_sequences)\n",
        "num_epochs = 16 # choose the number of epochs\n",
        "print ('# epochs =', num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56xZXugWrcyB"
      },
      "outputs": [],
      "source": [
        "# function to set variables such as steps_per_epoch etc.\n",
        "def sample_set(batch_size, set_size, exp_img_shape):\n",
        "    if set_size!= len(train_doc):\n",
        "        data_set = np.random.permutation(train_doc)[:set_size]\n",
        "    else:\n",
        "        data_set = train_doc.copy()\n",
        "    train_generator = generator(train_path, data_set, batch_size, exp_img_shape)\n",
        "    val_generator = generator(val_path, val_doc, batch_size, exp_img_shape)\n",
        "    num_train_sequences = len(data_set)\n",
        "    if (num_train_sequences%batch_size) == 0:\n",
        "        steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "    else:\n",
        "        steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "    if (num_val_sequences%batch_size) == 0:\n",
        "        validation_steps = int(num_val_sequences/batch_size)\n",
        "    else:\n",
        "        validation_steps = (num_val_sequences//batch_size) + 1\n",
        "    print('num_train_sequences:{0}, num_val_sequences:{1}, steps_per_epoch:{2}, validation_steps:{3}'.format(num_train_sequences,num_val_sequences,steps_per_epoch, validation_steps))\n",
        "    return (train_generator,val_generator,steps_per_epoch,validation_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9EAXnhqrcyC"
      },
      "outputs": [],
      "source": [
        "# save the weights of the model for each epoch\n",
        "# provide option to select desired model evalutaion parameter\n",
        "def save_model(eval_param):\n",
        "    curr_dt_time = datetime.datetime.now()\n",
        "    model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "    \n",
        "    if not os.path.exists(model_name):\n",
        "        os.mkdir(model_name)\n",
        "        \n",
        "    filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{'+eval_param+':.5f}-{val_loss:.5f}-{val_'+eval_param+':.5f}.h5'\n",
        "\n",
        "    checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto')\n",
        "\n",
        "    LR =   ReduceLROnPlateau(monitor = 'val_loss', factor=0.1, patience = 5) # write the REducelronplateau code here\n",
        "    callbacks_list = [checkpoint, LR]\n",
        "    return(callbacks_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ma2D2G5rcyC"
      },
      "source": [
        "## Model\n",
        "Here you make the model using different functionalities that Keras provides. Remember to use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. You would want to use `TimeDistributed` while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam.\n",
        "\n",
        "- Types of models to experiment with\n",
        "    - CNN 3D model\n",
        "    - Transfer Learning: CNN+GRU\n",
        "    - Transfer Learning: CNN+LSTM\n",
        "    - customized CNN+ GRU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwORkoz4rcyD"
      },
      "source": [
        "### Conv3D models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63tArE1frcyD"
      },
      "source": [
        "##### Model 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ygh9ODp_rcyD"
      },
      "outputs": [],
      "source": [
        "# Conv3D model\n",
        "def cnn_1(inp_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Conv3D(32, kernel_size = (2,2,2), strides =1, activation = 'relu', input_shape = inp_shape))\n",
        "    model.add(Conv3D(64, kernel_size = (2,2,2), strides =1,activation = 'relu', padding = 'same'))\n",
        "\n",
        "    model.add(Conv3D(64, kernel_size = (2,2,2), strides =1,activation = 'relu', padding = 'same'))\n",
        "    model.add(MaxPooling3D(pool_size = (2,2,2)))\n",
        "\n",
        "    model.add(Conv3D(128, kernel_size = (2,2,2), strides =1, activation = 'relu', padding = 'same'))\n",
        "    model.add(MaxPooling3D(pool_size = (2,2,2)))\n",
        "\n",
        "    model.add(Conv3D(128, kernel_size = (2,2,2), strides =1, activation = 'relu', padding = 'same'))\n",
        "    model.add(MaxPooling3D(pool_size = (2,2,2)))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation = 'relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Dense(5, activation = 'softmax'))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZxjKtObrcyD"
      },
      "source": [
        "Now that you have written the model, the next step is to `compile` the model. When you print the `summary` of the model, you'll see the total number of parameters you have to train."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpX4q6MurcyE",
        "outputId": "660a7fcb-ca6f-4f7c-d577-dca83195c0bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d (Conv3D)             (None, 14, 179, 179, 32)  800       \n",
            "                                                                 \n",
            " conv3d_1 (Conv3D)           (None, 14, 179, 179, 64)  16448     \n",
            "                                                                 \n",
            " conv3d_2 (Conv3D)           (None, 14, 179, 179, 64)  32832     \n",
            "                                                                 \n",
            " max_pooling3d (MaxPooling3D  (None, 7, 89, 89, 64)    0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv3d_3 (Conv3D)           (None, 7, 89, 89, 128)    65664     \n",
            "                                                                 \n",
            " max_pooling3d_1 (MaxPooling  (None, 3, 44, 44, 128)   0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " conv3d_4 (Conv3D)           (None, 3, 44, 44, 128)    131200    \n",
            "                                                                 \n",
            " max_pooling3d_2 (MaxPooling  (None, 1, 22, 22, 128)   0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1, 22, 22, 128)    0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 61952)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                3964992   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,212,261\n",
            "Trainable params: 4,212,261\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# use Adam with learning rate = 0.001\n",
        "optimiser = 'Adam' #write your optimizer\n",
        "model = cnn_1((15,180,180,3))\n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "print (model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0UxBS9arcyE"
      },
      "source": [
        "Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_X2gxPqnrcyE",
        "outputId": "f388aae6-a969-4b6f-a32c-9eaaa3811ca9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_train_sequences:100, num_val_sequences:100, steps_per_epoch:5, validation_steps:5\n"
          ]
        }
      ],
      "source": [
        "# ABLATION\n",
        "train_generator,val_generator,steps_per_epoch,validation_steps = sample_set(20,100,(180,180))\n",
        "callbacks_list = save_model('categorical_accuracy')\n",
        "num_epochs =16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVZn8d3QrcyF"
      },
      "source": [
        "The `steps_per_epoch` and `validation_steps` are used by `fit_generator` to decide the number of next() calls it need to make."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woL1gpZrrcyF"
      },
      "source": [
        "Let us now fit the model. This will start training the model and with the help of the checkpoints, you'll be able to save the model at the end of each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "cp_EME7LrcyF",
        "outputId": "482476fd-387b-4989-a0fc-b57c1ec3035b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----Batch0: size: 20\n",
            "Epoch 1/16\n",
            "-----Batch1: size: 20\n",
            "1/5 [=====>........................] - ETA: 13:05 - loss: 1.6247 - categorical_accuracy: 0.0500-----Batch2: size: 20\n",
            "2/5 [===========>..................] - ETA: 9:24 - loss: 1.6407 - categorical_accuracy: 0.1250 -----Batch3: size: 20\n",
            "3/5 [=================>............] - ETA: 6:28 - loss: 1.6725 - categorical_accuracy: 0.1333-----Batch4: size: 20\n",
            "4/5 [=======================>......] - ETA: 3:08 - loss: 1.6702 - categorical_accuracy: 0.1500-----Batch0: size: 20\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.6547 - categorical_accuracy: 0.1800  -----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "\n",
            "Epoch 00001: saving model to model_init_2021-12-2713_35_44.155618\\model-00001-1.65472-0.18000-1.60342-0.18000.h5\n",
            "5/5 [==============================] - 1031s 209s/step - loss: 1.6547 - categorical_accuracy: 0.1800 - val_loss: 1.6034 - val_categorical_accuracy: 0.1800 - lr: 0.0010\n",
            "Epoch 2/16\n",
            "-----Batch1: size: 20\n",
            "1/5 [=====>........................] - ETA: 10:26 - loss: 1.5948 - categorical_accuracy: 0.3000-----Batch2: size: 20\n",
            "2/5 [===========>..................] - ETA: 7:48 - loss: 1.6061 - categorical_accuracy: 0.2250 -----Batch3: size: 20\n",
            "3/5 [=================>............] - ETA: 5:13 - loss: 1.5883 - categorical_accuracy: 0.2333-----Batch4: size: 20\n",
            "4/5 [=======================>......] - ETA: 2:31 - loss: 1.6129 - categorical_accuracy: 0.1875-----Batch0: size: 20\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.6046 - categorical_accuracy: 0.1900  -----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "\n",
            "Epoch 00002: saving model to model_init_2021-12-2713_35_44.155618\\model-00002-1.60462-0.19000-1.59961-0.16000.h5\n",
            "5/5 [==============================] - 827s 168s/step - loss: 1.6046 - categorical_accuracy: 0.1900 - val_loss: 1.5996 - val_categorical_accuracy: 0.1600 - lr: 0.0010\n",
            "Epoch 3/16\n",
            "-----Batch1: size: 20\n",
            "1/5 [=====>........................] - ETA: 9:41 - loss: 1.5595 - categorical_accuracy: 0.3500-----Batch2: size: 20\n",
            "2/5 [===========>..................] - ETA: 7:57 - loss: 1.5729 - categorical_accuracy: 0.3000-----Batch3: size: 20\n",
            "3/5 [=================>............] - ETA: 5:23 - loss: 1.5736 - categorical_accuracy: 0.3333-----Batch4: size: 20\n",
            "4/5 [=======================>......] - ETA: 2:35 - loss: 1.5713 - categorical_accuracy: 0.2875-----Batch0: size: 20\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.5906 - categorical_accuracy: 0.2600  -----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "\n",
            "Epoch 00003: saving model to model_init_2021-12-2713_35_44.155618\\model-00003-1.59058-0.26000-1.57876-0.23000.h5\n",
            "5/5 [==============================] - 817s 168s/step - loss: 1.5906 - categorical_accuracy: 0.2600 - val_loss: 1.5788 - val_categorical_accuracy: 0.2300 - lr: 0.0010\n",
            "Epoch 4/16\n",
            "-----Batch1: size: 20\n",
            "1/5 [=====>........................] - ETA: 11:47 - loss: 1.5036 - categorical_accuracy: 0.3000-----Batch2: size: 20\n",
            "2/5 [===========>..................] - ETA: 13:44 - loss: 1.5489 - categorical_accuracy: 0.3000-----Batch3: size: 20\n",
            "3/5 [=================>............] - ETA: 9:10 - loss: 1.5481 - categorical_accuracy: 0.2000 -----Batch4: size: 20\n",
            "4/5 [=======================>......] - ETA: 4:42 - loss: 1.5375 - categorical_accuracy: 0.2250-----Batch0: size: 20\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.5510 - categorical_accuracy: 0.2000  -----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "\n",
            "Epoch 00004: saving model to model_init_2021-12-2713_35_44.155618\\model-00004-1.55099-0.20000-1.54839-0.21000.h5\n",
            "5/5 [==============================] - 1443s 317s/step - loss: 1.5510 - categorical_accuracy: 0.2000 - val_loss: 1.5484 - val_categorical_accuracy: 0.2100 - lr: 0.0010\n",
            "Epoch 5/16\n",
            "-----Batch1: size: 20\n",
            "1/5 [=====>........................] - ETA: 18:31 - loss: 1.3812 - categorical_accuracy: 0.4000-----Batch2: size: 20\n",
            "2/5 [===========>..................] - ETA: 14:28 - loss: 1.3835 - categorical_accuracy: 0.4500-----Batch3: size: 20\n",
            "3/5 [=================>............] - ETA: 10:04 - loss: 1.3855 - categorical_accuracy: 0.3500-----Batch4: size: 20\n",
            "4/5 [=======================>......] - ETA: 5:04 - loss: 1.4426 - categorical_accuracy: 0.3125 -----Batch0: size: 20\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.4840 - categorical_accuracy: 0.2900  -----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "\n",
            "Epoch 00005: saving model to model_init_2021-12-2713_35_44.155618\\model-00005-1.48400-0.29000-1.45396-0.28000.h5\n",
            "5/5 [==============================] - 1581s 326s/step - loss: 1.4840 - categorical_accuracy: 0.2900 - val_loss: 1.4540 - val_categorical_accuracy: 0.2800 - lr: 0.0010\n",
            "Epoch 6/16\n",
            "-----Batch1: size: 20\n",
            "1/5 [=====>........................] - ETA: 18:43 - loss: 1.2110 - categorical_accuracy: 0.6000-----Batch2: size: 20\n",
            "2/5 [===========>..................] - ETA: 14:57 - loss: 1.2639 - categorical_accuracy: 0.5500-----Batch3: size: 20\n",
            "3/5 [=================>............] - ETA: 10:06 - loss: 1.3353 - categorical_accuracy: 0.4333-----Batch4: size: 20\n",
            "4/5 [=======================>......] - ETA: 4:58 - loss: 1.3409 - categorical_accuracy: 0.3750 -----Batch0: size: 20\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.3260 - categorical_accuracy: 0.3800  -----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "\n",
            "Epoch 00006: saving model to model_init_2021-12-2713_35_44.155618\\model-00006-1.32598-0.38000-1.38522-0.29000.h5\n",
            "5/5 [==============================] - 1597s 329s/step - loss: 1.3260 - categorical_accuracy: 0.3800 - val_loss: 1.3852 - val_categorical_accuracy: 0.2900 - lr: 0.0010\n",
            "Epoch 7/16\n",
            "-----Batch1: size: 20\n",
            "1/5 [=====>........................] - ETA: 21:07 - loss: 1.0998 - categorical_accuracy: 0.4500-----Batch2: size: 20\n",
            "2/5 [===========>..................] - ETA: 15:15 - loss: 1.2096 - categorical_accuracy: 0.4000-----Batch3: size: 20\n",
            "3/5 [=================>............] - ETA: 9:57 - loss: 1.1688 - categorical_accuracy: 0.4333 -----Batch4: size: 20\n",
            "4/5 [=======================>......] - ETA: 4:54 - loss: 1.1775 - categorical_accuracy: 0.4125-----Batch0: size: 20\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.2049 - categorical_accuracy: 0.4100  -----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "\n",
            "Epoch 00007: saving model to model_init_2021-12-2713_35_44.155618\\model-00007-1.20486-0.41000-1.26537-0.39000.h5\n",
            "5/5 [==============================] - 1971s 413s/step - loss: 1.2049 - categorical_accuracy: 0.4100 - val_loss: 1.2654 - val_categorical_accuracy: 0.3900 - lr: 0.0010\n",
            "Epoch 8/16\n",
            "-----Batch1: size: 20\n",
            "1/5 [=====>........................] - ETA: 10:50 - loss: 1.1332 - categorical_accuracy: 0.5500-----Batch2: size: 20\n",
            "2/5 [===========>..................] - ETA: 6:57 - loss: 1.0908 - categorical_accuracy: 0.6000 -----Batch3: size: 20\n",
            "3/5 [=================>............] - ETA: 4:32 - loss: 1.0994 - categorical_accuracy: 0.5833-----Batch4: size: 20\n",
            "4/5 [=======================>......] - ETA: 2:15 - loss: 1.0614 - categorical_accuracy: 0.6375-----Batch0: size: 20\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0073 - categorical_accuracy: 0.6500  -----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "\n",
            "Epoch 00008: saving model to model_init_2021-12-2713_35_44.155618\\model-00008-1.00734-0.65000-1.59592-0.38000.h5\n",
            "5/5 [==============================] - 771s 152s/step - loss: 1.0073 - categorical_accuracy: 0.6500 - val_loss: 1.5959 - val_categorical_accuracy: 0.3800 - lr: 0.0010\n",
            "Epoch 9/16\n",
            "-----Batch1: size: 20\n",
            "1/5 [=====>........................] - ETA: 9:53 - loss: 0.8228 - categorical_accuracy: 0.5500-----Batch2: size: 20\n",
            "2/5 [===========>..................] - ETA: 7:14 - loss: 0.6301 - categorical_accuracy: 0.7250-----Batch3: size: 20\n",
            "3/5 [=================>............] - ETA: 5:07 - loss: 0.6182 - categorical_accuracy: 0.7500-----Batch4: size: 20\n",
            "4/5 [=======================>......] - ETA: 2:36 - loss: 0.6506 - categorical_accuracy: 0.7375-----Batch0: size: 20\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7259 - categorical_accuracy: 0.7200  -----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "\n",
            "Epoch 00009: saving model to model_init_2021-12-2713_35_44.155618\\model-00009-0.72586-0.72000-1.46711-0.58000.h5\n",
            "5/5 [==============================] - 837s 172s/step - loss: 0.7259 - categorical_accuracy: 0.7200 - val_loss: 1.4671 - val_categorical_accuracy: 0.5800 - lr: 0.0010\n",
            "Epoch 10/16\n",
            "-----Batch1: size: 20\n",
            "1/5 [=====>........................] - ETA: 10:15 - loss: 0.5165 - categorical_accuracy: 0.8500-----Batch2: size: 20\n",
            "2/5 [===========>..................] - ETA: 8:20 - loss: 0.4879 - categorical_accuracy: 0.8750 -----Batch3: size: 20\n",
            "3/5 [=================>............] - ETA: 5:34 - loss: 0.4805 - categorical_accuracy: 0.8500-----Batch4: size: 20\n",
            "4/5 [=======================>......] - ETA: 2:43 - loss: 0.5100 - categorical_accuracy: 0.8625-----Batch0: size: 20\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.5139 - categorical_accuracy: 0.8500  -----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "\n",
            "Epoch 00010: saving model to model_init_2021-12-2713_35_44.155618\\model-00010-0.51388-0.85000-1.56720-0.57000.h5\n",
            "5/5 [==============================] - 879s 181s/step - loss: 0.5139 - categorical_accuracy: 0.8500 - val_loss: 1.5672 - val_categorical_accuracy: 0.5700 - lr: 0.0010\n",
            "Epoch 11/16\n",
            "-----Batch1: size: 20\n",
            "1/5 [=====>........................] - ETA: 10:07 - loss: 0.7497 - categorical_accuracy: 0.5000-----Batch2: size: 20\n",
            "2/5 [===========>..................] - ETA: 7:34 - loss: 0.5424 - categorical_accuracy: 0.7250 -----Batch3: size: 20\n",
            "3/5 [=================>............] - ETA: 5:15 - loss: 0.4967 - categorical_accuracy: 0.7667-----Batch4: size: 20\n",
            "4/5 [=======================>......] - ETA: 2:38 - loss: 0.4843 - categorical_accuracy: 0.7875-----Batch0: size: 20\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4612 - categorical_accuracy: 0.8100  -----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "\n",
            "Epoch 00011: saving model to model_init_2021-12-2713_35_44.155618\\model-00011-0.46116-0.81000-1.54151-0.64000.h5\n",
            "5/5 [==============================] - 850s 175s/step - loss: 0.4612 - categorical_accuracy: 0.8100 - val_loss: 1.5415 - val_categorical_accuracy: 0.6400 - lr: 0.0010\n",
            "Epoch 12/16\n",
            "-----Batch1: size: 20\n",
            "1/5 [=====>........................] - ETA: 9:55 - loss: 0.5944 - categorical_accuracy: 0.8500-----Batch2: size: 20\n",
            "2/5 [===========>..................] - ETA: 8:01 - loss: 0.4987 - categorical_accuracy: 0.8750-----Batch3: size: 20\n",
            "3/5 [=================>............] - ETA: 5:30 - loss: 0.3779 - categorical_accuracy: 0.9167-----Batch4: size: 20\n",
            "4/5 [=======================>......] - ETA: 2:43 - loss: 0.3648 - categorical_accuracy: 0.9000-----Batch0: size: 20\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4083 - categorical_accuracy: 0.8700  -----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "\n",
            "Epoch 00012: saving model to model_init_2021-12-2713_35_44.155618\\model-00012-0.40825-0.87000-2.03182-0.61000.h5\n",
            "5/5 [==============================] - 858s 177s/step - loss: 0.4083 - categorical_accuracy: 0.8700 - val_loss: 2.0318 - val_categorical_accuracy: 0.6100 - lr: 0.0010\n",
            "Epoch 13/16\n",
            "-----Batch1: size: 20\n",
            "1/5 [=====>........................] - ETA: 9:38 - loss: 0.3392 - categorical_accuracy: 0.9000-----Batch2: size: 20\n",
            "2/5 [===========>..................] - ETA: 7:48 - loss: 0.2847 - categorical_accuracy: 0.9250-----Batch3: size: 20\n",
            "3/5 [=================>............] - ETA: 4:52 - loss: 0.2568 - categorical_accuracy: 0.9333-----Batch4: size: 20\n",
            "4/5 [=======================>......] - ETA: 2:26 - loss: 0.2465 - categorical_accuracy: 0.9375-----Batch0: size: 20\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2427 - categorical_accuracy: 0.9400  -----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "\n",
            "Epoch 00013: saving model to model_init_2021-12-2713_35_44.155618\\model-00013-0.24267-0.94000-2.11676-0.64000.h5\n",
            "5/5 [==============================] - 810s 166s/step - loss: 0.2427 - categorical_accuracy: 0.9400 - val_loss: 2.1168 - val_categorical_accuracy: 0.6400 - lr: 1.0000e-04\n",
            "Epoch 14/16\n",
            "-----Batch1: size: 20\n",
            "1/5 [=====>........................] - ETA: 9:19 - loss: 0.3206 - categorical_accuracy: 0.8500-----Batch2: size: 20\n",
            "2/5 [===========>..................] - ETA: 8:20 - loss: 0.2505 - categorical_accuracy: 0.9000-----Batch3: size: 20\n",
            "3/5 [=================>............] - ETA: 5:02 - loss: 0.1984 - categorical_accuracy: 0.9333-----Batch4: size: 20\n",
            "4/5 [=======================>......] - ETA: 2:34 - loss: 0.1859 - categorical_accuracy: 0.9375-----Batch0: size: 20\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1949 - categorical_accuracy: 0.9300  -----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "\n",
            "Epoch 00014: saving model to model_init_2021-12-2713_35_44.155618\\model-00014-0.19495-0.93000-1.52109-0.69000.h5\n",
            "5/5 [==============================] - 802s 165s/step - loss: 0.1949 - categorical_accuracy: 0.9300 - val_loss: 1.5211 - val_categorical_accuracy: 0.6900 - lr: 1.0000e-04\n",
            "Epoch 15/16\n",
            "-----Batch1: size: 20\n",
            "1/5 [=====>........................] - ETA: 10:55 - loss: 0.3348 - categorical_accuracy: 0.9000-----Batch2: size: 20\n",
            "2/5 [===========>..................] - ETA: 8:08 - loss: 0.2437 - categorical_accuracy: 0.9500 -----Batch3: size: 20\n",
            "3/5 [=================>............] - ETA: 5:24 - loss: 0.1809 - categorical_accuracy: 0.9667-----Batch4: size: 20\n",
            "4/5 [=======================>......] - ETA: 2:33 - loss: 0.1994 - categorical_accuracy: 0.9375-----Batch0: size: 20\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1942 - categorical_accuracy: 0.9400  -----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "\n",
            "Epoch 00015: saving model to model_init_2021-12-2713_35_44.155618\\model-00015-0.19424-0.94000-2.23826-0.61000.h5\n",
            "5/5 [==============================] - 826s 165s/step - loss: 0.1942 - categorical_accuracy: 0.9400 - val_loss: 2.2383 - val_categorical_accuracy: 0.6100 - lr: 1.0000e-04\n",
            "Epoch 16/16\n",
            "-----Batch1: size: 20\n",
            "1/5 [=====>........................] - ETA: 9:46 - loss: 0.2789 - categorical_accuracy: 0.9000-----Batch2: size: 20\n",
            "2/5 [===========>..................] - ETA: 8:11 - loss: 0.2132 - categorical_accuracy: 0.9500-----Batch3: size: 20\n",
            "3/5 [=================>............] - ETA: 5:17 - loss: 0.1826 - categorical_accuracy: 0.9500-----Batch4: size: 20\n",
            "4/5 [=======================>......] - ETA: 2:35 - loss: 0.1683 - categorical_accuracy: 0.9625-----Batch0: size: 20\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1517 - categorical_accuracy: 0.9600  -----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "\n",
            "Epoch 00016: saving model to model_init_2021-12-2713_35_44.155618\\model-00016-0.15170-0.96000-2.03453-0.64000.h5\n",
            "5/5 [==============================] - 838s 173s/step - loss: 0.1517 - categorical_accuracy: 0.9600 - val_loss: 2.0345 - val_categorical_accuracy: 0.6400 - lr: 1.0000e-04\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x2e806e485b0>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "                    callbacks=callbacks_list, validation_data=val_generator, \n",
        "                    validation_steps=validation_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsSsbIJDrcyF"
      },
      "source": [
        "Model 1 is able to overfit on the sample dateset, hence try training the model on complete dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLAcVIb5rcyG",
        "outputId": "1fdf25cd-c334-45c4-a8b0-5022b46d811b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_train_sequences:663, num_val_sequences:100, steps_per_epoch:34, validation_steps:5\n"
          ]
        }
      ],
      "source": [
        "### Training on complete dataset\n",
        "train_generator,val_generator,steps_per_epoch,validation_steps = sample_set(20,len(train_doc),(180,180))\n",
        "callbacks_list = save_model('categorical_accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BB3jQHQvrcyG"
      },
      "outputs": [],
      "source": [
        "### Training on complete dataset\n",
        "num_epochs =16\n",
        "model = cnn_1((15,180,180,3))\n",
        "optimiser = 'Adam' #write your optimizer\n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hl3Px5OarcyG"
      },
      "outputs": [],
      "source": [
        "model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "                    callbacks=callbacks_list, validation_data=val_generator, \n",
        "                    validation_steps=validation_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zvlxhS2rcyG"
      },
      "source": [
        "- Number of trainable paraemeters = 4,212,261\n",
        "- Categorical accuracy at the end of epoch 16:  Train data: 0.97, validation data: 0.85 \n",
        "- Categorical accuracy at epoch 9: Train data: 0.88, validation data: 0.84 \n",
        "- Model with parameters obtained at the end of epoch 9 is more suitable as it has no overfitting compared to the results at the end of epoch 16 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODtTAl55rcyG"
      },
      "source": [
        "##### Let's try a slightly different image preprocessing. Crop the image with an offset of 15 pixels at every side and then resize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7xS14qCrcyH"
      },
      "outputs": [],
      "source": [
        "def generator_crop(source_path, folder_list, batch_size, exp_img_shape):\n",
        "    #print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
        "    img_idx = np.arange(0,30,2)\n",
        "    #print(img_idx) #create a list of image numbers you want to use for a particular video\n",
        "    x = len(img_idx)\n",
        "    y,z = exp_img_shape \n",
        "    while True:\n",
        "        t = np.random.permutation(folder_list)\n",
        "        num_batches = len(t)//batch_size # calculate the number of batches\n",
        "        \n",
        "        # Take each batch of video for further processing \n",
        "        for batch in range(num_batches): # we iterate over the number of batches\n",
        "            \n",
        "            batch_data = np.zeros((batch_size,x,y,z,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
        "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
        "           \n",
        "        # treat the frames in each video\n",
        "            for folder in range(batch_size): # iterate over the batch_size\n",
        "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
        "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
        "                    image = io.imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
        "                    \n",
        "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
        "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
        "                    image = image[15:image.shape[0]-15+1,15:image.shape[1]-15+1,:]\n",
        "                    image = resize(image, (y,z))\n",
        "                    \n",
        "                    batch_data[folder,idx,:,:,0] = image[:,:,0]/255 #normalise and feed in the image\n",
        "                    batch_data[folder,idx,:,:,1] = image[:,:,1]/255 #normalise and feed in the image\n",
        "                    batch_data[folder,idx,:,:,2] = image[:,:,2]/255 #normalise and feed in the image\n",
        "                    \n",
        "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
        "            print(\"-----Batch{0}: size: {1}\".format(batch,batch_size))\n",
        "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
        "\n",
        "\n",
        "        if ((len(t) % batch_size) != 0) and (batch == num_batches-1):\n",
        "            bs = len(t) - (num_batches*batch_size)\n",
        "            batch_data = np.zeros((bs,x,y,z,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
        "            batch_labels = np.zeros((bs,5)) # batch_labels is the one hot representation of the output\n",
        "        # treat the frames in each video\n",
        "            for folder in range(bs): # iterate over the batch_size\n",
        "                imgs = os.listdir(source_path+'/'+ t[folder + num_batches*batch_size].split(';')[0]) # read all the images in the folder\n",
        "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
        "                    image = io.imread(source_path+'/'+ t[folder + (num_batches*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
        "                    \n",
        "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
        "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
        "                    image = image[15:image.shape[0]-15+1,15:image.shape[1]-15+1,:]\n",
        "                    image = resize(image, (y,z))\n",
        "                    \n",
        "                    batch_data[folder,idx,:,:,0] = image[:,:,0]/255 #normalise and feed in the image\n",
        "                    batch_data[folder,idx,:,:,1] = image[:,:,1]/255 #normalise and feed in the image\n",
        "                    batch_data[folder,idx,:,:,2] = image[:,:,2]/255 #normalise and feed in the image\n",
        "                    \n",
        "                batch_labels[folder, int(t[folder + (num_batches*batch_size)].strip().split(';')[2])] = 1\n",
        "            print(\"-----last Batch size: {0}\".format(bs))\n",
        "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
        "\n",
        "            \n",
        "        # write the code for the remaining data points which are left after full batches\n",
        "\n",
        "def sample_set_crop(batch_size, set_size,exp_img_shape):\n",
        "    if set_size!= len(train_doc):\n",
        "        data_set = np.random.permutation(train_doc)[:set_size]\n",
        "    else:\n",
        "        data_set = train_doc.copy()\n",
        "    train_generator = generator_crop(train_path, data_set, batch_size,exp_img_shape)\n",
        "    val_generator = generator_crop(val_path, val_doc, batch_size,exp_img_shape)\n",
        "    num_train_sequences = len(data_set)\n",
        "    if (num_train_sequences%batch_size) == 0:\n",
        "        steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "    else:\n",
        "        steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "    if (num_val_sequences%batch_size) == 0:\n",
        "        validation_steps = int(num_val_sequences/batch_size)\n",
        "    else:\n",
        "        validation_steps = (num_val_sequences//batch_size) + 1\n",
        "    print('num_train_sequences:{0}, num_val_sequences:{1}, steps_per_epoch:{2}, validation_steps:{3}'.format(num_train_sequences,num_val_sequences,steps_per_epoch, validation_steps))\n",
        "    return (train_generator,val_generator,steps_per_epoch,validation_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFxyZEMOrcyH"
      },
      "source": [
        "#### Model 2- Only difference with model 1 is in the input image shape and the image preprocessing steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7g5CjI80rcyH",
        "outputId": "4eb15f80-2f1f-4038-81af-a3c9d083b999"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_train_sequences:100, num_val_sequences:100, steps_per_epoch:5, validation_steps:5\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d (Conv3D)             (None, 14, 129, 129, 32)  800       \n",
            "                                                                 \n",
            " conv3d_1 (Conv3D)           (None, 14, 129, 129, 64)  16448     \n",
            "                                                                 \n",
            " conv3d_2 (Conv3D)           (None, 14, 129, 129, 64)  32832     \n",
            "                                                                 \n",
            " max_pooling3d (MaxPooling3D  (None, 7, 64, 64, 64)    0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv3d_3 (Conv3D)           (None, 7, 64, 64, 128)    65664     \n",
            "                                                                 \n",
            " max_pooling3d_1 (MaxPooling  (None, 3, 32, 32, 128)   0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " conv3d_4 (Conv3D)           (None, 3, 32, 32, 128)    131200    \n",
            "                                                                 \n",
            " max_pooling3d_2 (MaxPooling  (None, 1, 16, 16, 128)   0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1, 16, 16, 128)    0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 32768)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                2097216   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,344,485\n",
            "Trainable params: 2,344,485\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# ABLATION\n",
        "train_generator,val_generator,steps_per_epoch,validation_steps = sample_set_crop(20,100,(130,130))\n",
        "callbacks_list = save_model('categorical_accuracy')\n",
        "num_epochs = 16\n",
        "optimiser = 'Adam' #write your optimizer\n",
        "model = cnn_1((15,130,130,3))\n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "print (model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M15LORDOrcyI"
      },
      "source": [
        "Model is able to overfit on the newly processed data. Let's try to train the model fully"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61NzBTLsrcyI",
        "outputId": "32a506df-71f1-4876-e441-20e7e7003520"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_train_sequences:663, num_val_sequences:100, steps_per_epoch:34, validation_steps:5\n"
          ]
        }
      ],
      "source": [
        "### Training on complete dataset\n",
        "callbacks_list = save_model('categorical_accuracy')\n",
        "train_generator,val_generator,steps_per_epoch,validation_steps = sample_set_crop(20,len(train_doc),(130,130))\n",
        "model = cnn_1((15,130,130,3))\n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "GIqiSfTkrcyI",
        "outputId": "f9052cc3-4ffe-4409-f02b-ce920b725dab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----Batch0: size: 20\n",
            "Epoch 1/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 1:21:18 - loss: 1.5872 - categorical_accuracy: 0.3500-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 1:18:46 - loss: 2.2403 - categorical_accuracy: 0.3000-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 1:17:30 - loss: 2.0370 - categorical_accuracy: 0.3333-----Batch4: size: 20\n",
            " 4/34 [==>...........................] - ETA: 1:13:20 - loss: 1.9403 - categorical_accuracy: 0.2750-----Batch5: size: 20\n",
            " 5/34 [===>..........................] - ETA: 1:09:44 - loss: 1.8764 - categorical_accuracy: 0.2700-----Batch6: size: 20\n",
            " 6/34 [====>.........................] - ETA: 1:07:13 - loss: 1.8310 - categorical_accuracy: 0.2500-----Batch7: size: 20\n",
            " 7/34 [=====>........................] - ETA: 1:04:38 - loss: 1.7988 - categorical_accuracy: 0.2571-----Batch8: size: 20\n",
            " 8/34 [======>.......................] - ETA: 1:02:07 - loss: 1.7758 - categorical_accuracy: 0.2625-----Batch9: size: 20\n",
            " 9/34 [======>.......................] - ETA: 1:00:02 - loss: 1.7579 - categorical_accuracy: 0.2611-----Batch10: size: 20\n",
            "10/34 [=======>......................] - ETA: 57:40 - loss: 1.7423 - categorical_accuracy: 0.2450  -----Batch11: size: 20\n",
            "11/34 [========>.....................] - ETA: 55:14 - loss: 1.7321 - categorical_accuracy: 0.2364-----Batch12: size: 20\n",
            "12/34 [=========>....................] - ETA: 52:45 - loss: 1.7231 - categorical_accuracy: 0.2167-----Batch13: size: 20\n",
            "13/34 [==========>...................] - ETA: 50:12 - loss: 1.7141 - categorical_accuracy: 0.2192-----Batch14: size: 20\n",
            "14/34 [===========>..................] - ETA: 47:46 - loss: 1.7067 - categorical_accuracy: 0.2214-----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 45:14 - loss: 1.6994 - categorical_accuracy: 0.2333-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 43:06 - loss: 1.6922 - categorical_accuracy: 0.2375-----Batch17: size: 20\n",
            "17/34 [==============>...............] - ETA: 41:00 - loss: 1.6877 - categorical_accuracy: 0.2353-----Batch18: size: 20\n",
            "18/34 [==============>...............] - ETA: 38:49 - loss: 1.6840 - categorical_accuracy: 0.2306-----Batch19: size: 20\n",
            "19/34 [===============>..............] - ETA: 36:36 - loss: 1.6785 - categorical_accuracy: 0.2316-----Batch20: size: 20\n",
            "20/34 [================>.............] - ETA: 33:35 - loss: 1.6764 - categorical_accuracy: 0.2250-----Batch21: size: 20\n",
            "21/34 [=================>............] - ETA: 30:21 - loss: 1.6739 - categorical_accuracy: 0.2190-----Batch22: size: 20\n",
            "22/34 [==================>...........] - ETA: 27:19 - loss: 1.6697 - categorical_accuracy: 0.2250-----Batch23: size: 20\n",
            "23/34 [===================>..........] - ETA: 24:28 - loss: 1.6666 - categorical_accuracy: 0.2217-----Batch24: size: 20\n",
            "24/34 [====================>.........] - ETA: 21:47 - loss: 1.6639 - categorical_accuracy: 0.2188-----Batch25: size: 20\n",
            "25/34 [=====================>........] - ETA: 19:12 - loss: 1.6606 - categorical_accuracy: 0.2220-----Batch26: size: 20\n",
            "26/34 [=====================>........] - ETA: 16:44 - loss: 1.6589 - categorical_accuracy: 0.2173-----Batch27: size: 20\n",
            "27/34 [======================>.......] - ETA: 14:23 - loss: 1.6572 - categorical_accuracy: 0.2148-----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 12:07 - loss: 1.6532 - categorical_accuracy: 0.2214-----Batch29: size: 20\n",
            "29/34 [========================>.....] - ETA: 9:56 - loss: 1.6503 - categorical_accuracy: 0.2207 -----Batch30: size: 20\n",
            "30/34 [=========================>....] - ETA: 7:50 - loss: 1.6470 - categorical_accuracy: 0.2167-----Batch31: size: 20\n",
            "31/34 [==========================>...] - ETA: 5:47 - loss: 1.6427 - categorical_accuracy: 0.2177-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 3:48 - loss: 1.6335 - categorical_accuracy: 0.2219-----last Batch size: 3\n",
            "33/34 [============================>.] - ETA: 1:52 - loss: 1.6314 - categorical_accuracy: 0.2242-----Batch0: size: 20\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.6320 - categorical_accuracy: 0.2232  -----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "\n",
            "Epoch 00001: saving model to model_init_2021-12-2822_04_44.919280\\model-00001-1.63202-0.22323-1.50268-0.37000.h5\n",
            "34/34 [==============================] - 3819s 111s/step - loss: 1.6320 - categorical_accuracy: 0.2232 - val_loss: 1.5027 - val_categorical_accuracy: 0.3700 - lr: 0.0010\n",
            "Epoch 2/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 37:42 - loss: 1.5033 - categorical_accuracy: 0.4500-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 35:52 - loss: 1.5462 - categorical_accuracy: 0.3000-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 34:49 - loss: 1.5660 - categorical_accuracy: 0.3000-----Batch4: size: 20\n",
            " 4/34 [==>...........................] - ETA: 33:49 - loss: 1.5720 - categorical_accuracy: 0.3000-----Batch5: size: 20\n",
            " 5/34 [===>..........................] - ETA: 32:29 - loss: 1.5722 - categorical_accuracy: 0.3000-----Batch6: size: 20\n",
            " 6/34 [====>.........................] - ETA: 31:20 - loss: 1.5579 - categorical_accuracy: 0.3333-----Batch7: size: 20\n",
            " 7/34 [=====>........................] - ETA: 30:13 - loss: 1.5500 - categorical_accuracy: 0.3429-----Batch8: size: 20\n",
            " 8/34 [======>.......................] - ETA: 29:08 - loss: 1.5263 - categorical_accuracy: 0.3562-----Batch9: size: 20\n",
            " 9/34 [======>.......................] - ETA: 27:57 - loss: 1.5280 - categorical_accuracy: 0.3389-----Batch10: size: 20\n",
            "10/34 [=======>......................] - ETA: 26:41 - loss: 1.4984 - categorical_accuracy: 0.3450-----Batch11: size: 20\n",
            "11/34 [========>.....................] - ETA: 25:29 - loss: 1.5152 - categorical_accuracy: 0.3364-----Batch12: size: 20\n",
            "12/34 [=========>....................] - ETA: 24:17 - loss: 1.5054 - categorical_accuracy: 0.3500-----Batch13: size: 20\n",
            "13/34 [==========>...................] - ETA: 23:08 - loss: 1.5072 - categorical_accuracy: 0.3577-----Batch14: size: 20\n",
            "14/34 [===========>..................] - ETA: 21:59 - loss: 1.5040 - categorical_accuracy: 0.3607-----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 20:52 - loss: 1.5034 - categorical_accuracy: 0.3567-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 19:44 - loss: 1.5062 - categorical_accuracy: 0.3531-----Batch17: size: 20\n",
            "17/34 [==============>...............] - ETA: 18:37 - loss: 1.5000 - categorical_accuracy: 0.3618-----Batch18: size: 20\n",
            "18/34 [==============>...............] - ETA: 17:30 - loss: 1.4980 - categorical_accuracy: 0.3556-----Batch19: size: 20\n",
            "19/34 [===============>..............] - ETA: 16:26 - loss: 1.4894 - categorical_accuracy: 0.3632-----Batch20: size: 20\n",
            "20/34 [================>.............] - ETA: 15:21 - loss: 1.4649 - categorical_accuracy: 0.3725-----Batch21: size: 20\n",
            "21/34 [=================>............] - ETA: 14:14 - loss: 1.4489 - categorical_accuracy: 0.3714-----Batch22: size: 20\n",
            "22/34 [==================>...........] - ETA: 13:08 - loss: 1.4448 - categorical_accuracy: 0.3659-----Batch23: size: 20\n",
            "23/34 [===================>..........] - ETA: 12:01 - loss: 1.4406 - categorical_accuracy: 0.3652-----Batch24: size: 20\n",
            "24/34 [====================>.........] - ETA: 10:55 - loss: 1.4282 - categorical_accuracy: 0.3667-----Batch25: size: 20\n",
            "25/34 [=====================>........] - ETA: 9:49 - loss: 1.4235 - categorical_accuracy: 0.3700 -----Batch26: size: 20\n",
            "26/34 [=====================>........] - ETA: 8:43 - loss: 1.4187 - categorical_accuracy: 0.3750-----Batch27: size: 20\n",
            "27/34 [======================>.......] - ETA: 7:37 - loss: 1.4092 - categorical_accuracy: 0.3833-----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 6:32 - loss: 1.4029 - categorical_accuracy: 0.3893-----Batch29: size: 20\n",
            "29/34 [========================>.....] - ETA: 5:26 - loss: 1.3940 - categorical_accuracy: 0.4000-----Batch30: size: 20\n",
            "30/34 [=========================>....] - ETA: 4:21 - loss: 1.3732 - categorical_accuracy: 0.4100-----Batch31: size: 20\n",
            "31/34 [==========================>...] - ETA: 3:15 - loss: 1.3589 - categorical_accuracy: 0.4177-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 2:10 - loss: 1.3607 - categorical_accuracy: 0.4219-----last Batch size: 3\n",
            "33/34 [============================>.] - ETA: 1:05 - loss: 1.3521 - categorical_accuracy: 0.4273-----Batch0: size: 20\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.3520 - categorical_accuracy: 0.4268  -----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "\n",
            "Epoch 00002: saving model to model_init_2021-12-2822_04_44.919280\\model-00002-1.35196-0.42685-1.07697-0.58000.h5\n",
            "34/34 [==============================] - 2219s 65s/step - loss: 1.3520 - categorical_accuracy: 0.4268 - val_loss: 1.0770 - val_categorical_accuracy: 0.5800 - lr: 0.0010\n",
            "Epoch 3/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 38:45 - loss: 1.0672 - categorical_accuracy: 0.5000-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 36:29 - loss: 1.0190 - categorical_accuracy: 0.5500-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 34:37 - loss: 1.0001 - categorical_accuracy: 0.5333-----Batch4: size: 20\n",
            " 4/34 [==>...........................] - ETA: 33:26 - loss: 0.9845 - categorical_accuracy: 0.5625-----Batch5: size: 20\n",
            " 5/34 [===>..........................] - ETA: 32:26 - loss: 0.9718 - categorical_accuracy: 0.5700-----Batch6: size: 20\n",
            " 6/34 [====>.........................] - ETA: 31:23 - loss: 0.9572 - categorical_accuracy: 0.5917-----Batch7: size: 20\n",
            " 7/34 [=====>........................] - ETA: 30:17 - loss: 0.9371 - categorical_accuracy: 0.6143-----Batch8: size: 20\n",
            " 8/34 [======>.......................] - ETA: 29:04 - loss: 0.9510 - categorical_accuracy: 0.6250-----Batch9: size: 20\n",
            " 9/34 [======>.......................] - ETA: 27:48 - loss: 0.9367 - categorical_accuracy: 0.6278-----Batch10: size: 20\n",
            "10/34 [=======>......................] - ETA: 26:35 - loss: 0.9512 - categorical_accuracy: 0.6350-----Batch11: size: 20\n",
            "11/34 [========>.....................] - ETA: 25:25 - loss: 0.9407 - categorical_accuracy: 0.6455-----Batch12: size: 20\n",
            "12/34 [=========>....................] - ETA: 24:14 - loss: 0.9334 - categorical_accuracy: 0.6542-----Batch13: size: 20\n",
            "13/34 [==========>...................] - ETA: 23:05 - loss: 0.9019 - categorical_accuracy: 0.6731-----Batch14: size: 20\n",
            "14/34 [===========>..................] - ETA: 21:55 - loss: 0.8905 - categorical_accuracy: 0.6714-----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 20:47 - loss: 0.8872 - categorical_accuracy: 0.6667-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 19:40 - loss: 0.8928 - categorical_accuracy: 0.6625-----Batch17: size: 20\n",
            "17/34 [==============>...............] - ETA: 18:33 - loss: 0.8722 - categorical_accuracy: 0.6706-----Batch18: size: 20\n",
            "18/34 [==============>...............] - ETA: 17:26 - loss: 0.8842 - categorical_accuracy: 0.6722-----Batch19: size: 20\n",
            "19/34 [===============>..............] - ETA: 16:20 - loss: 0.8806 - categorical_accuracy: 0.6711-----Batch20: size: 20\n",
            "20/34 [================>.............] - ETA: 15:14 - loss: 0.8888 - categorical_accuracy: 0.6650-----Batch21: size: 20\n",
            "21/34 [=================>............] - ETA: 14:08 - loss: 0.8956 - categorical_accuracy: 0.6595-----Batch22: size: 20\n",
            "22/34 [==================>...........] - ETA: 13:03 - loss: 0.8803 - categorical_accuracy: 0.6636-----Batch23: size: 20\n",
            "23/34 [===================>..........] - ETA: 11:57 - loss: 0.8703 - categorical_accuracy: 0.6674-----Batch24: size: 20\n",
            "24/34 [====================>.........] - ETA: 10:51 - loss: 0.8758 - categorical_accuracy: 0.6708-----Batch25: size: 20\n",
            "25/34 [=====================>........] - ETA: 9:45 - loss: 0.8726 - categorical_accuracy: 0.6740 -----Batch26: size: 20\n",
            "26/34 [=====================>........] - ETA: 8:40 - loss: 0.8692 - categorical_accuracy: 0.6750-----Batch27: size: 20\n",
            "27/34 [======================>.......] - ETA: 7:34 - loss: 0.8688 - categorical_accuracy: 0.6704-----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 6:29 - loss: 0.8657 - categorical_accuracy: 0.6732-----Batch29: size: 20\n",
            "29/34 [========================>.....] - ETA: 5:24 - loss: 0.8634 - categorical_accuracy: 0.6776-----Batch30: size: 20\n",
            "30/34 [=========================>....] - ETA: 4:19 - loss: 0.8706 - categorical_accuracy: 0.6733-----Batch31: size: 20\n",
            "31/34 [==========================>...] - ETA: 3:14 - loss: 0.8735 - categorical_accuracy: 0.6726-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 2:09 - loss: 0.8791 - categorical_accuracy: 0.6687-----last Batch size: 3\n",
            "33/34 [============================>.] - ETA: 1:04 - loss: 0.8713 - categorical_accuracy: 0.6712-----Batch0: size: 20\n",
            "34/34 [==============================] - ETA: 0s - loss: 0.8719 - categorical_accuracy: 0.6697  -----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "\n",
            "Epoch 00003: saving model to model_init_2021-12-2822_04_44.919280\\model-00003-0.87194-0.66968-0.68060-0.79000.h5\n",
            "34/34 [==============================] - 2198s 64s/step - loss: 0.8719 - categorical_accuracy: 0.6697 - val_loss: 0.6806 - val_categorical_accuracy: 0.7900 - lr: 0.0010\n",
            "Epoch 4/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 35:43 - loss: 0.6622 - categorical_accuracy: 0.7500-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 34:22 - loss: 0.7055 - categorical_accuracy: 0.7500-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 33:27 - loss: 0.7455 - categorical_accuracy: 0.7500-----Batch4: size: 20\n",
            " 4/34 [==>...........................] - ETA: 32:22 - loss: 0.7218 - categorical_accuracy: 0.7625-----Batch5: size: 20\n",
            " 5/34 [===>..........................] - ETA: 31:15 - loss: 0.7813 - categorical_accuracy: 0.7200-----Batch6: size: 20\n",
            " 6/34 [====>.........................] - ETA: 30:11 - loss: 0.8280 - categorical_accuracy: 0.6833-----Batch7: size: 20\n",
            " 7/34 [=====>........................] - ETA: 29:07 - loss: 0.8166 - categorical_accuracy: 0.6929-----Batch8: size: 20\n",
            " 8/34 [======>.......................] - ETA: 28:17 - loss: 0.8042 - categorical_accuracy: 0.6875-----Batch9: size: 20\n",
            " 9/34 [======>.......................] - ETA: 27:31 - loss: 0.7833 - categorical_accuracy: 0.6944-----Batch10: size: 20\n",
            "10/34 [=======>......................] - ETA: 26:40 - loss: 0.7570 - categorical_accuracy: 0.7150-----Batch11: size: 20\n",
            "11/34 [========>.....................] - ETA: 25:44 - loss: 0.7851 - categorical_accuracy: 0.6864-----Batch12: size: 20\n",
            "12/34 [=========>....................] - ETA: 24:51 - loss: 0.7793 - categorical_accuracy: 0.6875-----Batch13: size: 20\n",
            "13/34 [==========>...................] - ETA: 23:46 - loss: 0.7656 - categorical_accuracy: 0.6885-----Batch14: size: 20\n",
            "14/34 [===========>..................] - ETA: 22:39 - loss: 0.7455 - categorical_accuracy: 0.7071-----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 21:33 - loss: 0.7398 - categorical_accuracy: 0.7067-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 20:28 - loss: 0.7167 - categorical_accuracy: 0.7156-----Batch17: size: 20\n",
            "17/34 [==============>...............] - ETA: 19:30 - loss: 0.7108 - categorical_accuracy: 0.7176-----Batch18: size: 20\n",
            "18/34 [==============>...............] - ETA: 18:24 - loss: 0.7078 - categorical_accuracy: 0.7111-----Batch19: size: 20\n",
            "19/34 [===============>..............] - ETA: 17:41 - loss: 0.7670 - categorical_accuracy: 0.7105-----Batch20: size: 20\n",
            "20/34 [================>.............] - ETA: 17:22 - loss: 0.7755 - categorical_accuracy: 0.7075-----Batch21: size: 20\n",
            "21/34 [=================>............] - ETA: 17:02 - loss: 0.7799 - categorical_accuracy: 0.7024-----Batch22: size: 20\n",
            "22/34 [==================>...........] - ETA: 16:26 - loss: 0.7696 - categorical_accuracy: 0.7045-----Batch23: size: 20\n",
            "23/34 [===================>..........] - ETA: 15:37 - loss: 0.7599 - categorical_accuracy: 0.7065-----Batch24: size: 20\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24/34 [====================>.........] - ETA: 14:03 - loss: 0.7618 - categorical_accuracy: 0.7000-----Batch25: size: 20\n",
            "25/34 [=====================>........] - ETA: 12:31 - loss: 0.7481 - categorical_accuracy: 0.7040-----Batch26: size: 20\n",
            "26/34 [=====================>........] - ETA: 11:02 - loss: 0.7537 - categorical_accuracy: 0.7038-----Batch27: size: 20\n",
            "27/34 [======================>.......] - ETA: 9:34 - loss: 0.7596 - categorical_accuracy: 0.6981 -----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 8:08 - loss: 0.7526 - categorical_accuracy: 0.7018-----Batch29: size: 20\n",
            "29/34 [========================>.....] - ETA: 6:43 - loss: 0.7370 - categorical_accuracy: 0.7103-----Batch30: size: 20\n",
            "30/34 [=========================>....] - ETA: 5:20 - loss: 0.7303 - categorical_accuracy: 0.7083-----Batch31: size: 20\n",
            "31/34 [==========================>...] - ETA: 3:58 - loss: 0.7248 - categorical_accuracy: 0.7145-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 2:38 - loss: 0.7216 - categorical_accuracy: 0.7141-----last Batch size: 3\n",
            "33/34 [============================>.] - ETA: 1:18 - loss: 0.7237 - categorical_accuracy: 0.7106-----Batch0: size: 20\n",
            "34/34 [==============================] - ETA: 0s - loss: 0.7248 - categorical_accuracy: 0.7104  -----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "\n",
            "Epoch 00004: saving model to model_init_2021-12-2822_04_44.919280\\model-00004-0.72485-0.71041-0.65906-0.81000.h5\n",
            "34/34 [==============================] - 2635s 78s/step - loss: 0.7248 - categorical_accuracy: 0.7104 - val_loss: 0.6591 - val_categorical_accuracy: 0.8100 - lr: 0.0010\n",
            "Epoch 5/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 35:14 - loss: 0.7077 - categorical_accuracy: 0.7000-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 34:15 - loss: 0.6588 - categorical_accuracy: 0.7250-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 32:58 - loss: 0.6775 - categorical_accuracy: 0.6833-----Batch4: size: 20\n",
            " 4/34 [==>...........................] - ETA: 31:53 - loss: 0.7073 - categorical_accuracy: 0.7000-----Batch5: size: 20\n",
            " 5/34 [===>..........................] - ETA: 30:50 - loss: 0.8036 - categorical_accuracy: 0.6900-----Batch6: size: 20\n",
            " 6/34 [====>.........................] - ETA: 29:45 - loss: 0.8021 - categorical_accuracy: 0.6917-----Batch7: size: 20\n",
            " 7/34 [=====>........................] - ETA: 28:40 - loss: 0.7534 - categorical_accuracy: 0.7071-----Batch8: size: 20\n",
            " 8/34 [======>.......................] - ETA: 27:35 - loss: 0.7362 - categorical_accuracy: 0.7188-----Batch9: size: 20\n",
            " 9/34 [======>.......................] - ETA: 26:30 - loss: 0.7287 - categorical_accuracy: 0.7056-----Batch10: size: 20\n",
            "10/34 [=======>......................] - ETA: 25:25 - loss: 0.7479 - categorical_accuracy: 0.7000-----Batch11: size: 20\n",
            "11/34 [========>.....................] - ETA: 24:20 - loss: 0.7349 - categorical_accuracy: 0.7045-----Batch12: size: 20\n",
            "12/34 [=========>....................] - ETA: 23:16 - loss: 0.7072 - categorical_accuracy: 0.7208-----Batch13: size: 20\n",
            "13/34 [==========>...................] - ETA: 22:12 - loss: 0.6951 - categorical_accuracy: 0.7192-----Batch14: size: 20\n",
            "14/34 [===========>..................] - ETA: 21:09 - loss: 0.6926 - categorical_accuracy: 0.7214-----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 20:06 - loss: 0.6805 - categorical_accuracy: 0.7200-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 19:02 - loss: 0.6736 - categorical_accuracy: 0.7281-----Batch17: size: 20\n",
            "17/34 [==============>...............] - ETA: 17:59 - loss: 0.6591 - categorical_accuracy: 0.7324-----Batch18: size: 20\n",
            "18/34 [==============>...............] - ETA: 16:56 - loss: 0.6614 - categorical_accuracy: 0.7333-----Batch19: size: 20\n",
            "19/34 [===============>..............] - ETA: 15:53 - loss: 0.6574 - categorical_accuracy: 0.7342-----Batch20: size: 20\n",
            "20/34 [================>.............] - ETA: 14:49 - loss: 0.6495 - categorical_accuracy: 0.7375-----Batch21: size: 20\n",
            "21/34 [=================>............] - ETA: 13:46 - loss: 0.6402 - categorical_accuracy: 0.7429-----Batch22: size: 20\n",
            "22/34 [==================>...........] - ETA: 12:43 - loss: 0.6323 - categorical_accuracy: 0.7477-----Batch23: size: 20\n",
            "23/34 [===================>..........] - ETA: 11:39 - loss: 0.6198 - categorical_accuracy: 0.7543-----Batch24: size: 20\n",
            "24/34 [====================>.........] - ETA: 10:35 - loss: 0.6152 - categorical_accuracy: 0.7542-----Batch25: size: 20\n",
            "25/34 [=====================>........] - ETA: 9:32 - loss: 0.6008 - categorical_accuracy: 0.7600 -----Batch26: size: 20\n",
            "26/34 [=====================>........] - ETA: 8:28 - loss: 0.6007 - categorical_accuracy: 0.7577-----Batch27: size: 20\n",
            "27/34 [======================>.......] - ETA: 7:24 - loss: 0.5886 - categorical_accuracy: 0.7648-----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 6:21 - loss: 0.5858 - categorical_accuracy: 0.7679-----Batch29: size: 20\n",
            "29/34 [========================>.....] - ETA: 5:17 - loss: 0.5729 - categorical_accuracy: 0.7741-----Batch30: size: 20\n",
            "30/34 [=========================>....] - ETA: 4:14 - loss: 0.5602 - categorical_accuracy: 0.7800-----Batch31: size: 20\n",
            "31/34 [==========================>...] - ETA: 3:10 - loss: 0.5680 - categorical_accuracy: 0.7774-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 2:07 - loss: 0.5632 - categorical_accuracy: 0.7781-----last Batch size: 3\n",
            "33/34 [============================>.] - ETA: 1:03 - loss: 0.5638 - categorical_accuracy: 0.7758-----Batch0: size: 20\n",
            "34/34 [==============================] - ETA: 0s - loss: 0.5662 - categorical_accuracy: 0.7738  -----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "\n",
            "Epoch 00005: saving model to model_init_2021-12-2822_04_44.919280\\model-00005-0.56619-0.77376-0.68929-0.83000.h5\n",
            "34/34 [==============================] - 2153s 63s/step - loss: 0.5662 - categorical_accuracy: 0.7738 - val_loss: 0.6893 - val_categorical_accuracy: 0.8300 - lr: 0.0010\n",
            "Epoch 6/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 35:11 - loss: 0.2922 - categorical_accuracy: 0.9000-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 33:49 - loss: 0.3592 - categorical_accuracy: 0.8750-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 32:50 - loss: 0.4338 - categorical_accuracy: 0.8500-----Batch4: size: 20\n",
            " 4/34 [==>...........................] - ETA: 31:52 - loss: 0.4843 - categorical_accuracy: 0.8375-----Batch5: size: 20\n",
            " 5/34 [===>..........................] - ETA: 30:47 - loss: 0.5141 - categorical_accuracy: 0.8100-----Batch6: size: 20\n",
            " 6/34 [====>.........................] - ETA: 29:42 - loss: 0.5043 - categorical_accuracy: 0.8333-----Batch7: size: 20\n",
            " 7/34 [=====>........................] - ETA: 28:39 - loss: 0.4898 - categorical_accuracy: 0.8357-----Batch8: size: 20\n",
            " 8/34 [======>.......................] - ETA: 27:34 - loss: 0.4659 - categorical_accuracy: 0.8438-----Batch9: size: 20\n",
            " 9/34 [======>.......................] - ETA: 26:31 - loss: 0.4921 - categorical_accuracy: 0.8333-----Batch10: size: 20\n",
            "10/34 [=======>......................] - ETA: 25:26 - loss: 0.4876 - categorical_accuracy: 0.8350-----Batch11: size: 20\n",
            "11/34 [========>.....................] - ETA: 24:23 - loss: 0.4824 - categorical_accuracy: 0.8273-----Batch12: size: 20\n",
            "12/34 [=========>....................] - ETA: 23:19 - loss: 0.4661 - categorical_accuracy: 0.8375-----Batch13: size: 20\n",
            "13/34 [==========>...................] - ETA: 22:14 - loss: 0.4760 - categorical_accuracy: 0.8308-----Batch14: size: 20\n",
            "14/34 [===========>..................] - ETA: 21:10 - loss: 0.4815 - categorical_accuracy: 0.8250-----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 20:06 - loss: 0.4766 - categorical_accuracy: 0.8267-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 19:02 - loss: 0.4734 - categorical_accuracy: 0.8250-----Batch17: size: 20\n",
            "17/34 [==============>...............] - ETA: 17:58 - loss: 0.4637 - categorical_accuracy: 0.8265-----Batch18: size: 20\n",
            "18/34 [==============>...............] - ETA: 16:54 - loss: 0.4549 - categorical_accuracy: 0.8278-----Batch19: size: 20\n",
            "19/34 [===============>..............] - ETA: 15:51 - loss: 0.4563 - categorical_accuracy: 0.8289-----Batch20: size: 20\n",
            "20/34 [================>.............] - ETA: 14:48 - loss: 0.4577 - categorical_accuracy: 0.8250-----Batch21: size: 20\n",
            "21/34 [=================>............] - ETA: 13:45 - loss: 0.4507 - categorical_accuracy: 0.8310-----Batch22: size: 20\n",
            "22/34 [==================>...........] - ETA: 12:41 - loss: 0.4576 - categorical_accuracy: 0.8250-----Batch23: size: 20\n",
            "23/34 [===================>..........] - ETA: 11:39 - loss: 0.4521 - categorical_accuracy: 0.8283-----Batch24: size: 20\n",
            "24/34 [====================>.........] - ETA: 10:35 - loss: 0.4493 - categorical_accuracy: 0.8292-----Batch25: size: 20\n",
            "25/34 [=====================>........] - ETA: 9:32 - loss: 0.4420 - categorical_accuracy: 0.8320 -----Batch26: size: 20\n",
            "26/34 [=====================>........] - ETA: 8:28 - loss: 0.4414 - categorical_accuracy: 0.8327-----Batch27: size: 20\n",
            "27/34 [======================>.......] - ETA: 7:25 - loss: 0.4347 - categorical_accuracy: 0.8352-----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 6:21 - loss: 0.4448 - categorical_accuracy: 0.8304-----Batch29: size: 20\n",
            "29/34 [========================>.....] - ETA: 5:17 - loss: 0.4505 - categorical_accuracy: 0.8310-----Batch30: size: 20\n",
            "30/34 [=========================>....] - ETA: 4:14 - loss: 0.4471 - categorical_accuracy: 0.8333-----Batch31: size: 20\n",
            "31/34 [==========================>...] - ETA: 3:10 - loss: 0.4418 - categorical_accuracy: 0.8339-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 2:06 - loss: 0.4365 - categorical_accuracy: 0.8375-----last Batch size: 3\n",
            "33/34 [============================>.] - ETA: 1:03 - loss: 0.4321 - categorical_accuracy: 0.8379-----Batch0: size: 20\n",
            "34/34 [==============================] - ETA: 0s - loss: 0.4302 - categorical_accuracy: 0.8386  -----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "\n",
            "Epoch 00006: saving model to model_init_2021-12-2822_04_44.919280\\model-00006-0.43022-0.83861-0.55551-0.87000.h5\n",
            "34/34 [==============================] - 2150s 63s/step - loss: 0.4302 - categorical_accuracy: 0.8386 - val_loss: 0.5555 - val_categorical_accuracy: 0.8700 - lr: 0.0010\n",
            "Epoch 7/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 35:01 - loss: 0.6113 - categorical_accuracy: 0.7000-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 33:53 - loss: 0.4184 - categorical_accuracy: 0.8000-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 32:56 - loss: 0.3647 - categorical_accuracy: 0.8333-----Batch4: size: 20\n",
            " 4/34 [==>...........................] - ETA: 31:48 - loss: 0.3432 - categorical_accuracy: 0.8500-----Batch5: size: 20\n",
            " 5/34 [===>..........................] - ETA: 30:46 - loss: 0.4172 - categorical_accuracy: 0.8400-----Batch6: size: 20\n",
            " 6/34 [====>.........................] - ETA: 29:40 - loss: 0.3916 - categorical_accuracy: 0.8583-----Batch7: size: 20\n",
            " 7/34 [=====>........................] - ETA: 28:36 - loss: 0.4084 - categorical_accuracy: 0.8643-----Batch8: size: 20\n",
            " 8/34 [======>.......................] - ETA: 27:30 - loss: 0.3912 - categorical_accuracy: 0.8687-----Batch9: size: 20\n",
            " 9/34 [======>.......................] - ETA: 26:27 - loss: 0.3946 - categorical_accuracy: 0.8611-----Batch10: size: 20\n",
            "10/34 [=======>......................] - ETA: 25:24 - loss: 0.3936 - categorical_accuracy: 0.8550-----Batch11: size: 20\n",
            "11/34 [========>.....................] - ETA: 24:20 - loss: 0.3832 - categorical_accuracy: 0.8591-----Batch12: size: 20\n",
            "12/34 [=========>....................] - ETA: 23:16 - loss: 0.3604 - categorical_accuracy: 0.8667-----Batch13: size: 20\n",
            "13/34 [==========>...................] - ETA: 22:12 - loss: 0.3412 - categorical_accuracy: 0.8731-----Batch14: size: 20\n",
            "14/34 [===========>..................] - ETA: 21:08 - loss: 0.3266 - categorical_accuracy: 0.8786-----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 20:05 - loss: 0.3161 - categorical_accuracy: 0.8833-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 19:01 - loss: 0.3101 - categorical_accuracy: 0.8875-----Batch17: size: 20\n",
            "17/34 [==============>...............] - ETA: 17:58 - loss: 0.3055 - categorical_accuracy: 0.8882-----Batch18: size: 20\n",
            "18/34 [==============>...............] - ETA: 16:54 - loss: 0.3131 - categorical_accuracy: 0.8833-----Batch19: size: 20\n",
            "19/34 [===============>..............] - ETA: 15:51 - loss: 0.3112 - categorical_accuracy: 0.8842-----Batch20: size: 20\n",
            "20/34 [================>.............] - ETA: 14:47 - loss: 0.2987 - categorical_accuracy: 0.8900-----Batch21: size: 20\n",
            "21/34 [=================>............] - ETA: 13:44 - loss: 0.2948 - categorical_accuracy: 0.8881-----Batch22: size: 20\n",
            "22/34 [==================>...........] - ETA: 12:40 - loss: 0.2883 - categorical_accuracy: 0.8886-----Batch23: size: 20\n",
            "23/34 [===================>..........] - ETA: 11:37 - loss: 0.2889 - categorical_accuracy: 0.8870-----Batch24: size: 20\n",
            "24/34 [====================>.........] - ETA: 10:33 - loss: 0.2867 - categorical_accuracy: 0.8854-----Batch25: size: 20\n",
            "25/34 [=====================>........] - ETA: 9:30 - loss: 0.2835 - categorical_accuracy: 0.8860 -----Batch26: size: 20\n",
            "26/34 [=====================>........] - ETA: 8:27 - loss: 0.2800 - categorical_accuracy: 0.8885-----Batch27: size: 20\n",
            "27/34 [======================>.......] - ETA: 7:23 - loss: 0.2763 - categorical_accuracy: 0.8889-----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 6:20 - loss: 0.2778 - categorical_accuracy: 0.8893-----Batch29: size: 20\n",
            "29/34 [========================>.....] - ETA: 5:17 - loss: 0.2702 - categorical_accuracy: 0.8931-----Batch30: size: 20\n",
            "30/34 [=========================>....] - ETA: 4:13 - loss: 0.2701 - categorical_accuracy: 0.8933-----Batch31: size: 20\n",
            "31/34 [==========================>...] - ETA: 3:10 - loss: 0.2713 - categorical_accuracy: 0.8952-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 2:06 - loss: 0.2705 - categorical_accuracy: 0.8969-----last Batch size: 3\n",
            "33/34 [============================>.] - ETA: 1:03 - loss: 0.2673 - categorical_accuracy: 0.8985-----Batch0: size: 20\n",
            "34/34 [==============================] - ETA: 0s - loss: 0.2741 - categorical_accuracy: 0.8959  -----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "\n",
            "Epoch 00007: saving model to model_init_2021-12-2822_04_44.919280\\model-00007-0.27413-0.89593-0.62936-0.84000.h5\n",
            "34/34 [==============================] - 2147s 63s/step - loss: 0.2741 - categorical_accuracy: 0.8959 - val_loss: 0.6294 - val_categorical_accuracy: 0.8400 - lr: 0.0010\n",
            "Epoch 8/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 34:54 - loss: 0.1251 - categorical_accuracy: 0.9000-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 33:33 - loss: 0.1458 - categorical_accuracy: 0.9250-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 32:41 - loss: 0.1425 - categorical_accuracy: 0.9500-----Batch4: size: 20\n",
            " 4/34 [==>...........................] - ETA: 31:37 - loss: 0.1388 - categorical_accuracy: 0.9625-----Batch5: size: 20\n",
            " 5/34 [===>..........................] - ETA: 30:30 - loss: 0.1522 - categorical_accuracy: 0.9600-----Batch6: size: 20\n",
            " 6/34 [====>.........................] - ETA: 29:25 - loss: 0.1407 - categorical_accuracy: 0.9667-----Batch7: size: 20\n",
            " 7/34 [=====>........................] - ETA: 28:21 - loss: 0.1797 - categorical_accuracy: 0.9429-----Batch8: size: 20\n",
            " 8/34 [======>.......................] - ETA: 27:18 - loss: 0.1846 - categorical_accuracy: 0.9438-----Batch9: size: 20\n",
            " 9/34 [======>.......................] - ETA: 26:14 - loss: 0.1802 - categorical_accuracy: 0.9444-----Batch10: size: 20\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/34 [=======>......................] - ETA: 25:11 - loss: 0.1792 - categorical_accuracy: 0.9450-----Batch11: size: 20\n",
            "11/34 [========>.....................] - ETA: 24:08 - loss: 0.1829 - categorical_accuracy: 0.9409-----Batch12: size: 20\n",
            "12/34 [=========>....................] - ETA: 23:06 - loss: 0.1742 - categorical_accuracy: 0.9458-----Batch13: size: 20\n",
            "13/34 [==========>...................] - ETA: 22:03 - loss: 0.1846 - categorical_accuracy: 0.9423-----Batch14: size: 20\n",
            "14/34 [===========>..................] - ETA: 21:00 - loss: 0.1816 - categorical_accuracy: 0.9393-----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 19:59 - loss: 0.2048 - categorical_accuracy: 0.9333-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 18:57 - loss: 0.2096 - categorical_accuracy: 0.9281-----Batch17: size: 20\n",
            "17/34 [==============>...............] - ETA: 17:54 - loss: 0.2113 - categorical_accuracy: 0.9265-----Batch18: size: 20\n",
            "18/34 [==============>...............] - ETA: 16:51 - loss: 0.2176 - categorical_accuracy: 0.9222-----Batch19: size: 20\n",
            "19/34 [===============>..............] - ETA: 15:48 - loss: 0.2181 - categorical_accuracy: 0.9211-----Batch20: size: 20\n",
            "20/34 [================>.............] - ETA: 14:44 - loss: 0.2172 - categorical_accuracy: 0.9250-----Batch21: size: 20\n",
            "21/34 [=================>............] - ETA: 13:41 - loss: 0.2233 - categorical_accuracy: 0.9214-----Batch22: size: 20\n",
            "22/34 [==================>...........] - ETA: 12:37 - loss: 0.2245 - categorical_accuracy: 0.9182-----Batch23: size: 20\n",
            "23/34 [===================>..........] - ETA: 11:34 - loss: 0.2186 - categorical_accuracy: 0.9217-----Batch24: size: 20\n",
            "24/34 [====================>.........] - ETA: 10:31 - loss: 0.2161 - categorical_accuracy: 0.9229-----Batch25: size: 20\n",
            "25/34 [=====================>........] - ETA: 9:28 - loss: 0.2225 - categorical_accuracy: 0.9220 -----Batch26: size: 20\n",
            "26/34 [=====================>........] - ETA: 8:25 - loss: 0.2300 - categorical_accuracy: 0.9192-----Batch27: size: 20\n",
            "27/34 [======================>.......] - ETA: 7:22 - loss: 0.2233 - categorical_accuracy: 0.9222-----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 6:19 - loss: 0.2206 - categorical_accuracy: 0.9232-----Batch29: size: 20\n",
            "29/34 [========================>.....] - ETA: 5:16 - loss: 0.2383 - categorical_accuracy: 0.9190-----Batch30: size: 20\n",
            "30/34 [=========================>....] - ETA: 4:13 - loss: 0.2389 - categorical_accuracy: 0.9200-----Batch31: size: 20\n",
            "31/34 [==========================>...] - ETA: 3:09 - loss: 0.2369 - categorical_accuracy: 0.9210-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 2:06 - loss: 0.2307 - categorical_accuracy: 0.9234-----last Batch size: 3\n",
            "33/34 [============================>.] - ETA: 1:03 - loss: 0.2333 - categorical_accuracy: 0.9212-----Batch0: size: 20\n",
            "34/34 [==============================] - ETA: 0s - loss: 0.2329 - categorical_accuracy: 0.9216  -----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "\n",
            "Epoch 00008: saving model to model_init_2021-12-2822_04_44.919280\\model-00008-0.23288-0.92157-0.86621-0.79000.h5\n",
            "34/34 [==============================] - 2143s 63s/step - loss: 0.2329 - categorical_accuracy: 0.9216 - val_loss: 0.8662 - val_categorical_accuracy: 0.7900 - lr: 0.0010\n",
            "Epoch 9/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 35:29 - loss: 0.3124 - categorical_accuracy: 0.8000-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 34:00 - loss: 0.2440 - categorical_accuracy: 0.8750-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 32:51 - loss: 0.2774 - categorical_accuracy: 0.8667-----Batch4: size: 20\n",
            " 4/34 [==>...........................] - ETA: 31:48 - loss: 0.3550 - categorical_accuracy: 0.8375-----Batch5: size: 20\n",
            " 5/34 [===>..........................] - ETA: 30:42 - loss: 0.3128 - categorical_accuracy: 0.8600-----Batch6: size: 20\n",
            " 6/34 [====>.........................] - ETA: 29:36 - loss: 0.2834 - categorical_accuracy: 0.8833-----Batch7: size: 20\n",
            " 7/34 [=====>........................] - ETA: 28:33 - loss: 0.2603 - categorical_accuracy: 0.8929-----Batch8: size: 20\n",
            " 8/34 [======>.......................] - ETA: 27:28 - loss: 0.2465 - categorical_accuracy: 0.9000-----Batch9: size: 20\n",
            " 9/34 [======>.......................] - ETA: 26:24 - loss: 0.2394 - categorical_accuracy: 0.9000-----Batch10: size: 20\n",
            "10/34 [=======>......................] - ETA: 25:20 - loss: 0.2411 - categorical_accuracy: 0.9000-----Batch11: size: 20\n",
            "11/34 [========>.....................] - ETA: 24:16 - loss: 0.2354 - categorical_accuracy: 0.9045-----Batch12: size: 20\n",
            "12/34 [=========>....................] - ETA: 23:12 - loss: 0.2526 - categorical_accuracy: 0.9000-----Batch13: size: 20\n",
            "13/34 [==========>...................] - ETA: 22:09 - loss: 0.2496 - categorical_accuracy: 0.9038-----Batch14: size: 20\n",
            "14/34 [===========>..................] - ETA: 21:06 - loss: 0.2448 - categorical_accuracy: 0.9107-----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 20:03 - loss: 0.2512 - categorical_accuracy: 0.9033-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 19:00 - loss: 0.2431 - categorical_accuracy: 0.9062-----Batch17: size: 20\n",
            "17/34 [==============>...............] - ETA: 17:56 - loss: 0.2397 - categorical_accuracy: 0.9029-----Batch18: size: 20\n",
            "18/34 [==============>...............] - ETA: 16:53 - loss: 0.2617 - categorical_accuracy: 0.8972-----Batch19: size: 20\n",
            "19/34 [===============>..............] - ETA: 15:50 - loss: 0.2666 - categorical_accuracy: 0.8974-----Batch20: size: 20\n",
            "20/34 [================>.............] - ETA: 14:47 - loss: 0.2691 - categorical_accuracy: 0.8975-----Batch21: size: 20\n",
            "21/34 [=================>............] - ETA: 13:44 - loss: 0.2655 - categorical_accuracy: 0.8976-----Batch22: size: 20\n",
            "22/34 [==================>...........] - ETA: 12:41 - loss: 0.2756 - categorical_accuracy: 0.8932-----Batch23: size: 20\n",
            "23/34 [===================>..........] - ETA: 11:37 - loss: 0.2684 - categorical_accuracy: 0.8978-----Batch24: size: 20\n",
            "24/34 [====================>.........] - ETA: 10:33 - loss: 0.2632 - categorical_accuracy: 0.8979-----Batch25: size: 20\n",
            "25/34 [=====================>........] - ETA: 9:30 - loss: 0.2547 - categorical_accuracy: 0.9020 -----Batch26: size: 20\n",
            "26/34 [=====================>........] - ETA: 8:27 - loss: 0.2533 - categorical_accuracy: 0.9019-----Batch27: size: 20\n",
            "27/34 [======================>.......] - ETA: 7:23 - loss: 0.2510 - categorical_accuracy: 0.9037-----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 6:20 - loss: 0.2606 - categorical_accuracy: 0.9036-----Batch29: size: 20\n",
            "29/34 [========================>.....] - ETA: 5:16 - loss: 0.2561 - categorical_accuracy: 0.9052-----Batch30: size: 20\n",
            "30/34 [=========================>....] - ETA: 4:13 - loss: 0.2642 - categorical_accuracy: 0.9017-----Batch31: size: 20\n",
            "31/34 [==========================>...] - ETA: 3:10 - loss: 0.2588 - categorical_accuracy: 0.9032-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 2:06 - loss: 0.2607 - categorical_accuracy: 0.9031-----last Batch size: 3\n",
            "33/34 [============================>.] - ETA: 1:03 - loss: 0.2626 - categorical_accuracy: 0.9015-----Batch0: size: 20\n",
            "34/34 [==============================] - ETA: 0s - loss: 0.2616 - categorical_accuracy: 0.9020  -----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "\n",
            "Epoch 00009: saving model to model_init_2021-12-2822_04_44.919280\\model-00009-0.26158-0.90196-0.61915-0.85000.h5\n",
            "34/34 [==============================] - 2147s 63s/step - loss: 0.2616 - categorical_accuracy: 0.9020 - val_loss: 0.6192 - val_categorical_accuracy: 0.8500 - lr: 0.0010\n",
            "Epoch 10/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 35:23 - loss: 0.4197 - categorical_accuracy: 0.9000-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 33:51 - loss: 0.3057 - categorical_accuracy: 0.9250-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 32:53 - loss: 0.2373 - categorical_accuracy: 0.9500-----Batch4: size: 20\n",
            " 4/34 [==>...........................] - ETA: 31:47 - loss: 0.2114 - categorical_accuracy: 0.9625-----Batch5: size: 20\n",
            " 5/34 [===>..........................] - ETA: 30:44 - loss: 0.1841 - categorical_accuracy: 0.9700-----Batch6: size: 20\n",
            " 6/34 [====>.........................] - ETA: 29:39 - loss: 0.1988 - categorical_accuracy: 0.9583-----Batch7: size: 20\n",
            " 7/34 [=====>........................] - ETA: 28:35 - loss: 0.1773 - categorical_accuracy: 0.9643-----Batch8: size: 20\n",
            " 8/34 [======>.......................] - ETA: 27:31 - loss: 0.1810 - categorical_accuracy: 0.9500-----Batch9: size: 20\n",
            " 9/34 [======>.......................] - ETA: 26:25 - loss: 0.1857 - categorical_accuracy: 0.9444-----Batch10: size: 20\n",
            "10/34 [=======>......................] - ETA: 25:21 - loss: 0.1848 - categorical_accuracy: 0.9450-----Batch11: size: 20\n",
            "11/34 [========>.....................] - ETA: 24:16 - loss: 0.1713 - categorical_accuracy: 0.9500-----Batch12: size: 20\n",
            "12/34 [=========>....................] - ETA: 23:12 - loss: 0.1722 - categorical_accuracy: 0.9500-----Batch13: size: 20\n",
            "13/34 [==========>...................] - ETA: 22:09 - loss: 0.1631 - categorical_accuracy: 0.9538-----Batch14: size: 20\n",
            "14/34 [===========>..................] - ETA: 21:06 - loss: 0.1539 - categorical_accuracy: 0.9571-----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 20:03 - loss: 0.1643 - categorical_accuracy: 0.9500-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 18:59 - loss: 0.1586 - categorical_accuracy: 0.9531-----Batch17: size: 20\n",
            "17/34 [==============>...............] - ETA: 17:56 - loss: 0.1512 - categorical_accuracy: 0.9559-----Batch18: size: 20\n",
            "18/34 [==============>...............] - ETA: 16:54 - loss: 0.1552 - categorical_accuracy: 0.9528-----Batch19: size: 20\n",
            "19/34 [===============>..............] - ETA: 15:51 - loss: 0.1482 - categorical_accuracy: 0.9553-----Batch20: size: 20\n",
            "20/34 [================>.............] - ETA: 14:47 - loss: 0.1478 - categorical_accuracy: 0.9525-----Batch21: size: 20\n",
            "21/34 [=================>............] - ETA: 13:44 - loss: 0.1445 - categorical_accuracy: 0.9548-----Batch22: size: 20\n",
            "22/34 [==================>...........] - ETA: 12:40 - loss: 0.1403 - categorical_accuracy: 0.9568-----Batch23: size: 20\n",
            "23/34 [===================>..........] - ETA: 11:37 - loss: 0.1465 - categorical_accuracy: 0.9543-----Batch24: size: 20\n",
            "24/34 [====================>.........] - ETA: 10:33 - loss: 0.1482 - categorical_accuracy: 0.9521-----Batch25: size: 20\n",
            "25/34 [=====================>........] - ETA: 9:30 - loss: 0.1523 - categorical_accuracy: 0.9500 -----Batch26: size: 20\n",
            "26/34 [=====================>........] - ETA: 8:27 - loss: 0.1514 - categorical_accuracy: 0.9500-----Batch27: size: 20\n",
            "27/34 [======================>.......] - ETA: 7:23 - loss: 0.1516 - categorical_accuracy: 0.9481-----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 6:20 - loss: 0.1506 - categorical_accuracy: 0.9482-----Batch29: size: 20\n",
            "29/34 [========================>.....] - ETA: 5:16 - loss: 0.1507 - categorical_accuracy: 0.9466-----Batch30: size: 20\n",
            "30/34 [=========================>....] - ETA: 4:13 - loss: 0.1496 - categorical_accuracy: 0.9467-----Batch31: size: 20\n",
            "31/34 [==========================>...] - ETA: 3:10 - loss: 0.1525 - categorical_accuracy: 0.9435-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 2:07 - loss: 0.1525 - categorical_accuracy: 0.9422-----last Batch size: 3\n",
            "33/34 [============================>.] - ETA: 1:03 - loss: 0.1491 - categorical_accuracy: 0.9439-----Batch0: size: 20\n",
            "34/34 [==============================] - ETA: 0s - loss: 0.1494 - categorical_accuracy: 0.9442  -----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "\n",
            "Epoch 00010: saving model to model_init_2021-12-2822_04_44.919280\\model-00010-0.14942-0.94419-0.63717-0.87000.h5\n",
            "34/34 [==============================] - 2151s 63s/step - loss: 0.1494 - categorical_accuracy: 0.9442 - val_loss: 0.6372 - val_categorical_accuracy: 0.8700 - lr: 0.0010\n",
            "Epoch 11/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 34:59 - loss: 0.0704 - categorical_accuracy: 0.9500-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 33:45 - loss: 0.0556 - categorical_accuracy: 0.9750-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 32:53 - loss: 0.0614 - categorical_accuracy: 0.9667-----Batch4: size: 20\n",
            " 4/34 [==>...........................] - ETA: 31:45 - loss: 0.0684 - categorical_accuracy: 0.9750-----Batch5: size: 20\n",
            " 5/34 [===>..........................] - ETA: 30:40 - loss: 0.0745 - categorical_accuracy: 0.9700-----Batch6: size: 20\n",
            " 6/34 [====>.........................] - ETA: 29:34 - loss: 0.0683 - categorical_accuracy: 0.9750-----Batch7: size: 20\n",
            " 7/34 [=====>........................] - ETA: 28:30 - loss: 0.0727 - categorical_accuracy: 0.9714-----Batch8: size: 20\n",
            " 8/34 [======>.......................] - ETA: 27:28 - loss: 0.0866 - categorical_accuracy: 0.9688-----Batch9: size: 20\n",
            " 9/34 [======>.......................] - ETA: 26:24 - loss: 0.0809 - categorical_accuracy: 0.9722-----Batch10: size: 20\n",
            "10/34 [=======>......................] - ETA: 25:20 - loss: 0.0787 - categorical_accuracy: 0.9750-----Batch11: size: 20\n",
            "11/34 [========>.....................] - ETA: 24:15 - loss: 0.0763 - categorical_accuracy: 0.9773-----Batch12: size: 20\n",
            "12/34 [=========>....................] - ETA: 23:13 - loss: 0.1031 - categorical_accuracy: 0.9667-----Batch13: size: 20\n",
            "13/34 [==========>...................] - ETA: 22:09 - loss: 0.1006 - categorical_accuracy: 0.9692-----Batch14: size: 20\n",
            "14/34 [===========>..................] - ETA: 21:05 - loss: 0.1148 - categorical_accuracy: 0.9643-----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 20:02 - loss: 0.1132 - categorical_accuracy: 0.9633-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 18:58 - loss: 0.1276 - categorical_accuracy: 0.9594-----Batch17: size: 20\n",
            "17/34 [==============>...............] - ETA: 17:55 - loss: 0.1225 - categorical_accuracy: 0.9618-----Batch18: size: 20\n",
            "18/34 [==============>...............] - ETA: 16:51 - loss: 0.1355 - categorical_accuracy: 0.9556-----Batch19: size: 20\n",
            "19/34 [===============>..............] - ETA: 15:48 - loss: 0.1542 - categorical_accuracy: 0.9500-----Batch20: size: 20\n",
            "20/34 [================>.............] - ETA: 14:44 - loss: 0.1496 - categorical_accuracy: 0.9500-----Batch21: size: 20\n",
            "21/34 [=================>............] - ETA: 13:41 - loss: 0.1448 - categorical_accuracy: 0.9524-----Batch22: size: 20\n",
            "22/34 [==================>...........] - ETA: 12:37 - loss: 0.1387 - categorical_accuracy: 0.9545-----Batch23: size: 20\n",
            "23/34 [===================>..........] - ETA: 11:34 - loss: 0.1503 - categorical_accuracy: 0.9522-----Batch24: size: 20\n",
            "24/34 [====================>.........] - ETA: 10:31 - loss: 0.1469 - categorical_accuracy: 0.9542-----Batch25: size: 20\n",
            "25/34 [=====================>........] - ETA: 9:28 - loss: 0.1455 - categorical_accuracy: 0.9540 -----Batch26: size: 20\n",
            "26/34 [=====================>........] - ETA: 8:25 - loss: 0.1508 - categorical_accuracy: 0.9519-----Batch27: size: 20\n",
            "27/34 [======================>.......] - ETA: 7:22 - loss: 0.1502 - categorical_accuracy: 0.9519-----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 6:19 - loss: 0.1622 - categorical_accuracy: 0.9446-----Batch29: size: 20\n",
            "29/34 [========================>.....] - ETA: 5:16 - loss: 0.1591 - categorical_accuracy: 0.9448-----Batch30: size: 20\n",
            "30/34 [=========================>....] - ETA: 4:12 - loss: 0.1571 - categorical_accuracy: 0.9450-----Batch31: size: 20\n",
            "31/34 [==========================>...] - ETA: 3:09 - loss: 0.1572 - categorical_accuracy: 0.9468-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 2:06 - loss: 0.1567 - categorical_accuracy: 0.9469-----last Batch size: 3\n",
            "33/34 [============================>.] - ETA: 1:03 - loss: 0.1543 - categorical_accuracy: 0.9485-----Batch0: size: 20\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34/34 [==============================] - ETA: 0s - loss: 0.1536 - categorical_accuracy: 0.9487  -----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "\n",
            "Epoch 00011: saving model to model_init_2021-12-2822_04_44.919280\\model-00011-0.15360-0.94872-0.71227-0.84000.h5\n",
            "34/34 [==============================] - 2142s 63s/step - loss: 0.1536 - categorical_accuracy: 0.9487 - val_loss: 0.7123 - val_categorical_accuracy: 0.8400 - lr: 0.0010\n",
            "Epoch 12/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 34:49 - loss: 0.1435 - categorical_accuracy: 0.9000-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 33:35 - loss: 0.0927 - categorical_accuracy: 0.9500-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 32:31 - loss: 0.1102 - categorical_accuracy: 0.9500-----Batch4: size: 20\n",
            " 4/34 [==>...........................] - ETA: 31:34 - loss: 0.1227 - categorical_accuracy: 0.9500-----Batch5: size: 20\n",
            " 5/34 [===>..........................] - ETA: 30:32 - loss: 0.1489 - categorical_accuracy: 0.9400-----Batch6: size: 20\n",
            " 6/34 [====>.........................] - ETA: 29:31 - loss: 0.1405 - categorical_accuracy: 0.9500-----Batch7: size: 20\n",
            " 7/34 [=====>........................] - ETA: 28:31 - loss: 0.1288 - categorical_accuracy: 0.9571-----Batch8: size: 20\n",
            " 8/34 [======>.......................] - ETA: 27:28 - loss: 0.1171 - categorical_accuracy: 0.9625-----Batch9: size: 20\n",
            " 9/34 [======>.......................] - ETA: 26:26 - loss: 0.1081 - categorical_accuracy: 0.9667-----Batch10: size: 20\n",
            "10/34 [=======>......................] - ETA: 25:22 - loss: 0.1235 - categorical_accuracy: 0.9600-----Batch11: size: 20\n",
            "11/34 [========>.....................] - ETA: 24:18 - loss: 0.1316 - categorical_accuracy: 0.9591-----Batch12: size: 20\n",
            "12/34 [=========>....................] - ETA: 23:14 - loss: 0.1282 - categorical_accuracy: 0.9625-----Batch13: size: 20\n",
            "13/34 [==========>...................] - ETA: 22:11 - loss: 0.1218 - categorical_accuracy: 0.9654-----Batch14: size: 20\n",
            "14/34 [===========>..................] - ETA: 21:07 - loss: 0.1189 - categorical_accuracy: 0.9679-----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 20:04 - loss: 0.1130 - categorical_accuracy: 0.9700-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 19:00 - loss: 0.1221 - categorical_accuracy: 0.9688-----Batch17: size: 20\n",
            "17/34 [==============>...............] - ETA: 17:57 - loss: 0.1188 - categorical_accuracy: 0.9706-----Batch18: size: 20\n",
            "18/34 [==============>...............] - ETA: 16:53 - loss: 0.1250 - categorical_accuracy: 0.9694-----Batch19: size: 20\n",
            "19/34 [===============>..............] - ETA: 15:50 - loss: 0.1196 - categorical_accuracy: 0.9711-----Batch20: size: 20\n",
            "20/34 [================>.............] - ETA: 14:46 - loss: 0.1187 - categorical_accuracy: 0.9725-----Batch21: size: 20\n",
            "21/34 [=================>............] - ETA: 13:43 - loss: 0.1146 - categorical_accuracy: 0.9738-----Batch22: size: 20\n",
            "22/34 [==================>...........] - ETA: 12:39 - loss: 0.1215 - categorical_accuracy: 0.9705-----Batch23: size: 20\n",
            "23/34 [===================>..........] - ETA: 11:36 - loss: 0.1182 - categorical_accuracy: 0.9717-----Batch24: size: 20\n",
            "24/34 [====================>.........] - ETA: 10:32 - loss: 0.1181 - categorical_accuracy: 0.9708-----Batch25: size: 20\n",
            "25/34 [=====================>........] - ETA: 9:29 - loss: 0.1208 - categorical_accuracy: 0.9680 -----Batch26: size: 20\n",
            "26/34 [=====================>........] - ETA: 8:26 - loss: 0.1206 - categorical_accuracy: 0.9673-----Batch27: size: 20\n",
            "27/34 [======================>.......] - ETA: 7:22 - loss: 0.1177 - categorical_accuracy: 0.9685-----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 6:19 - loss: 0.1143 - categorical_accuracy: 0.9696-----Batch29: size: 20\n",
            "29/34 [========================>.....] - ETA: 5:16 - loss: 0.1143 - categorical_accuracy: 0.9707-----Batch30: size: 20\n",
            "30/34 [=========================>....] - ETA: 4:13 - loss: 0.1145 - categorical_accuracy: 0.9700-----Batch31: size: 20\n",
            "31/34 [==========================>...] - ETA: 3:09 - loss: 0.1119 - categorical_accuracy: 0.9710-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 2:06 - loss: 0.1101 - categorical_accuracy: 0.9719-----last Batch size: 3\n",
            "33/34 [============================>.] - ETA: 1:03 - loss: 0.1114 - categorical_accuracy: 0.9712-----Batch0: size: 20\n",
            "34/34 [==============================] - ETA: 0s - loss: 0.1110 - categorical_accuracy: 0.9713  -----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "\n",
            "Epoch 00012: saving model to model_init_2021-12-2822_04_44.919280\\model-00012-0.11105-0.97134-0.57957-0.89000.h5\n",
            "34/34 [==============================] - 2144s 63s/step - loss: 0.1110 - categorical_accuracy: 0.9713 - val_loss: 0.5796 - val_categorical_accuracy: 0.8900 - lr: 1.0000e-04\n",
            "Epoch 13/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 35:12 - loss: 0.0630 - categorical_accuracy: 1.0000-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 33:47 - loss: 0.0667 - categorical_accuracy: 0.9750-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 32:52 - loss: 0.0545 - categorical_accuracy: 0.9833-----Batch4: size: 20\n",
            " 4/34 [==>...........................] - ETA: 31:57 - loss: 0.0638 - categorical_accuracy: 0.9750-----Batch5: size: 20\n",
            " 5/34 [===>..........................] - ETA: 30:48 - loss: 0.0697 - categorical_accuracy: 0.9700-----Batch6: size: 20\n",
            " 6/34 [====>.........................] - ETA: 29:43 - loss: 0.0648 - categorical_accuracy: 0.9750-----Batch7: size: 20\n",
            " 7/34 [=====>........................] - ETA: 28:34 - loss: 0.0634 - categorical_accuracy: 0.9786-----Batch8: size: 20\n",
            " 8/34 [======>.......................] - ETA: 27:32 - loss: 0.0657 - categorical_accuracy: 0.9750-----Batch9: size: 20\n",
            " 9/34 [======>.......................] - ETA: 26:28 - loss: 0.0734 - categorical_accuracy: 0.9722-----Batch10: size: 20\n",
            "10/34 [=======>......................] - ETA: 25:24 - loss: 0.0792 - categorical_accuracy: 0.9700-----Batch11: size: 20\n",
            "11/34 [========>.....................] - ETA: 24:20 - loss: 0.0906 - categorical_accuracy: 0.9682-----Batch12: size: 20\n",
            "12/34 [=========>....................] - ETA: 23:16 - loss: 0.0962 - categorical_accuracy: 0.9667-----Batch13: size: 20\n",
            "13/34 [==========>...................] - ETA: 22:13 - loss: 0.0894 - categorical_accuracy: 0.9692-----Batch14: size: 20\n",
            "14/34 [===========>..................] - ETA: 21:11 - loss: 0.0949 - categorical_accuracy: 0.9643-----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 20:07 - loss: 0.0927 - categorical_accuracy: 0.9667-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 19:04 - loss: 0.0902 - categorical_accuracy: 0.9688-----Batch17: size: 20\n",
            "17/34 [==============>...............] - ETA: 18:01 - loss: 0.0927 - categorical_accuracy: 0.9676-----Batch18: size: 20\n",
            "18/34 [==============>...............] - ETA: 16:57 - loss: 0.0883 - categorical_accuracy: 0.9694-----Batch19: size: 20\n",
            "19/34 [===============>..............] - ETA: 15:53 - loss: 0.0856 - categorical_accuracy: 0.9711-----Batch20: size: 20\n",
            "20/34 [================>.............] - ETA: 14:50 - loss: 0.0903 - categorical_accuracy: 0.9675-----Batch21: size: 20\n",
            "21/34 [=================>............] - ETA: 13:46 - loss: 0.0895 - categorical_accuracy: 0.9667-----Batch22: size: 20\n",
            "22/34 [==================>...........] - ETA: 12:42 - loss: 0.0882 - categorical_accuracy: 0.9682-----Batch23: size: 20\n",
            "23/34 [===================>..........] - ETA: 11:38 - loss: 0.0864 - categorical_accuracy: 0.9696-----Batch24: size: 20\n",
            "24/34 [====================>.........] - ETA: 10:34 - loss: 0.0854 - categorical_accuracy: 0.9688-----Batch25: size: 20\n",
            "25/34 [=====================>........] - ETA: 9:31 - loss: 0.0895 - categorical_accuracy: 0.9680 -----Batch26: size: 20\n",
            "26/34 [=====================>........] - ETA: 8:27 - loss: 0.0897 - categorical_accuracy: 0.9673-----Batch27: size: 20\n",
            "27/34 [======================>.......] - ETA: 7:24 - loss: 0.0922 - categorical_accuracy: 0.9667-----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 6:20 - loss: 0.0952 - categorical_accuracy: 0.9661-----Batch29: size: 20\n",
            "29/34 [========================>.....] - ETA: 5:17 - loss: 0.0947 - categorical_accuracy: 0.9655-----Batch30: size: 20\n",
            "30/34 [=========================>....] - ETA: 4:13 - loss: 0.0931 - categorical_accuracy: 0.9667-----Batch31: size: 20\n",
            "31/34 [==========================>...] - ETA: 3:10 - loss: 0.0934 - categorical_accuracy: 0.9661-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 2:06 - loss: 0.0919 - categorical_accuracy: 0.9672-----last Batch size: 3\n",
            "33/34 [============================>.] - ETA: 1:03 - loss: 0.0908 - categorical_accuracy: 0.9667-----Batch0: size: 20\n",
            "34/34 [==============================] - ETA: 0s - loss: 0.0956 - categorical_accuracy: 0.9653  -----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "\n",
            "Epoch 00013: saving model to model_init_2021-12-2822_04_44.919280\\model-00013-0.09555-0.96531-0.87055-0.88000.h5\n",
            "34/34 [==============================] - 2149s 63s/step - loss: 0.0956 - categorical_accuracy: 0.9653 - val_loss: 0.8706 - val_categorical_accuracy: 0.8800 - lr: 1.0000e-04\n",
            "Epoch 14/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 35:21 - loss: 0.0708 - categorical_accuracy: 1.0000-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 34:00 - loss: 0.0613 - categorical_accuracy: 1.0000-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 32:58 - loss: 0.0600 - categorical_accuracy: 1.0000-----Batch4: size: 20\n",
            " 4/34 [==>...........................] - ETA: 31:50 - loss: 0.0580 - categorical_accuracy: 1.0000-----Batch5: size: 20\n",
            " 5/34 [===>..........................] - ETA: 30:43 - loss: 0.0668 - categorical_accuracy: 1.0000-----Batch6: size: 20\n",
            " 6/34 [====>.........................] - ETA: 29:39 - loss: 0.0589 - categorical_accuracy: 1.0000-----Batch7: size: 20\n",
            " 7/34 [=====>........................] - ETA: 28:33 - loss: 0.0665 - categorical_accuracy: 1.0000-----Batch8: size: 20\n",
            " 8/34 [======>.......................] - ETA: 27:31 - loss: 0.0601 - categorical_accuracy: 1.0000-----Batch9: size: 20\n",
            " 9/34 [======>.......................] - ETA: 26:26 - loss: 0.0629 - categorical_accuracy: 1.0000-----Batch10: size: 20\n",
            "10/34 [=======>......................] - ETA: 25:21 - loss: 0.0607 - categorical_accuracy: 1.0000-----Batch11: size: 20\n",
            "11/34 [========>.....................] - ETA: 24:16 - loss: 0.0666 - categorical_accuracy: 0.9955-----Batch12: size: 20\n",
            "12/34 [=========>....................] - ETA: 23:12 - loss: 0.0631 - categorical_accuracy: 0.9958-----Batch13: size: 20\n",
            "13/34 [==========>...................] - ETA: 22:08 - loss: 0.0614 - categorical_accuracy: 0.9962-----Batch14: size: 20\n",
            "14/34 [===========>..................] - ETA: 21:05 - loss: 0.0598 - categorical_accuracy: 0.9964-----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 20:02 - loss: 0.0614 - categorical_accuracy: 0.9933-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 18:58 - loss: 0.0634 - categorical_accuracy: 0.9906-----Batch17: size: 20\n",
            "17/34 [==============>...............] - ETA: 17:56 - loss: 0.0612 - categorical_accuracy: 0.9912-----Batch18: size: 20\n",
            "18/34 [==============>...............] - ETA: 16:53 - loss: 0.0674 - categorical_accuracy: 0.9861-----Batch19: size: 20\n",
            "19/34 [===============>..............] - ETA: 15:50 - loss: 0.0648 - categorical_accuracy: 0.9868-----Batch20: size: 20\n",
            "20/34 [================>.............] - ETA: 14:47 - loss: 0.0636 - categorical_accuracy: 0.9875-----Batch21: size: 20\n",
            "21/34 [=================>............] - ETA: 13:44 - loss: 0.0634 - categorical_accuracy: 0.9857-----Batch22: size: 20\n",
            "22/34 [==================>...........] - ETA: 12:40 - loss: 0.0618 - categorical_accuracy: 0.9864-----Batch23: size: 20\n",
            "23/34 [===================>..........] - ETA: 11:37 - loss: 0.0696 - categorical_accuracy: 0.9848-----Batch24: size: 20\n",
            "24/34 [====================>.........] - ETA: 10:33 - loss: 0.0687 - categorical_accuracy: 0.9854-----Batch25: size: 20\n",
            "25/34 [=====================>........] - ETA: 9:30 - loss: 0.0678 - categorical_accuracy: 0.9860 -----Batch26: size: 20\n",
            "26/34 [=====================>........] - ETA: 8:26 - loss: 0.0714 - categorical_accuracy: 0.9846-----Batch27: size: 20\n",
            "27/34 [======================>.......] - ETA: 7:23 - loss: 0.0709 - categorical_accuracy: 0.9852-----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 6:19 - loss: 0.0716 - categorical_accuracy: 0.9839-----Batch29: size: 20\n",
            "29/34 [========================>.....] - ETA: 5:16 - loss: 0.0733 - categorical_accuracy: 0.9828-----Batch30: size: 20\n",
            "30/34 [=========================>....] - ETA: 4:13 - loss: 0.0715 - categorical_accuracy: 0.9833-----Batch31: size: 20\n",
            "31/34 [==========================>...] - ETA: 3:09 - loss: 0.0741 - categorical_accuracy: 0.9823-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 2:06 - loss: 0.0727 - categorical_accuracy: 0.9828-----last Batch size: 3\n",
            "33/34 [============================>.] - ETA: 1:03 - loss: 0.0725 - categorical_accuracy: 0.9818-----Batch0: size: 20\n",
            "34/34 [==============================] - ETA: 0s - loss: 0.0722 - categorical_accuracy: 0.9819  -----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "\n",
            "Epoch 00014: saving model to model_init_2021-12-2822_04_44.919280\\model-00014-0.07217-0.98190-0.47857-0.91000.h5\n",
            "34/34 [==============================] - 2142s 63s/step - loss: 0.0722 - categorical_accuracy: 0.9819 - val_loss: 0.4786 - val_categorical_accuracy: 0.9100 - lr: 1.0000e-04\n",
            "Epoch 15/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 34:54 - loss: 0.1915 - categorical_accuracy: 0.9500-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 33:53 - loss: 0.1134 - categorical_accuracy: 0.9750-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 32:46 - loss: 0.1188 - categorical_accuracy: 0.9667-----Batch4: size: 20\n",
            " 4/34 [==>...........................] - ETA: 31:51 - loss: 0.0955 - categorical_accuracy: 0.9750-----Batch5: size: 20\n",
            " 5/34 [===>..........................] - ETA: 30:46 - loss: 0.0881 - categorical_accuracy: 0.9800-----Batch6: size: 20\n",
            " 6/34 [====>.........................] - ETA: 29:40 - loss: 0.0875 - categorical_accuracy: 0.9833-----Batch7: size: 20\n",
            " 7/34 [=====>........................] - ETA: 28:33 - loss: 0.0778 - categorical_accuracy: 0.9857-----Batch8: size: 20\n",
            " 8/34 [======>.......................] - ETA: 27:29 - loss: 0.0810 - categorical_accuracy: 0.9812-----Batch9: size: 20\n",
            " 9/34 [======>.......................] - ETA: 26:26 - loss: 0.0735 - categorical_accuracy: 0.9833-----Batch10: size: 20\n",
            "10/34 [=======>......................] - ETA: 25:23 - loss: 0.0708 - categorical_accuracy: 0.9850-----Batch11: size: 20\n",
            "11/34 [========>.....................] - ETA: 24:19 - loss: 0.0656 - categorical_accuracy: 0.9864-----Batch12: size: 20\n",
            "12/34 [=========>....................] - ETA: 23:15 - loss: 0.0680 - categorical_accuracy: 0.9833-----Batch13: size: 20\n",
            "13/34 [==========>...................] - ETA: 22:11 - loss: 0.0650 - categorical_accuracy: 0.9846-----Batch14: size: 20\n",
            "14/34 [===========>..................] - ETA: 21:07 - loss: 0.0611 - categorical_accuracy: 0.9857-----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 20:03 - loss: 0.0609 - categorical_accuracy: 0.9867-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 18:59 - loss: 0.0586 - categorical_accuracy: 0.9875-----Batch17: size: 20\n",
            "17/34 [==============>...............] - ETA: 17:56 - loss: 0.0593 - categorical_accuracy: 0.9882-----Batch18: size: 20\n",
            "18/34 [==============>...............] - ETA: 16:53 - loss: 0.0600 - categorical_accuracy: 0.9889-----Batch19: size: 20\n",
            "19/34 [===============>..............] - ETA: 15:50 - loss: 0.0658 - categorical_accuracy: 0.9868-----Batch20: size: 20\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/34 [================>.............] - ETA: 14:46 - loss: 0.0683 - categorical_accuracy: 0.9850-----Batch21: size: 20\n",
            "21/34 [=================>............] - ETA: 13:43 - loss: 0.0680 - categorical_accuracy: 0.9857-----Batch22: size: 20\n",
            "22/34 [==================>...........] - ETA: 12:40 - loss: 0.0678 - categorical_accuracy: 0.9864-----Batch23: size: 20\n",
            "23/34 [===================>..........] - ETA: 11:37 - loss: 0.0750 - categorical_accuracy: 0.9826-----Batch24: size: 20\n",
            "24/34 [====================>.........] - ETA: 10:33 - loss: 0.0746 - categorical_accuracy: 0.9833-----Batch25: size: 20\n",
            "25/34 [=====================>........] - ETA: 9:30 - loss: 0.0760 - categorical_accuracy: 0.9820 -----Batch26: size: 20\n",
            "26/34 [=====================>........] - ETA: 8:27 - loss: 0.0750 - categorical_accuracy: 0.9827-----Batch27: size: 20\n",
            "27/34 [======================>.......] - ETA: 7:23 - loss: 0.0728 - categorical_accuracy: 0.9833-----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 6:20 - loss: 0.0750 - categorical_accuracy: 0.9821-----Batch29: size: 20\n",
            "29/34 [========================>.....] - ETA: 5:16 - loss: 0.0727 - categorical_accuracy: 0.9828-----Batch30: size: 20\n",
            "30/34 [=========================>....] - ETA: 4:13 - loss: 0.0733 - categorical_accuracy: 0.9817-----Batch31: size: 20\n",
            "31/34 [==========================>...] - ETA: 3:10 - loss: 0.0729 - categorical_accuracy: 0.9806-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 2:06 - loss: 0.0746 - categorical_accuracy: 0.9812-----last Batch size: 3\n",
            "33/34 [============================>.] - ETA: 1:03 - loss: 0.0727 - categorical_accuracy: 0.9818-----Batch0: size: 20\n",
            "34/34 [==============================] - ETA: 0s - loss: 0.0747 - categorical_accuracy: 0.9804  -----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "\n",
            "Epoch 00015: saving model to model_init_2021-12-2822_04_44.919280\\model-00015-0.07469-0.98039-1.02087-0.89000.h5\n",
            "34/34 [==============================] - 2146s 63s/step - loss: 0.0747 - categorical_accuracy: 0.9804 - val_loss: 1.0209 - val_categorical_accuracy: 0.8900 - lr: 1.0000e-04\n",
            "Epoch 16/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 34:52 - loss: 0.0237 - categorical_accuracy: 1.0000-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 33:29 - loss: 0.0953 - categorical_accuracy: 0.9750-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 32:27 - loss: 0.0778 - categorical_accuracy: 0.9833-----Batch4: size: 20\n",
            " 4/34 [==>...........................] - ETA: 31:26 - loss: 0.1132 - categorical_accuracy: 0.9750-----Batch5: size: 20\n",
            " 5/34 [===>..........................] - ETA: 30:28 - loss: 0.1129 - categorical_accuracy: 0.9700-----Batch6: size: 20\n",
            " 6/34 [====>.........................] - ETA: 29:26 - loss: 0.1005 - categorical_accuracy: 0.9750-----Batch7: size: 20\n",
            " 7/34 [=====>........................] - ETA: 28:24 - loss: 0.0915 - categorical_accuracy: 0.9786-----Batch8: size: 20\n",
            " 8/34 [======>.......................] - ETA: 27:21 - loss: 0.0841 - categorical_accuracy: 0.9812-----Batch9: size: 20\n",
            " 9/34 [======>.......................] - ETA: 26:18 - loss: 0.0785 - categorical_accuracy: 0.9833-----Batch10: size: 20\n",
            "10/34 [=======>......................] - ETA: 25:16 - loss: 0.0757 - categorical_accuracy: 0.9850-----Batch11: size: 20\n",
            "11/34 [========>.....................] - ETA: 24:14 - loss: 0.0743 - categorical_accuracy: 0.9818-----Batch12: size: 20\n",
            "12/34 [=========>....................] - ETA: 23:11 - loss: 0.0690 - categorical_accuracy: 0.9833-----Batch13: size: 20\n",
            "13/34 [==========>...................] - ETA: 22:08 - loss: 0.0653 - categorical_accuracy: 0.9846-----Batch14: size: 20\n",
            "14/34 [===========>..................] - ETA: 21:05 - loss: 0.0610 - categorical_accuracy: 0.9857-----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 20:02 - loss: 0.0673 - categorical_accuracy: 0.9833-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 19:00 - loss: 0.0638 - categorical_accuracy: 0.9844-----Batch17: size: 20\n",
            "17/34 [==============>...............] - ETA: 17:56 - loss: 0.0650 - categorical_accuracy: 0.9824-----Batch18: size: 20\n",
            "18/34 [==============>...............] - ETA: 16:53 - loss: 0.0626 - categorical_accuracy: 0.9833-----Batch19: size: 20\n",
            "19/34 [===============>..............] - ETA: 15:51 - loss: 0.0628 - categorical_accuracy: 0.9842-----Batch20: size: 20\n",
            "20/34 [================>.............] - ETA: 14:50 - loss: 0.0607 - categorical_accuracy: 0.9850-----Batch21: size: 20\n",
            "21/34 [=================>............] - ETA: 13:47 - loss: 0.0589 - categorical_accuracy: 0.9857-----Batch22: size: 20\n",
            "22/34 [==================>...........] - ETA: 12:44 - loss: 0.0579 - categorical_accuracy: 0.9864-----Batch23: size: 20\n",
            "23/34 [===================>..........] - ETA: 11:40 - loss: 0.0578 - categorical_accuracy: 0.9870-----Batch24: size: 20\n",
            "24/34 [====================>.........] - ETA: 10:37 - loss: 0.0641 - categorical_accuracy: 0.9833-----Batch25: size: 20\n",
            "25/34 [=====================>........] - ETA: 9:33 - loss: 0.0658 - categorical_accuracy: 0.9820 -----Batch26: size: 20\n",
            "26/34 [=====================>........] - ETA: 8:30 - loss: 0.0643 - categorical_accuracy: 0.9827-----Batch27: size: 20\n",
            "27/34 [======================>.......] - ETA: 7:26 - loss: 0.0630 - categorical_accuracy: 0.9833-----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 6:22 - loss: 0.0629 - categorical_accuracy: 0.9839-----Batch29: size: 20\n",
            "29/34 [========================>.....] - ETA: 5:19 - loss: 0.0622 - categorical_accuracy: 0.9845-----Batch30: size: 20\n",
            "30/34 [=========================>....] - ETA: 4:15 - loss: 0.0606 - categorical_accuracy: 0.9850-----Batch31: size: 20\n",
            "31/34 [==========================>...] - ETA: 3:11 - loss: 0.0633 - categorical_accuracy: 0.9839-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 2:07 - loss: 0.0625 - categorical_accuracy: 0.9844-----last Batch size: 3\n",
            "33/34 [============================>.] - ETA: 1:03 - loss: 0.0625 - categorical_accuracy: 0.9833-----Batch0: size: 20\n",
            "34/34 [==============================] - ETA: 0s - loss: 0.0622 - categorical_accuracy: 0.9834  -----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "\n",
            "Epoch 00016: saving model to model_init_2021-12-2822_04_44.919280\\model-00016-0.06221-0.98341-0.79662-0.86000.h5\n",
            "34/34 [==============================] - 2158s 63s/step - loss: 0.0622 - categorical_accuracy: 0.9834 - val_loss: 0.7966 - val_categorical_accuracy: 0.8600 - lr: 1.0000e-04\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1ee8a2cef70>"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "                    callbacks=callbacks_list, validation_data=val_generator, \n",
        "                    validation_steps=validation_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDLo8pKwrcyJ"
      },
      "source": [
        "Observations:\n",
        "- Categorical accuracy at the end of epoch 16:  Train data: 0.98, validation data: 0.86 \n",
        "- Categorical accuracy at epoch 14: Train data: 0.98, validation data: 0.91 \n",
        "- So, model obtained at the end of epoch 14 seems suitable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HU1vCAwYrcyJ"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4R9q1mJnrcyJ"
      },
      "source": [
        "### Transfer learning: CNN (Resnet) + RNN (GRU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkoSrKDPrcyJ"
      },
      "source": [
        "#### Model#3: Use Resnet50 with last 10 layers weights being retrained along with GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHwPItc_rcyJ",
        "outputId": "03224c0b-6db7-4eee-f014-eda8740e4560"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " time_distributed_18 (TimeDi  (None, 15, 512)          24276288  \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " gru_11 (GRU)                (None, 15, 32)            52416     \n",
            "                                                                 \n",
            " gru_12 (GRU)                (None, 16)                2400      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 5)                 85        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,331,189\n",
            "Trainable params: 5,209,141\n",
            "Non-trainable params: 19,122,048\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "## model 3\n",
        "resnet = ResNet50(include_top=False,weights='imagenet',input_shape=(180,180,3))\n",
        "for layer in resnet.layers[:-10]:\n",
        "    layer.trainable=False\n",
        "cnn =Sequential([resnet])\n",
        "cnn.add(Conv2D(64,(2,2),strides=(1,1)))\n",
        "cnn.add(Conv2D(128,(2,2),strides=(1,1)))\n",
        "cnn.add(Conv2D(128,(2,2), strides= (1,1)))\n",
        "cnn.add(Conv2D(128,(2,2), strides= (1,1)))\n",
        "cnn.add(Flatten())\n",
        "model = Sequential()\n",
        "model.add(TimeDistributed(cnn,input_shape=(15,180,180,3)))\n",
        "model.add(GRU(32,input_shape=(None,15,512),return_sequences=True))\n",
        "model.add(GRU(16))\n",
        "model.add(Dense(5,activation='softmax'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYep851srcyK",
        "outputId": "933c574d-138f-40ba-fd7f-205e1801a362"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_train_sequences:150, num_val_sequences:100, steps_per_epoch:19, validation_steps:13\n",
            "-----Batch0: size: 8\n",
            "Epoch 1/5\n",
            "-----Batch1: size: 8\n",
            " 1/19 [>.............................] - ETA: 4:48 - loss: 1.5141 - categorical_accuracy: 0.3750-----Batch2: size: 8\n",
            " 2/19 [==>...........................] - ETA: 2:52 - loss: 1.9111 - categorical_accuracy: 0.2500-----Batch3: size: 8\n",
            " 3/19 [===>..........................] - ETA: 2:42 - loss: 1.8857 - categorical_accuracy: 0.2083-----Batch4: size: 8\n",
            " 4/19 [=====>........................] - ETA: 2:32 - loss: 1.9293 - categorical_accuracy: 0.1562-----Batch5: size: 8\n",
            " 5/19 [======>.......................] - ETA: 2:22 - loss: 1.8767 - categorical_accuracy: 0.1500-----Batch6: size: 8\n",
            " 6/19 [========>.....................] - ETA: 2:11 - loss: 1.8815 - categorical_accuracy: 0.1667-----Batch7: size: 8\n",
            " 7/19 [==========>...................] - ETA: 2:00 - loss: 1.8157 - categorical_accuracy: 0.1964-----Batch8: size: 8\n",
            " 8/19 [===========>..................] - ETA: 1:50 - loss: 1.7769 - categorical_accuracy: 0.2188-----Batch9: size: 8\n",
            " 9/19 [=============>................] - ETA: 1:39 - loss: 1.7650 - categorical_accuracy: 0.2083-----Batch10: size: 8\n",
            "10/19 [==============>...............] - ETA: 1:29 - loss: 1.7596 - categorical_accuracy: 0.2125-----Batch11: size: 8\n",
            "11/19 [================>.............] - ETA: 1:19 - loss: 1.7624 - categorical_accuracy: 0.2045-----Batch12: size: 8\n",
            "12/19 [=================>............] - ETA: 1:09 - loss: 1.7625 - categorical_accuracy: 0.1979-----Batch13: size: 8\n",
            "13/19 [===================>..........] - ETA: 59s - loss: 1.7666 - categorical_accuracy: 0.1827 -----Batch14: size: 8\n",
            "14/19 [=====================>........] - ETA: 49s - loss: 1.7697 - categorical_accuracy: 0.1696-----Batch15: size: 8\n",
            "15/19 [======================>.......] - ETA: 39s - loss: 1.7600 - categorical_accuracy: 0.1750-----Batch16: size: 8\n",
            "16/19 [========================>.....] - ETA: 29s - loss: 1.7559 - categorical_accuracy: 0.1719-----Batch17: size: 8\n",
            "17/19 [=========================>....] - ETA: 19s - loss: 1.7504 - categorical_accuracy: 0.1691-----last Batch size: 6\n",
            "18/19 [===========================>..] - ETA: 9s - loss: 1.7440 - categorical_accuracy: 0.1667 -----Batch0: size: 8\n",
            "19/19 [==============================] - ETA: 0s - loss: 1.7358 - categorical_accuracy: 0.1667-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "\n",
            "Epoch 00001: saving model to model_init_2021-12-2816_24_42.038728\\model-00001-1.73584-0.16667-1.61505-0.22000.h5\n",
            "19/19 [==============================] - 258s 13s/step - loss: 1.7358 - categorical_accuracy: 0.1667 - val_loss: 1.6150 - val_categorical_accuracy: 0.2200 - lr: 1.0000e-04\n",
            "Epoch 2/5\n",
            "-----Batch1: size: 8\n",
            " 1/19 [>.............................] - ETA: 3:03 - loss: 1.5892 - categorical_accuracy: 0.1250-----Batch2: size: 8\n",
            " 2/19 [==>...........................] - ETA: 2:48 - loss: 1.5933 - categorical_accuracy: 0.1875-----Batch3: size: 8\n",
            " 3/19 [===>..........................] - ETA: 2:38 - loss: 1.5759 - categorical_accuracy: 0.2083-----Batch4: size: 8\n",
            " 4/19 [=====>........................] - ETA: 2:29 - loss: 1.5652 - categorical_accuracy: 0.2812-----Batch5: size: 8\n",
            " 5/19 [======>.......................] - ETA: 2:18 - loss: 1.5751 - categorical_accuracy: 0.2500-----Batch6: size: 8\n",
            " 6/19 [========>.....................] - ETA: 2:08 - loss: 1.6444 - categorical_accuracy: 0.2083-----Batch7: size: 8\n",
            " 7/19 [==========>...................] - ETA: 1:58 - loss: 1.6500 - categorical_accuracy: 0.1964-----Batch8: size: 8\n",
            " 8/19 [===========>..................] - ETA: 1:48 - loss: 1.6467 - categorical_accuracy: 0.1875-----Batch9: size: 8\n",
            " 9/19 [=============>................] - ETA: 1:38 - loss: 1.6403 - categorical_accuracy: 0.1667-----Batch10: size: 8\n",
            "10/19 [==============>...............] - ETA: 1:28 - loss: 1.6397 - categorical_accuracy: 0.1750-----Batch11: size: 8\n",
            "11/19 [================>.............] - ETA: 1:18 - loss: 1.6303 - categorical_accuracy: 0.1932-----Batch12: size: 8\n",
            "12/19 [=================>............] - ETA: 1:08 - loss: 1.6279 - categorical_accuracy: 0.2083-----Batch13: size: 8\n",
            "13/19 [===================>..........] - ETA: 58s - loss: 1.6291 - categorical_accuracy: 0.2019 -----Batch14: size: 8\n",
            "14/19 [=====================>........] - ETA: 49s - loss: 1.6342 - categorical_accuracy: 0.1964-----Batch15: size: 8\n",
            "15/19 [======================>.......] - ETA: 39s - loss: 1.6429 - categorical_accuracy: 0.1917-----Batch16: size: 8\n",
            "16/19 [========================>.....] - ETA: 29s - loss: 1.6365 - categorical_accuracy: 0.1875-----Batch17: size: 8\n",
            "17/19 [=========================>....] - ETA: 19s - loss: 1.6343 - categorical_accuracy: 0.1985-----last Batch size: 6\n",
            "18/19 [===========================>..] - ETA: 9s - loss: 1.6371 - categorical_accuracy: 0.1875 -----Batch0: size: 8\n",
            "19/19 [==============================] - ETA: 0s - loss: 1.6366 - categorical_accuracy: 0.1867-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "\n",
            "Epoch 00002: saving model to model_init_2021-12-2816_24_42.038728\\model-00002-1.63656-0.18667-1.59811-0.22000.h5\n",
            "19/19 [==============================] - 249s 13s/step - loss: 1.6366 - categorical_accuracy: 0.1867 - val_loss: 1.5981 - val_categorical_accuracy: 0.2200 - lr: 1.0000e-04\n",
            "Epoch 3/5\n",
            "-----Batch1: size: 8\n",
            " 1/19 [>.............................] - ETA: 3:00 - loss: 1.5697 - categorical_accuracy: 0.5000-----Batch2: size: 8\n",
            " 2/19 [==>...........................] - ETA: 2:51 - loss: 1.6267 - categorical_accuracy: 0.3125-----Batch3: size: 8\n",
            " 3/19 [===>..........................] - ETA: 2:40 - loss: 1.6320 - categorical_accuracy: 0.2500-----Batch4: size: 8\n",
            " 4/19 [=====>........................] - ETA: 2:29 - loss: 1.6262 - categorical_accuracy: 0.2812-----Batch5: size: 8\n",
            " 5/19 [======>.......................] - ETA: 2:18 - loss: 1.6209 - categorical_accuracy: 0.2750-----Batch6: size: 8\n",
            " 6/19 [========>.....................] - ETA: 2:07 - loss: 1.6053 - categorical_accuracy: 0.2917-----Batch7: size: 8\n",
            " 7/19 [==========>...................] - ETA: 1:57 - loss: 1.6124 - categorical_accuracy: 0.2679-----Batch8: size: 8\n",
            " 8/19 [===========>..................] - ETA: 1:47 - loss: 1.6103 - categorical_accuracy: 0.2812-----Batch9: size: 8\n",
            " 9/19 [=============>................] - ETA: 1:38 - loss: 1.5974 - categorical_accuracy: 0.3194-----Batch10: size: 8\n",
            "10/19 [==============>...............] - ETA: 1:28 - loss: 1.5952 - categorical_accuracy: 0.3250-----Batch11: size: 8\n",
            "11/19 [================>.............] - ETA: 1:18 - loss: 1.6009 - categorical_accuracy: 0.2955-----Batch12: size: 8\n",
            "12/19 [=================>............] - ETA: 1:08 - loss: 1.6035 - categorical_accuracy: 0.2708-----Batch13: size: 8\n",
            "13/19 [===================>..........] - ETA: 58s - loss: 1.6070 - categorical_accuracy: 0.2500 -----Batch14: size: 8\n",
            "14/19 [=====================>........] - ETA: 49s - loss: 1.6092 - categorical_accuracy: 0.2411-----Batch15: size: 8\n",
            "15/19 [======================>.......] - ETA: 39s - loss: 1.6105 - categorical_accuracy: 0.2417-----Batch16: size: 8\n",
            "16/19 [========================>.....] - ETA: 29s - loss: 1.6094 - categorical_accuracy: 0.2422-----Batch17: size: 8\n",
            "17/19 [=========================>....] - ETA: 19s - loss: 1.6062 - categorical_accuracy: 0.2574-----last Batch size: 6\n",
            "18/19 [===========================>..] - ETA: 9s - loss: 1.6085 - categorical_accuracy: 0.2500 -----Batch0: size: 8\n",
            "19/19 [==============================] - ETA: 0s - loss: 1.6085 - categorical_accuracy: 0.2467-----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "\n",
            "Epoch 00003: saving model to model_init_2021-12-2816_24_42.038728\\model-00003-1.60852-0.24667-1.60178-0.18000.h5\n",
            "19/19 [==============================] - 248s 13s/step - loss: 1.6085 - categorical_accuracy: 0.2467 - val_loss: 1.6018 - val_categorical_accuracy: 0.1800 - lr: 1.0000e-04\n",
            "Epoch 4/5\n",
            "-----Batch1: size: 8\n",
            " 1/19 [>.............................] - ETA: 2:58 - loss: 1.5806 - categorical_accuracy: 0.2500-----Batch2: size: 8\n",
            " 2/19 [==>...........................] - ETA: 2:48 - loss: 1.5963 - categorical_accuracy: 0.2500-----Batch3: size: 8\n",
            " 3/19 [===>..........................] - ETA: 2:36 - loss: 1.5818 - categorical_accuracy: 0.4167-----Batch4: size: 8\n",
            " 4/19 [=====>........................] - ETA: 2:26 - loss: 1.5637 - categorical_accuracy: 0.4375-----Batch5: size: 8\n",
            " 5/19 [======>.......................] - ETA: 2:16 - loss: 1.5639 - categorical_accuracy: 0.4000-----Batch6: size: 8\n",
            " 6/19 [========>.....................] - ETA: 2:06 - loss: 1.5710 - categorical_accuracy: 0.3333-----Batch7: size: 8\n",
            " 7/19 [==========>...................] - ETA: 1:56 - loss: 1.5660 - categorical_accuracy: 0.3571-----Batch8: size: 8\n",
            " 8/19 [===========>..................] - ETA: 1:46 - loss: 1.5767 - categorical_accuracy: 0.3125-----Batch9: size: 8\n",
            " 9/19 [=============>................] - ETA: 1:37 - loss: 1.5758 - categorical_accuracy: 0.3194-----Batch10: size: 8\n",
            "10/19 [==============>...............] - ETA: 1:27 - loss: 1.5859 - categorical_accuracy: 0.3000-----Batch11: size: 8\n",
            "11/19 [================>.............] - ETA: 1:17 - loss: 1.5856 - categorical_accuracy: 0.2955-----Batch12: size: 8\n",
            "12/19 [=================>............] - ETA: 1:08 - loss: 1.5774 - categorical_accuracy: 0.3021-----Batch13: size: 8\n",
            "13/19 [===================>..........] - ETA: 58s - loss: 1.5773 - categorical_accuracy: 0.2981 -----Batch14: size: 8\n",
            "14/19 [=====================>........] - ETA: 49s - loss: 1.5729 - categorical_accuracy: 0.2946-----Batch15: size: 8\n",
            "15/19 [======================>.......] - ETA: 39s - loss: 1.5649 - categorical_accuracy: 0.3083-----Batch16: size: 8\n",
            "16/19 [========================>.....] - ETA: 29s - loss: 1.5689 - categorical_accuracy: 0.3047-----Batch17: size: 8\n",
            "17/19 [=========================>....] - ETA: 19s - loss: 1.5795 - categorical_accuracy: 0.2941-----last Batch size: 6\n",
            "18/19 [===========================>..] - ETA: 9s - loss: 1.5756 - categorical_accuracy: 0.2986 -----Batch0: size: 8\n",
            "19/19 [==============================] - ETA: 0s - loss: 1.5786 - categorical_accuracy: 0.2933-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "\n",
            "Epoch 00004: saving model to model_init_2021-12-2816_24_42.038728\\model-00004-1.57858-0.29333-1.56129-0.27000.h5\n",
            "19/19 [==============================] - 247s 13s/step - loss: 1.5786 - categorical_accuracy: 0.2933 - val_loss: 1.5613 - val_categorical_accuracy: 0.2700 - lr: 1.0000e-04\n",
            "Epoch 5/5\n",
            "-----Batch1: size: 8\n",
            " 1/19 [>.............................] - ETA: 3:00 - loss: 1.5904 - categorical_accuracy: 0.2500-----Batch2: size: 8\n",
            " 2/19 [==>...........................] - ETA: 2:43 - loss: 1.5769 - categorical_accuracy: 0.1875-----Batch3: size: 8\n",
            " 3/19 [===>..........................] - ETA: 2:34 - loss: 1.5640 - categorical_accuracy: 0.2083-----Batch4: size: 8\n",
            " 4/19 [=====>........................] - ETA: 2:25 - loss: 1.5282 - categorical_accuracy: 0.3125-----Batch5: size: 8\n",
            " 5/19 [======>.......................] - ETA: 2:15 - loss: 1.5295 - categorical_accuracy: 0.3000-----Batch6: size: 8\n",
            " 6/19 [========>.....................] - ETA: 2:05 - loss: 1.5182 - categorical_accuracy: 0.3333-----Batch7: size: 8\n",
            " 7/19 [==========>...................] - ETA: 1:56 - loss: 1.5043 - categorical_accuracy: 0.3393-----Batch8: size: 8\n",
            " 8/19 [===========>..................] - ETA: 1:46 - loss: 1.5073 - categorical_accuracy: 0.3125-----Batch9: size: 8\n",
            " 9/19 [=============>................] - ETA: 1:36 - loss: 1.5024 - categorical_accuracy: 0.3333-----Batch10: size: 8\n",
            "10/19 [==============>...............] - ETA: 1:27 - loss: 1.5046 - categorical_accuracy: 0.3250-----Batch11: size: 8\n",
            "11/19 [================>.............] - ETA: 1:17 - loss: 1.5121 - categorical_accuracy: 0.3068-----Batch12: size: 8\n",
            "12/19 [=================>............] - ETA: 1:08 - loss: 1.5188 - categorical_accuracy: 0.2812-----Batch13: size: 8\n",
            "13/19 [===================>..........] - ETA: 58s - loss: 1.5364 - categorical_accuracy: 0.2596 -----Batch14: size: 8\n",
            "14/19 [=====================>........] - ETA: 48s - loss: 1.5465 - categorical_accuracy: 0.2500-----Batch15: size: 8\n",
            "15/19 [======================>.......] - ETA: 39s - loss: 1.5378 - categorical_accuracy: 0.2667-----Batch16: size: 8\n",
            "16/19 [========================>.....] - ETA: 29s - loss: 1.5270 - categorical_accuracy: 0.2812-----Batch17: size: 8\n",
            "17/19 [=========================>....] - ETA: 19s - loss: 1.5211 - categorical_accuracy: 0.2941-----last Batch size: 6\n",
            "18/19 [===========================>..] - ETA: 9s - loss: 1.5209 - categorical_accuracy: 0.3056 -----Batch0: size: 8\n",
            "19/19 [==============================] - ETA: 0s - loss: 1.5203 - categorical_accuracy: 0.3067-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "\n",
            "Epoch 00005: saving model to model_init_2021-12-2816_24_42.038728\\model-00005-1.52035-0.30667-1.54602-0.31000.h5\n",
            "19/19 [==============================] - 246s 13s/step - loss: 1.5203 - categorical_accuracy: 0.3067 - val_loss: 1.5460 - val_categorical_accuracy: 0.3100 - lr: 1.0000e-04\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1eea9d04df0>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## ABLATION\n",
        "# Let's use a learning rate of 0.0001 to improve learning\n",
        "num_epochs = 8\n",
        "train_generator,val_generator,steps_per_epoch,validation_steps = sample_set(8,150,(180,180))\n",
        "callbacks_list = save_model('categorical_accuracy')\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.0001) \n",
        "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['categorical_accuracy'])\n",
        "model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "                    callbacks=callbacks_list, validation_data=val_generator, \n",
        "                    validation_steps=validation_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ua8_vT5grcyK"
      },
      "source": [
        "Observations:\n",
        "- Model doesn't seem to overfit easily on the sample data. Let's try to increase the ResNet layers to be retrained from 10 to last 20 layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZxdoFyDrcyK"
      },
      "source": [
        "#### Model#4: ResNet layers to be retrained: last 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0Ut2Rd3rcyK"
      },
      "outputs": [],
      "source": [
        "## model 4\n",
        "def res_cnn_1():\n",
        "    resnet = ResNet50(include_top=False,weights='imagenet',input_shape=(180,180,3))\n",
        "    for layer in resnet.layers[:-20]:\n",
        "        layer.trainable=False\n",
        "    cnn =Sequential([resnet])\n",
        "    cnn.add(Conv2D(64,(2,2),strides=(1,1)))\n",
        "    cnn.add(Conv2D(128,(2,2),strides=(1,1)))\n",
        "    cnn.add(Conv2D(128,(2,2), strides= (1,1)))\n",
        "    cnn.add(Conv2D(128,(2,2), strides= (1,1)))\n",
        "    cnn.add(Flatten())\n",
        "    model = Sequential()\n",
        "    model.add(TimeDistributed(cnn,input_shape=(15,180,180,3)))\n",
        "    model.add(GRU(32,input_shape=(None,15,512),return_sequences=True))\n",
        "    model.add(GRU(16))\n",
        "    model.add(Dense(5,activation='softmax'))\n",
        "    print(model.summary())\n",
        "    return(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJFT8MUUrcyK",
        "outputId": "cfc0f8e6-7e99-4ed1-f529-f4c16e9527bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " time_distributed (TimeDistr  (None, 15, 512)          24276288  \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 15, 32)            52416     \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 16)                2400      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5)                 85        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,331,189\n",
            "Trainable params: 9,674,805\n",
            "Non-trainable params: 14,656,384\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model = res_cnn_1()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7OSZ8lwrcyL",
        "outputId": "cf8bd89b-349a-4e9d-99e0-003a14db8f39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_train_sequences:150, num_val_sequences:100, steps_per_epoch:19, validation_steps:13\n",
            "-----Batch0: size: 8\n",
            "Epoch 1/5\n",
            "-----Batch1: size: 8\n",
            " 1/19 [>.............................] - ETA: 4:52 - loss: 1.5806 - categorical_accuracy: 0.5000-----Batch2: size: 8\n",
            " 2/19 [==>...........................] - ETA: 2:58 - loss: 1.8425 - categorical_accuracy: 0.3125-----Batch3: size: 8\n",
            " 3/19 [===>..........................] - ETA: 2:47 - loss: 1.7360 - categorical_accuracy: 0.3333-----Batch4: size: 8\n",
            " 4/19 [=====>........................] - ETA: 2:38 - loss: 1.7685 - categorical_accuracy: 0.2500-----Batch5: size: 8\n",
            " 5/19 [======>.......................] - ETA: 2:28 - loss: 1.7908 - categorical_accuracy: 0.2250-----Batch6: size: 8\n",
            " 6/19 [========>.....................] - ETA: 2:17 - loss: 1.7562 - categorical_accuracy: 0.2708-----Batch7: size: 8\n",
            " 7/19 [==========>...................] - ETA: 2:07 - loss: 1.7556 - categorical_accuracy: 0.2500-----Batch8: size: 8\n",
            " 8/19 [===========>..................] - ETA: 1:56 - loss: 1.7129 - categorical_accuracy: 0.2812-----Batch9: size: 8\n",
            " 9/19 [=============>................] - ETA: 1:45 - loss: 1.6996 - categorical_accuracy: 0.2778-----Batch10: size: 8\n",
            "10/19 [==============>...............] - ETA: 1:35 - loss: 1.7027 - categorical_accuracy: 0.2750-----Batch11: size: 8\n",
            "11/19 [================>.............] - ETA: 1:24 - loss: 1.6948 - categorical_accuracy: 0.2727-----Batch12: size: 8\n",
            "12/19 [=================>............] - ETA: 1:14 - loss: 1.6755 - categorical_accuracy: 0.2812-----Batch13: size: 8\n",
            "13/19 [===================>..........] - ETA: 1:03 - loss: 1.6795 - categorical_accuracy: 0.2692-----Batch14: size: 8\n",
            "14/19 [=====================>........] - ETA: 52s - loss: 1.6751 - categorical_accuracy: 0.2679 -----Batch15: size: 8\n",
            "15/19 [======================>.......] - ETA: 42s - loss: 1.6785 - categorical_accuracy: 0.2583-----Batch16: size: 8\n",
            "16/19 [========================>.....] - ETA: 31s - loss: 1.6726 - categorical_accuracy: 0.2656-----Batch17: size: 8\n",
            "17/19 [=========================>....] - ETA: 21s - loss: 1.6725 - categorical_accuracy: 0.2574-----last Batch size: 6\n",
            "18/19 [===========================>..] - ETA: 10s - loss: 1.6709 - categorical_accuracy: 0.2569-----Batch0: size: 8\n",
            "19/19 [==============================] - ETA: 0s - loss: 1.6649 - categorical_accuracy: 0.2600 -----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "\n",
            "Epoch 00001: saving model to model_init_2021-12-2816_49_59.228771\\model-00001-1.66494-0.26000-1.68490-0.24000.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\veena\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19/19 [==============================] - 268s 14s/step - loss: 1.6649 - categorical_accuracy: 0.2600 - val_loss: 1.6849 - val_categorical_accuracy: 0.2400 - lr: 1.0000e-04\n",
            "Epoch 2/5\n",
            "-----Batch1: size: 8\n",
            " 1/19 [>.............................] - ETA: 3:10 - loss: 1.5646 - categorical_accuracy: 0.3750-----Batch2: size: 8\n",
            " 2/19 [==>...........................] - ETA: 3:03 - loss: 1.6758 - categorical_accuracy: 0.2500-----Batch3: size: 8\n",
            " 3/19 [===>..........................] - ETA: 2:51 - loss: 1.6225 - categorical_accuracy: 0.2083-----Batch4: size: 8\n",
            " 4/19 [=====>........................] - ETA: 2:39 - loss: 1.6009 - categorical_accuracy: 0.2500-----Batch5: size: 8\n",
            " 5/19 [======>.......................] - ETA: 2:29 - loss: 1.5840 - categorical_accuracy: 0.2750-----Batch6: size: 8\n",
            " 6/19 [========>.....................] - ETA: 2:18 - loss: 1.5734 - categorical_accuracy: 0.2708-----Batch7: size: 8\n",
            " 7/19 [==========>...................] - ETA: 2:07 - loss: 1.5425 - categorical_accuracy: 0.3393-----Batch8: size: 8\n",
            " 8/19 [===========>..................] - ETA: 1:56 - loss: 1.5308 - categorical_accuracy: 0.3594-----Batch9: size: 8\n",
            " 9/19 [=============>................] - ETA: 1:45 - loss: 1.5972 - categorical_accuracy: 0.3194-----Batch10: size: 8\n",
            "10/19 [==============>...............] - ETA: 1:35 - loss: 1.5725 - categorical_accuracy: 0.3500-----Batch11: size: 8\n",
            "11/19 [================>.............] - ETA: 1:24 - loss: 1.5617 - categorical_accuracy: 0.3523-----Batch12: size: 8\n",
            "12/19 [=================>............] - ETA: 1:14 - loss: 1.5787 - categorical_accuracy: 0.3438-----Batch13: size: 8\n",
            "13/19 [===================>..........] - ETA: 1:03 - loss: 1.6065 - categorical_accuracy: 0.3173-----Batch14: size: 8\n",
            "14/19 [=====================>........] - ETA: 53s - loss: 1.6295 - categorical_accuracy: 0.3036 -----Batch15: size: 8\n",
            "15/19 [======================>.......] - ETA: 42s - loss: 1.6288 - categorical_accuracy: 0.3000-----Batch16: size: 8\n",
            "16/19 [========================>.....] - ETA: 31s - loss: 1.6398 - categorical_accuracy: 0.2812-----Batch17: size: 8\n",
            "17/19 [=========================>....] - ETA: 21s - loss: 1.6383 - categorical_accuracy: 0.2721-----last Batch size: 6\n",
            "18/19 [===========================>..] - ETA: 10s - loss: 1.6370 - categorical_accuracy: 0.2708-----Batch0: size: 8\n",
            "19/19 [==============================] - ETA: 0s - loss: 1.6362 - categorical_accuracy: 0.2667 -----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "\n",
            "Epoch 00002: saving model to model_init_2021-12-2816_49_59.228771\\model-00002-1.63618-0.26667-1.65127-0.16000.h5\n",
            "19/19 [==============================] - 261s 14s/step - loss: 1.6362 - categorical_accuracy: 0.2667 - val_loss: 1.6513 - val_categorical_accuracy: 0.1600 - lr: 1.0000e-04\n",
            "Epoch 3/5\n",
            "-----Batch1: size: 8\n",
            " 1/19 [>.............................] - ETA: 3:11 - loss: 1.6449 - categorical_accuracy: 0.1250-----Batch2: size: 8\n",
            " 2/19 [==>...........................] - ETA: 3:01 - loss: 1.6449 - categorical_accuracy: 0.1250-----Batch3: size: 8\n",
            " 3/19 [===>..........................] - ETA: 2:49 - loss: 1.5677 - categorical_accuracy: 0.2500-----Batch4: size: 8\n",
            " 4/19 [=====>........................] - ETA: 2:38 - loss: 1.5291 - categorical_accuracy: 0.2812-----Batch5: size: 8\n",
            " 5/19 [======>.......................] - ETA: 2:27 - loss: 1.5077 - categorical_accuracy: 0.3000-----Batch6: size: 8\n",
            " 6/19 [========>.....................] - ETA: 2:17 - loss: 1.5122 - categorical_accuracy: 0.2708-----Batch7: size: 8\n",
            " 7/19 [==========>...................] - ETA: 2:06 - loss: 1.4900 - categorical_accuracy: 0.3214-----Batch8: size: 8\n",
            " 8/19 [===========>..................] - ETA: 1:56 - loss: 1.4957 - categorical_accuracy: 0.2969-----Batch9: size: 8\n",
            " 9/19 [=============>................] - ETA: 1:46 - loss: 1.5356 - categorical_accuracy: 0.2778-----Batch10: size: 8\n",
            "10/19 [==============>...............] - ETA: 1:35 - loss: 1.5483 - categorical_accuracy: 0.2750-----Batch11: size: 8\n",
            "11/19 [================>.............] - ETA: 1:25 - loss: 1.5427 - categorical_accuracy: 0.2727-----Batch12: size: 8\n",
            "12/19 [=================>............] - ETA: 1:14 - loss: 1.5400 - categorical_accuracy: 0.2708-----Batch13: size: 8\n",
            "13/19 [===================>..........] - ETA: 1:03 - loss: 1.5433 - categorical_accuracy: 0.2692-----Batch14: size: 8\n",
            "14/19 [=====================>........] - ETA: 53s - loss: 1.5423 - categorical_accuracy: 0.2679 -----Batch15: size: 8\n",
            "15/19 [======================>.......] - ETA: 42s - loss: 1.5555 - categorical_accuracy: 0.2500-----Batch16: size: 8\n",
            "16/19 [========================>.....] - ETA: 31s - loss: 1.5582 - categorical_accuracy: 0.2656-----Batch17: size: 8\n",
            "17/19 [=========================>....] - ETA: 21s - loss: 1.5569 - categorical_accuracy: 0.2574-----last Batch size: 6\n",
            "18/19 [===========================>..] - ETA: 10s - loss: 1.5595 - categorical_accuracy: 0.2431-----Batch0: size: 8\n",
            "19/19 [==============================] - ETA: 0s - loss: 1.5520 - categorical_accuracy: 0.2400 -----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "\n",
            "Epoch 00003: saving model to model_init_2021-12-2816_49_59.228771\\model-00003-1.55201-0.24000-1.66878-0.15000.h5\n",
            "19/19 [==============================] - 261s 14s/step - loss: 1.5520 - categorical_accuracy: 0.2400 - val_loss: 1.6688 - val_categorical_accuracy: 0.1500 - lr: 1.0000e-04\n",
            "Epoch 4/5\n",
            "-----Batch1: size: 8\n",
            " 1/19 [>.............................] - ETA: 3:05 - loss: 1.4408 - categorical_accuracy: 0.2500-----Batch2: size: 8\n",
            " 2/19 [==>...........................] - ETA: 2:59 - loss: 1.4957 - categorical_accuracy: 0.3125-----Batch3: size: 8\n",
            " 3/19 [===>..........................] - ETA: 2:50 - loss: 1.5384 - categorical_accuracy: 0.3750-----Batch4: size: 8\n",
            " 4/19 [=====>........................] - ETA: 2:40 - loss: 1.5537 - categorical_accuracy: 0.3438-----Batch5: size: 8\n",
            " 5/19 [======>.......................] - ETA: 2:32 - loss: 1.5313 - categorical_accuracy: 0.3750-----Batch6: size: 8\n",
            " 6/19 [========>.....................] - ETA: 2:22 - loss: 1.5105 - categorical_accuracy: 0.3958-----Batch7: size: 8\n",
            " 7/19 [==========>...................] - ETA: 2:12 - loss: 1.5315 - categorical_accuracy: 0.3393-----Batch8: size: 8\n",
            " 8/19 [===========>..................] - ETA: 2:00 - loss: 1.5252 - categorical_accuracy: 0.3594-----Batch9: size: 8\n",
            " 9/19 [=============>................] - ETA: 1:49 - loss: 1.5057 - categorical_accuracy: 0.3611-----Batch10: size: 8\n",
            "10/19 [==============>...............] - ETA: 1:38 - loss: 1.5004 - categorical_accuracy: 0.3500-----Batch11: size: 8\n",
            "11/19 [================>.............] - ETA: 1:27 - loss: 1.4913 - categorical_accuracy: 0.3636-----Batch12: size: 8\n",
            "12/19 [=================>............] - ETA: 1:16 - loss: 1.5023 - categorical_accuracy: 0.3542-----Batch13: size: 8\n",
            "13/19 [===================>..........] - ETA: 1:05 - loss: 1.4975 - categorical_accuracy: 0.3558-----Batch14: size: 8\n",
            "14/19 [=====================>........] - ETA: 54s - loss: 1.5227 - categorical_accuracy: 0.3304 -----Batch15: size: 8\n",
            "15/19 [======================>.......] - ETA: 43s - loss: 1.5189 - categorical_accuracy: 0.3333-----Batch16: size: 8\n",
            "16/19 [========================>.....] - ETA: 32s - loss: 1.5156 - categorical_accuracy: 0.3281-----Batch17: size: 8\n",
            "17/19 [=========================>....] - ETA: 21s - loss: 1.5198 - categorical_accuracy: 0.3235-----last Batch size: 6\n",
            "18/19 [===========================>..] - ETA: 10s - loss: 1.5212 - categorical_accuracy: 0.3194-----Batch0: size: 8\n",
            "19/19 [==============================] - ETA: 0s - loss: 1.5237 - categorical_accuracy: 0.3133 -----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "\n",
            "Epoch 00004: saving model to model_init_2021-12-2816_49_59.228771\\model-00004-1.52374-0.31333-1.66005-0.17000.h5\n",
            "19/19 [==============================] - 265s 14s/step - loss: 1.5237 - categorical_accuracy: 0.3133 - val_loss: 1.6601 - val_categorical_accuracy: 0.1700 - lr: 1.0000e-04\n",
            "Epoch 5/5\n",
            "-----Batch1: size: 8\n",
            " 1/19 [>.............................] - ETA: 3:11 - loss: 1.4084 - categorical_accuracy: 0.6250-----Batch2: size: 8\n",
            " 2/19 [==>...........................] - ETA: 3:00 - loss: 1.3761 - categorical_accuracy: 0.6250-----Batch3: size: 8\n",
            " 3/19 [===>..........................] - ETA: 2:50 - loss: 1.3657 - categorical_accuracy: 0.5833-----Batch4: size: 8\n",
            " 4/19 [=====>........................] - ETA: 2:39 - loss: 1.4901 - categorical_accuracy: 0.4688-----Batch5: size: 8\n",
            " 5/19 [======>.......................] - ETA: 2:28 - loss: 1.5316 - categorical_accuracy: 0.4250-----Batch6: size: 8\n",
            " 6/19 [========>.....................] - ETA: 2:18 - loss: 1.5244 - categorical_accuracy: 0.4583-----Batch7: size: 8\n",
            " 7/19 [==========>...................] - ETA: 2:07 - loss: 1.5192 - categorical_accuracy: 0.4643-----Batch8: size: 8\n",
            " 8/19 [===========>..................] - ETA: 1:57 - loss: 1.5085 - categorical_accuracy: 0.4531-----Batch9: size: 8\n",
            " 9/19 [=============>................] - ETA: 1:46 - loss: 1.4928 - categorical_accuracy: 0.4583-----Batch10: size: 8\n",
            "10/19 [==============>...............] - ETA: 1:36 - loss: 1.5105 - categorical_accuracy: 0.4375-----Batch11: size: 8\n",
            "11/19 [================>.............] - ETA: 1:25 - loss: 1.4985 - categorical_accuracy: 0.4318-----Batch12: size: 8\n",
            "12/19 [=================>............] - ETA: 1:15 - loss: 1.5091 - categorical_accuracy: 0.4167-----Batch13: size: 8\n",
            "13/19 [===================>..........] - ETA: 1:04 - loss: 1.5132 - categorical_accuracy: 0.3846-----Batch14: size: 8\n",
            "14/19 [=====================>........] - ETA: 53s - loss: 1.5037 - categorical_accuracy: 0.3929 -----Batch15: size: 8\n",
            "15/19 [======================>.......] - ETA: 42s - loss: 1.4920 - categorical_accuracy: 0.3917-----Batch16: size: 8\n",
            "16/19 [========================>.....] - ETA: 32s - loss: 1.4931 - categorical_accuracy: 0.3906-----Batch17: size: 8\n",
            "17/19 [=========================>....] - ETA: 21s - loss: 1.4998 - categorical_accuracy: 0.3750-----last Batch size: 6\n",
            "18/19 [===========================>..] - ETA: 10s - loss: 1.5099 - categorical_accuracy: 0.3750-----Batch0: size: 8\n",
            "19/19 [==============================] - ETA: 0s - loss: 1.5163 - categorical_accuracy: 0.3667 -----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "\n",
            "Epoch 00005: saving model to model_init_2021-12-2816_49_59.228771\\model-00005-1.51630-0.36667-1.59482-0.17000.h5\n",
            "19/19 [==============================] - 266s 14s/step - loss: 1.5163 - categorical_accuracy: 0.3667 - val_loss: 1.5948 - val_categorical_accuracy: 0.1700 - lr: 1.0000e-04\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1ee8e6efee0>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## ABLATION\n",
        "num_epochs = 5\n",
        "train_generator,val_generator,steps_per_epoch,validation_steps = sample_set(8,150,(180,180))\n",
        "callbacks_list = save_model('categorical_accuracy')\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.0001) \n",
        "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['categorical_accuracy'])\n",
        "model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "                    callbacks=callbacks_list, validation_data=val_generator, \n",
        "                    validation_steps=validation_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUBCTAz6rcyL"
      },
      "source": [
        "Observations:\n",
        "- model seems to be learning progressively over the epochs and shows symptoms of overfitting. So, let's try to perform complete training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mYLWJMIrcyL",
        "outputId": "9d215aa2-00c7-4609-c6c7-25274f771328"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_train_sequences:663, num_val_sequences:100, steps_per_epoch:34, validation_steps:5\n",
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " time_distributed_21 (TimeDi  (None, 15, 512)          24276288  \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " gru_17 (GRU)                (None, 15, 32)            52416     \n",
            "                                                                 \n",
            " gru_18 (GRU)                (None, 16)                2400      \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 5)                 85        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,331,189\n",
            "Trainable params: 9,674,805\n",
            "Non-trainable params: 14,656,384\n",
            "_________________________________________________________________\n",
            "None\n",
            "-----Batch0: size: 20\n",
            "Epoch 1/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 17:46 - loss: 1.8354 - categorical_accuracy: 0.2000-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 14:40 - loss: 1.7482 - categorical_accuracy: 0.2000-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 14:02 - loss: 1.7581 - categorical_accuracy: 0.1833-----Batch4: size: 20\n",
            " 4/34 [==>...........................] - ETA: 13:30 - loss: 1.7656 - categorical_accuracy: 0.1750-----Batch5: size: 20\n",
            " 5/34 [===>..........................] - ETA: 13:03 - loss: 1.7556 - categorical_accuracy: 0.1500-----Batch6: size: 20\n",
            " 6/34 [====>.........................] - ETA: 12:37 - loss: 1.7300 - categorical_accuracy: 0.1667-----Batch7: size: 20\n",
            " 7/34 [=====>........................] - ETA: 12:08 - loss: 1.7192 - categorical_accuracy: 0.1571-----Batch8: size: 20\n",
            " 8/34 [======>.......................] - ETA: 11:39 - loss: 1.7116 - categorical_accuracy: 0.1562-----Batch9: size: 20\n",
            " 9/34 [======>.......................] - ETA: 11:09 - loss: 1.7017 - categorical_accuracy: 0.1778-----Batch10: size: 20\n",
            "10/34 [=======>......................] - ETA: 10:43 - loss: 1.6917 - categorical_accuracy: 0.1950-----Batch11: size: 20\n",
            "11/34 [========>.....................] - ETA: 10:19 - loss: 1.6841 - categorical_accuracy: 0.2000-----Batch12: size: 20\n",
            "12/34 [=========>....................] - ETA: 9:51 - loss: 1.6775 - categorical_accuracy: 0.2042 -----Batch13: size: 20\n",
            "13/34 [==========>...................] - ETA: 9:23 - loss: 1.6757 - categorical_accuracy: 0.2000-----Batch14: size: 20\n",
            "14/34 [===========>..................] - ETA: 8:56 - loss: 1.6713 - categorical_accuracy: 0.2000-----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 8:30 - loss: 1.6654 - categorical_accuracy: 0.2067-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 8:03 - loss: 1.6596 - categorical_accuracy: 0.2062-----Batch17: size: 20\n",
            "17/34 [==============>...............] - ETA: 7:35 - loss: 1.6545 - categorical_accuracy: 0.2059-----Batch18: size: 20\n",
            "18/34 [==============>...............] - ETA: 7:09 - loss: 1.6510 - categorical_accuracy: 0.2083-----Batch19: size: 20\n",
            "19/34 [===============>..............] - ETA: 6:43 - loss: 1.6465 - categorical_accuracy: 0.2105-----Batch20: size: 20\n",
            "20/34 [================>.............] - ETA: 6:16 - loss: 1.6429 - categorical_accuracy: 0.2175-----Batch21: size: 20\n",
            "21/34 [=================>............] - ETA: 5:49 - loss: 1.6433 - categorical_accuracy: 0.2167-----Batch22: size: 20\n",
            "22/34 [==================>...........] - ETA: 5:22 - loss: 1.6427 - categorical_accuracy: 0.2136-----Batch23: size: 20\n",
            "23/34 [===================>..........] - ETA: 4:55 - loss: 1.6408 - categorical_accuracy: 0.2174-----Batch24: size: 20\n",
            "24/34 [====================>.........] - ETA: 4:28 - loss: 1.6389 - categorical_accuracy: 0.2229-----Batch25: size: 20\n",
            "25/34 [=====================>........] - ETA: 4:01 - loss: 1.6380 - categorical_accuracy: 0.2200-----Batch26: size: 20\n",
            "26/34 [=====================>........] - ETA: 3:34 - loss: 1.6377 - categorical_accuracy: 0.2154-----Batch27: size: 20\n",
            "27/34 [======================>.......] - ETA: 3:08 - loss: 1.6340 - categorical_accuracy: 0.2204-----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 2:41 - loss: 1.6343 - categorical_accuracy: 0.2161-----Batch29: size: 20\n",
            "29/34 [========================>.....] - ETA: 2:14 - loss: 1.6333 - categorical_accuracy: 0.2155-----Batch30: size: 20\n",
            "30/34 [=========================>....] - ETA: 1:47 - loss: 1.6287 - categorical_accuracy: 0.2233-----Batch31: size: 20\n",
            "31/34 [==========================>...] - ETA: 1:20 - loss: 1.6269 - categorical_accuracy: 0.2242-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 53s - loss: 1.6262 - categorical_accuracy: 0.2219 -----last Batch size: 3\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.6219 - categorical_accuracy: 0.2293 -----Batch0: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "\n",
            "Epoch 00001: saving model to model_init_2021-12-2817_15_33.974604\\model-00001-1.62195-0.22926-1.62280-0.18000.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\veena\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34/34 [==============================] - 963s 28s/step - loss: 1.6219 - categorical_accuracy: 0.2293 - val_loss: 1.6228 - val_categorical_accuracy: 0.1800 - lr: 1.0000e-04\n",
            "Epoch 2/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 14:51 - loss: 1.6106 - categorical_accuracy: 0.2000-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 15:53 - loss: 1.5515 - categorical_accuracy: 0.2750-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 14:37 - loss: 1.5767 - categorical_accuracy: 0.2167-----Batch4: size: 20\n",
            " 4/34 [==>...........................] - ETA: 13:51 - loss: 1.5720 - categorical_accuracy: 0.2125-----Batch5: size: 20\n",
            " 5/34 [===>..........................] - ETA: 13:14 - loss: 1.5622 - categorical_accuracy: 0.2300-----Batch6: size: 20\n",
            " 6/34 [====>.........................] - ETA: 12:46 - loss: 1.5766 - categorical_accuracy: 0.2167-----Batch7: size: 20\n",
            " 7/34 [=====>........................] - ETA: 12:17 - loss: 1.5735 - categorical_accuracy: 0.2286-----Batch8: size: 20\n",
            " 8/34 [======>.......................] - ETA: 11:46 - loss: 1.5888 - categorical_accuracy: 0.2188-----Batch9: size: 20\n",
            " 9/34 [======>.......................] - ETA: 11:19 - loss: 1.5915 - categorical_accuracy: 0.2333-----Batch10: size: 20\n",
            "10/34 [=======>......................] - ETA: 10:50 - loss: 1.5900 - categorical_accuracy: 0.2450-----Batch11: size: 20\n",
            "11/34 [========>.....................] - ETA: 10:24 - loss: 1.5892 - categorical_accuracy: 0.2409-----Batch12: size: 20\n",
            "12/34 [=========>....................] - ETA: 9:56 - loss: 1.5979 - categorical_accuracy: 0.2333 -----Batch13: size: 20\n",
            "13/34 [==========>...................] - ETA: 9:28 - loss: 1.5989 - categorical_accuracy: 0.2231-----Batch14: size: 20\n",
            "14/34 [===========>..................] - ETA: 9:00 - loss: 1.6019 - categorical_accuracy: 0.2214-----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 8:33 - loss: 1.5984 - categorical_accuracy: 0.2167-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 8:06 - loss: 1.5960 - categorical_accuracy: 0.2313-----Batch17: size: 20\n",
            "17/34 [==============>...............] - ETA: 7:38 - loss: 1.5969 - categorical_accuracy: 0.2324-----Batch18: size: 20\n",
            "18/34 [==============>...............] - ETA: 7:10 - loss: 1.5935 - categorical_accuracy: 0.2444-----Batch19: size: 20\n",
            "19/34 [===============>..............] - ETA: 6:43 - loss: 1.5935 - categorical_accuracy: 0.2368-----Batch20: size: 20\n",
            "20/34 [================>.............] - ETA: 6:17 - loss: 1.5947 - categorical_accuracy: 0.2325-----Batch21: size: 20\n",
            "21/34 [=================>............] - ETA: 5:50 - loss: 1.5988 - categorical_accuracy: 0.2333-----Batch22: size: 20\n",
            "22/34 [==================>...........] - ETA: 5:22 - loss: 1.5973 - categorical_accuracy: 0.2295-----Batch23: size: 20\n",
            "23/34 [===================>..........] - ETA: 4:55 - loss: 1.5993 - categorical_accuracy: 0.2326-----Batch24: size: 20\n",
            "24/34 [====================>.........] - ETA: 4:29 - loss: 1.5970 - categorical_accuracy: 0.2417-----Batch25: size: 20\n",
            "25/34 [=====================>........] - ETA: 4:02 - loss: 1.5965 - categorical_accuracy: 0.2440-----Batch26: size: 20\n",
            "26/34 [=====================>........] - ETA: 3:35 - loss: 1.5950 - categorical_accuracy: 0.2481-----Batch27: size: 20\n",
            "27/34 [======================>.......] - ETA: 3:08 - loss: 1.5943 - categorical_accuracy: 0.2500-----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 2:41 - loss: 1.5952 - categorical_accuracy: 0.2446-----Batch29: size: 20\n",
            "29/34 [========================>.....] - ETA: 2:14 - loss: 1.5955 - categorical_accuracy: 0.2466-----Batch30: size: 20\n",
            "30/34 [=========================>....] - ETA: 1:47 - loss: 1.5971 - categorical_accuracy: 0.2433-----Batch31: size: 20\n",
            "31/34 [==========================>...] - ETA: 1:20 - loss: 1.5955 - categorical_accuracy: 0.2452-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 53s - loss: 1.5962 - categorical_accuracy: 0.2438 -----last Batch size: 3\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5951 - categorical_accuracy: 0.2428 -----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "\n",
            "Epoch 00002: saving model to model_init_2021-12-2817_15_33.974604\\model-00002-1.59514-0.24284-1.60388-0.33000.h5\n",
            "34/34 [==============================] - 954s 28s/step - loss: 1.5951 - categorical_accuracy: 0.2428 - val_loss: 1.6039 - val_categorical_accuracy: 0.3300 - lr: 1.0000e-04\n",
            "Epoch 3/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 14:48 - loss: 1.5560 - categorical_accuracy: 0.3000-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 14:08 - loss: 1.5371 - categorical_accuracy: 0.3750-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 13:40 - loss: 1.5555 - categorical_accuracy: 0.3333-----Batch4: size: 20\n",
            " 4/34 [==>...........................] - ETA: 13:22 - loss: 1.5566 - categorical_accuracy: 0.3375-----Batch5: size: 20\n",
            " 5/34 [===>..........................] - ETA: 12:57 - loss: 1.5598 - categorical_accuracy: 0.3200-----Batch6: size: 20\n",
            " 6/34 [====>.........................] - ETA: 12:29 - loss: 1.5568 - categorical_accuracy: 0.3083-----Batch7: size: 20\n",
            " 7/34 [=====>........................] - ETA: 12:01 - loss: 1.5589 - categorical_accuracy: 0.2786-----Batch8: size: 20\n",
            " 8/34 [======>.......................] - ETA: 11:35 - loss: 1.5613 - categorical_accuracy: 0.2812-----Batch9: size: 20\n",
            " 9/34 [======>.......................] - ETA: 11:10 - loss: 1.5616 - categorical_accuracy: 0.2778-----Batch10: size: 20\n",
            "10/34 [=======>......................] - ETA: 10:43 - loss: 1.5621 - categorical_accuracy: 0.2700-----Batch11: size: 20\n",
            "11/34 [========>.....................] - ETA: 10:16 - loss: 1.5674 - categorical_accuracy: 0.2636-----Batch12: size: 20\n",
            "12/34 [=========>....................] - ETA: 9:48 - loss: 1.5647 - categorical_accuracy: 0.2708 -----Batch13: size: 20\n",
            "13/34 [==========>...................] - ETA: 9:25 - loss: 1.5672 - categorical_accuracy: 0.2731-----Batch14: size: 20\n",
            "14/34 [===========>..................] - ETA: 9:01 - loss: 1.5664 - categorical_accuracy: 0.2714-----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 8:34 - loss: 1.5654 - categorical_accuracy: 0.2767-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 8:06 - loss: 1.5666 - categorical_accuracy: 0.2750-----Batch17: size: 20\n",
            "17/34 [==============>...............] - ETA: 7:39 - loss: 1.5695 - categorical_accuracy: 0.2676-----Batch18: size: 20\n",
            "18/34 [==============>...............] - ETA: 7:13 - loss: 1.5693 - categorical_accuracy: 0.2694-----Batch19: size: 20\n",
            "19/34 [===============>..............] - ETA: 6:45 - loss: 1.5694 - categorical_accuracy: 0.2737-----Batch20: size: 20\n",
            "20/34 [================>.............] - ETA: 6:18 - loss: 1.5700 - categorical_accuracy: 0.2725-----Batch21: size: 20\n",
            "21/34 [=================>............] - ETA: 5:51 - loss: 1.5721 - categorical_accuracy: 0.2690-----Batch22: size: 20\n",
            "22/34 [==================>...........] - ETA: 5:24 - loss: 1.5676 - categorical_accuracy: 0.2727-----Batch23: size: 20\n",
            "23/34 [===================>..........] - ETA: 4:57 - loss: 1.5661 - categorical_accuracy: 0.2739-----Batch24: size: 20\n",
            "24/34 [====================>.........] - ETA: 4:30 - loss: 1.5656 - categorical_accuracy: 0.2812-----Batch25: size: 20\n",
            "25/34 [=====================>........] - ETA: 4:03 - loss: 1.5649 - categorical_accuracy: 0.2800-----Batch26: size: 20\n",
            "26/34 [=====================>........] - ETA: 3:36 - loss: 1.5621 - categorical_accuracy: 0.2788-----Batch27: size: 20\n",
            "27/34 [======================>.......] - ETA: 3:09 - loss: 1.5677 - categorical_accuracy: 0.2778-----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 2:41 - loss: 1.5650 - categorical_accuracy: 0.2750-----Batch29: size: 20\n",
            "29/34 [========================>.....] - ETA: 2:14 - loss: 1.5594 - categorical_accuracy: 0.2828-----Batch30: size: 20\n",
            "30/34 [=========================>....] - ETA: 1:47 - loss: 1.5638 - categorical_accuracy: 0.2783-----Batch31: size: 20\n",
            "31/34 [==========================>...] - ETA: 1:20 - loss: 1.5607 - categorical_accuracy: 0.2806-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 53s - loss: 1.5587 - categorical_accuracy: 0.2812 -----last Batch size: 3\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5584 - categorical_accuracy: 0.2790 -----Batch0: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "\n",
            "Epoch 00003: saving model to model_init_2021-12-2817_15_33.974604\\model-00003-1.55842-0.27903-1.59511-0.29000.h5\n",
            "34/34 [==============================] - 958s 28s/step - loss: 1.5584 - categorical_accuracy: 0.2790 - val_loss: 1.5951 - val_categorical_accuracy: 0.2900 - lr: 1.0000e-04\n",
            "Epoch 4/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 14:40 - loss: 1.5602 - categorical_accuracy: 0.4000-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 14:03 - loss: 1.5535 - categorical_accuracy: 0.4000-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 13:38 - loss: 1.5498 - categorical_accuracy: 0.4167-----Batch4: size: 20\n",
            " 4/34 [==>...........................] - ETA: 13:17 - loss: 1.5756 - categorical_accuracy: 0.3625-----Batch5: size: 20\n",
            " 5/34 [===>..........................] - ETA: 12:59 - loss: 1.5745 - categorical_accuracy: 0.3600-----Batch6: size: 20\n",
            " 6/34 [====>.........................] - ETA: 12:33 - loss: 1.5691 - categorical_accuracy: 0.3583-----Batch7: size: 20\n",
            " 7/34 [=====>........................] - ETA: 12:04 - loss: 1.5551 - categorical_accuracy: 0.3786-----Batch8: size: 20\n",
            " 8/34 [======>.......................] - ETA: 11:35 - loss: 1.5510 - categorical_accuracy: 0.3625-----Batch9: size: 20\n",
            " 9/34 [======>.......................] - ETA: 11:11 - loss: 1.5420 - categorical_accuracy: 0.3778-----Batch10: size: 20\n",
            "10/34 [=======>......................] - ETA: 10:44 - loss: 1.5321 - categorical_accuracy: 0.3750-----Batch11: size: 20\n",
            "11/34 [========>.....................] - ETA: 10:16 - loss: 1.5253 - categorical_accuracy: 0.3682-----Batch12: size: 20\n",
            "12/34 [=========>....................] - ETA: 9:49 - loss: 1.5215 - categorical_accuracy: 0.3833 -----Batch13: size: 20\n",
            "13/34 [==========>...................] - ETA: 9:23 - loss: 1.5252 - categorical_accuracy: 0.3692-----Batch14: size: 20\n",
            "14/34 [===========>..................] - ETA: 8:56 - loss: 1.5188 - categorical_accuracy: 0.3679-----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 8:29 - loss: 1.5283 - categorical_accuracy: 0.3533-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 8:02 - loss: 1.5281 - categorical_accuracy: 0.3469-----Batch17: size: 20\n",
            "17/34 [==============>...............] - ETA: 7:35 - loss: 1.5295 - categorical_accuracy: 0.3529-----Batch18: size: 20\n",
            "18/34 [==============>...............] - ETA: 7:09 - loss: 1.5355 - categorical_accuracy: 0.3333-----Batch19: size: 20\n",
            "19/34 [===============>..............] - ETA: 6:42 - loss: 1.5282 - categorical_accuracy: 0.3421-----Batch20: size: 20\n",
            "20/34 [================>.............] - ETA: 6:15 - loss: 1.5234 - categorical_accuracy: 0.3475-----Batch21: size: 20\n",
            "21/34 [=================>............] - ETA: 5:48 - loss: 1.5237 - categorical_accuracy: 0.3476-----Batch22: size: 20\n",
            "22/34 [==================>...........] - ETA: 5:22 - loss: 1.5185 - categorical_accuracy: 0.3500-----Batch23: size: 20\n",
            "23/34 [===================>..........] - ETA: 4:55 - loss: 1.5204 - categorical_accuracy: 0.3435-----Batch24: size: 20\n",
            "24/34 [====================>.........] - ETA: 4:28 - loss: 1.5194 - categorical_accuracy: 0.3479-----Batch25: size: 20\n",
            "25/34 [=====================>........] - ETA: 4:01 - loss: 1.5193 - categorical_accuracy: 0.3500-----Batch26: size: 20\n",
            "26/34 [=====================>........] - ETA: 3:34 - loss: 1.5178 - categorical_accuracy: 0.3481-----Batch27: size: 20\n",
            "27/34 [======================>.......] - ETA: 3:07 - loss: 1.5153 - categorical_accuracy: 0.3463-----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 2:41 - loss: 1.5170 - categorical_accuracy: 0.3411-----Batch29: size: 20\n",
            "29/34 [========================>.....] - ETA: 2:14 - loss: 1.5141 - categorical_accuracy: 0.3397-----Batch30: size: 20\n",
            "30/34 [=========================>....] - ETA: 1:47 - loss: 1.5094 - categorical_accuracy: 0.3433-----Batch31: size: 20\n",
            "31/34 [==========================>...] - ETA: 1:20 - loss: 1.5087 - categorical_accuracy: 0.3419-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 53s - loss: 1.5099 - categorical_accuracy: 0.3375 -----last Batch size: 3\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5104 - categorical_accuracy: 0.3379 -----Batch0: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "\n",
            "Epoch 00004: saving model to model_init_2021-12-2817_15_33.974604\\model-00004-1.51039-0.33786-1.46737-0.35000.h5\n",
            "34/34 [==============================] - 953s 28s/step - loss: 1.5104 - categorical_accuracy: 0.3379 - val_loss: 1.4674 - val_categorical_accuracy: 0.3500 - lr: 1.0000e-04\n",
            "Epoch 5/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 14:39 - loss: 1.4159 - categorical_accuracy: 0.4000-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 14:13 - loss: 1.4892 - categorical_accuracy: 0.2750-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 13:52 - loss: 1.4737 - categorical_accuracy: 0.2833-----Batch4: size: 20\n",
            " 4/34 [==>...........................] - ETA: 13:26 - loss: 1.4616 - categorical_accuracy: 0.3125-----Batch5: size: 20\n",
            " 5/34 [===>..........................] - ETA: 13:04 - loss: 1.4700 - categorical_accuracy: 0.3000-----Batch6: size: 20\n",
            " 6/34 [====>.........................] - ETA: 12:35 - loss: 1.4634 - categorical_accuracy: 0.2833-----Batch7: size: 20\n",
            " 7/34 [=====>........................] - ETA: 12:06 - loss: 1.4580 - categorical_accuracy: 0.3143-----Batch8: size: 20\n",
            " 8/34 [======>.......................] - ETA: 11:37 - loss: 1.4722 - categorical_accuracy: 0.3125-----Batch9: size: 20\n",
            " 9/34 [======>.......................] - ETA: 11:12 - loss: 1.4644 - categorical_accuracy: 0.3222-----Batch10: size: 20\n",
            "10/34 [=======>......................] - ETA: 10:45 - loss: 1.4729 - categorical_accuracy: 0.3350-----Batch11: size: 20\n",
            "11/34 [========>.....................] - ETA: 10:18 - loss: 1.4803 - categorical_accuracy: 0.3409-----Batch12: size: 20\n",
            "12/34 [=========>....................] - ETA: 9:50 - loss: 1.4682 - categorical_accuracy: 0.3542 -----Batch13: size: 20\n",
            "13/34 [==========>...................] - ETA: 9:23 - loss: 1.4564 - categorical_accuracy: 0.3731-----Batch14: size: 20\n",
            "14/34 [===========>..................] - ETA: 8:57 - loss: 1.4462 - categorical_accuracy: 0.3857-----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 8:30 - loss: 1.4520 - categorical_accuracy: 0.3733-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 8:03 - loss: 1.4529 - categorical_accuracy: 0.3812-----Batch17: size: 20\n",
            "17/34 [==============>...............] - ETA: 7:36 - loss: 1.4360 - categorical_accuracy: 0.3971-----Batch18: size: 20\n",
            "18/34 [==============>...............] - ETA: 7:10 - loss: 1.4532 - categorical_accuracy: 0.3889-----Batch19: size: 20\n",
            "19/34 [===============>..............] - ETA: 6:45 - loss: 1.4568 - categorical_accuracy: 0.3842-----Batch20: size: 20\n",
            "20/34 [================>.............] - ETA: 6:19 - loss: 1.4671 - categorical_accuracy: 0.3750-----Batch21: size: 20\n",
            "21/34 [=================>............] - ETA: 5:52 - loss: 1.4613 - categorical_accuracy: 0.3786-----Batch22: size: 20\n",
            "22/34 [==================>...........] - ETA: 5:25 - loss: 1.4576 - categorical_accuracy: 0.3818-----Batch23: size: 20\n",
            "23/34 [===================>..........] - ETA: 4:58 - loss: 1.4528 - categorical_accuracy: 0.3848-----Batch24: size: 20\n",
            "24/34 [====================>.........] - ETA: 4:31 - loss: 1.4433 - categorical_accuracy: 0.3917-----Batch25: size: 20\n",
            "25/34 [=====================>........] - ETA: 4:04 - loss: 1.4515 - categorical_accuracy: 0.3900-----Batch26: size: 20\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "26/34 [=====================>........] - ETA: 3:37 - loss: 1.4550 - categorical_accuracy: 0.3865-----Batch27: size: 20\n",
            "27/34 [======================>.......] - ETA: 3:10 - loss: 1.4559 - categorical_accuracy: 0.3870-----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 2:43 - loss: 1.4598 - categorical_accuracy: 0.3839-----Batch29: size: 20\n",
            "29/34 [========================>.....] - ETA: 2:16 - loss: 1.4602 - categorical_accuracy: 0.3862-----Batch30: size: 20\n",
            "30/34 [=========================>....] - ETA: 1:49 - loss: 1.4613 - categorical_accuracy: 0.3883-----Batch31: size: 20\n",
            "31/34 [==========================>...] - ETA: 1:22 - loss: 1.4588 - categorical_accuracy: 0.3887-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 54s - loss: 1.4552 - categorical_accuracy: 0.3922 -----last Batch size: 3\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.4489 - categorical_accuracy: 0.3967 -----Batch0: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "\n",
            "Epoch 00005: saving model to model_init_2021-12-2817_15_33.974604\\model-00005-1.44888-0.39668-1.58829-0.31000.h5\n",
            "34/34 [==============================] - 974s 29s/step - loss: 1.4489 - categorical_accuracy: 0.3967 - val_loss: 1.5883 - val_categorical_accuracy: 0.3100 - lr: 1.0000e-04\n",
            "Epoch 6/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 15:13 - loss: 1.3545 - categorical_accuracy: 0.4500-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 14:50 - loss: 1.3260 - categorical_accuracy: 0.4500-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 14:39 - loss: 1.3875 - categorical_accuracy: 0.4500-----Batch4: size: 20\n",
            " 4/34 [==>...........................] - ETA: 14:04 - loss: 1.3771 - categorical_accuracy: 0.4500-----Batch5: size: 20\n",
            " 5/34 [===>..........................] - ETA: 13:34 - loss: 1.3678 - categorical_accuracy: 0.4300-----Batch6: size: 20\n",
            " 6/34 [====>.........................] - ETA: 13:05 - loss: 1.3797 - categorical_accuracy: 0.4000-----Batch7: size: 20\n",
            " 7/34 [=====>........................] - ETA: 12:35 - loss: 1.4011 - categorical_accuracy: 0.3571-----Batch8: size: 20\n",
            " 8/34 [======>.......................] - ETA: 12:06 - loss: 1.3889 - categorical_accuracy: 0.3688-----Batch9: size: 20\n",
            " 9/34 [======>.......................] - ETA: 11:38 - loss: 1.4013 - categorical_accuracy: 0.3556-----Batch10: size: 20\n",
            "10/34 [=======>......................] - ETA: 11:09 - loss: 1.4099 - categorical_accuracy: 0.3600-----Batch11: size: 20\n",
            "11/34 [========>.....................] - ETA: 10:41 - loss: 1.3900 - categorical_accuracy: 0.3818-----Batch12: size: 20\n",
            "12/34 [=========>....................] - ETA: 10:12 - loss: 1.3800 - categorical_accuracy: 0.4000-----Batch13: size: 20\n",
            "13/34 [==========>...................] - ETA: 9:44 - loss: 1.3742 - categorical_accuracy: 0.4038 -----Batch14: size: 20\n",
            "14/34 [===========>..................] - ETA: 9:16 - loss: 1.3701 - categorical_accuracy: 0.4143-----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 8:48 - loss: 1.3754 - categorical_accuracy: 0.4067-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 8:20 - loss: 1.3749 - categorical_accuracy: 0.4125-----Batch17: size: 20\n",
            "17/34 [==============>...............] - ETA: 7:52 - loss: 1.3714 - categorical_accuracy: 0.4206-----Batch18: size: 20\n",
            "18/34 [==============>...............] - ETA: 7:24 - loss: 1.3696 - categorical_accuracy: 0.4194-----Batch19: size: 20\n",
            "19/34 [===============>..............] - ETA: 6:56 - loss: 1.3676 - categorical_accuracy: 0.4211-----Batch20: size: 20\n",
            "20/34 [================>.............] - ETA: 6:29 - loss: 1.3724 - categorical_accuracy: 0.4200-----Batch21: size: 20\n",
            "21/34 [=================>............] - ETA: 6:01 - loss: 1.3753 - categorical_accuracy: 0.4167-----Batch22: size: 20\n",
            "22/34 [==================>...........] - ETA: 5:33 - loss: 1.3746 - categorical_accuracy: 0.4205-----Batch23: size: 20\n",
            "23/34 [===================>..........] - ETA: 5:05 - loss: 1.3682 - categorical_accuracy: 0.4261-----Batch24: size: 20\n",
            "24/34 [====================>.........] - ETA: 4:37 - loss: 1.3704 - categorical_accuracy: 0.4271-----Batch25: size: 20\n",
            "25/34 [=====================>........] - ETA: 4:10 - loss: 1.3769 - categorical_accuracy: 0.4240-----Batch26: size: 20\n",
            "26/34 [=====================>........] - ETA: 3:42 - loss: 1.3746 - categorical_accuracy: 0.4250-----Batch27: size: 20\n",
            "27/34 [======================>.......] - ETA: 3:14 - loss: 1.3728 - categorical_accuracy: 0.4241-----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 2:46 - loss: 1.3754 - categorical_accuracy: 0.4196-----Batch29: size: 20\n",
            "29/34 [========================>.....] - ETA: 2:18 - loss: 1.3827 - categorical_accuracy: 0.4138-----Batch30: size: 20\n",
            "30/34 [=========================>....] - ETA: 1:51 - loss: 1.3748 - categorical_accuracy: 0.4183-----Batch31: size: 20\n",
            "31/34 [==========================>...] - ETA: 1:23 - loss: 1.3705 - categorical_accuracy: 0.4210-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 55s - loss: 1.3659 - categorical_accuracy: 0.4234 -----last Batch size: 3\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.3699 - categorical_accuracy: 0.4178 -----Batch0: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "\n",
            "Epoch 00006: saving model to model_init_2021-12-2817_15_33.974604\\model-00006-1.36993-0.41780-1.46603-0.38000.h5\n",
            "34/34 [==============================] - 988s 29s/step - loss: 1.3699 - categorical_accuracy: 0.4178 - val_loss: 1.4660 - val_categorical_accuracy: 0.3800 - lr: 1.0000e-04\n",
            "Epoch 7/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 15:16 - loss: 1.3061 - categorical_accuracy: 0.5000-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 14:44 - loss: 1.1868 - categorical_accuracy: 0.6250-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 14:18 - loss: 1.1787 - categorical_accuracy: 0.5667-----Batch4: size: 20\n",
            " 4/34 [==>...........................] - ETA: 13:50 - loss: 1.2461 - categorical_accuracy: 0.5000-----Batch5: size: 20\n",
            " 5/34 [===>..........................] - ETA: 13:22 - loss: 1.2720 - categorical_accuracy: 0.4600-----Batch6: size: 20\n",
            " 6/34 [====>.........................] - ETA: 12:54 - loss: 1.3188 - categorical_accuracy: 0.4333-----Batch7: size: 20\n",
            " 7/34 [=====>........................] - ETA: 12:25 - loss: 1.3639 - categorical_accuracy: 0.4071-----Batch8: size: 20\n",
            " 8/34 [======>.......................] - ETA: 11:59 - loss: 1.3572 - categorical_accuracy: 0.4250-----Batch9: size: 20\n",
            " 9/34 [======>.......................] - ETA: 11:30 - loss: 1.3258 - categorical_accuracy: 0.4611-----Batch10: size: 20\n",
            "10/34 [=======>......................] - ETA: 11:02 - loss: 1.3297 - categorical_accuracy: 0.4400-----Batch11: size: 20\n",
            "11/34 [========>.....................] - ETA: 10:34 - loss: 1.3275 - categorical_accuracy: 0.4500-----Batch12: size: 20\n",
            "12/34 [=========>....................] - ETA: 10:06 - loss: 1.3193 - categorical_accuracy: 0.4625-----Batch13: size: 20\n",
            "13/34 [==========>...................] - ETA: 9:39 - loss: 1.3210 - categorical_accuracy: 0.4538 -----Batch14: size: 20\n",
            "14/34 [===========>..................] - ETA: 9:11 - loss: 1.3248 - categorical_accuracy: 0.4464-----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 8:43 - loss: 1.3274 - categorical_accuracy: 0.4467-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 8:16 - loss: 1.3396 - categorical_accuracy: 0.4344-----Batch17: size: 20\n",
            "17/34 [==============>...............] - ETA: 7:48 - loss: 1.3466 - categorical_accuracy: 0.4353-----Batch18: size: 20\n",
            "18/34 [==============>...............] - ETA: 7:20 - loss: 1.3509 - categorical_accuracy: 0.4333-----Batch19: size: 20\n",
            "19/34 [===============>..............] - ETA: 6:53 - loss: 1.3512 - categorical_accuracy: 0.4368-----Batch20: size: 20\n",
            "20/34 [================>.............] - ETA: 6:26 - loss: 1.3601 - categorical_accuracy: 0.4275-----Batch21: size: 20\n",
            "21/34 [=================>............] - ETA: 5:59 - loss: 1.3593 - categorical_accuracy: 0.4286-----Batch22: size: 20\n",
            "22/34 [==================>...........] - ETA: 5:31 - loss: 1.3536 - categorical_accuracy: 0.4295-----Batch23: size: 20\n",
            "23/34 [===================>..........] - ETA: 5:04 - loss: 1.3571 - categorical_accuracy: 0.4304-----Batch24: size: 20\n",
            "24/34 [====================>.........] - ETA: 4:36 - loss: 1.3556 - categorical_accuracy: 0.4271-----Batch25: size: 20\n",
            "25/34 [=====================>........] - ETA: 4:09 - loss: 1.3566 - categorical_accuracy: 0.4220-----Batch26: size: 20\n",
            "26/34 [=====================>........] - ETA: 3:41 - loss: 1.3604 - categorical_accuracy: 0.4212-----Batch27: size: 20\n",
            "27/34 [======================>.......] - ETA: 3:13 - loss: 1.3564 - categorical_accuracy: 0.4278-----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 2:45 - loss: 1.3510 - categorical_accuracy: 0.4304-----Batch29: size: 20\n",
            "29/34 [========================>.....] - ETA: 2:18 - loss: 1.3486 - categorical_accuracy: 0.4293-----Batch30: size: 20\n",
            "30/34 [=========================>....] - ETA: 1:50 - loss: 1.3561 - categorical_accuracy: 0.4267-----Batch31: size: 20\n",
            "31/34 [==========================>...] - ETA: 1:23 - loss: 1.3629 - categorical_accuracy: 0.4242-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 55s - loss: 1.3629 - categorical_accuracy: 0.4219 -----last Batch size: 3\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.3609 - categorical_accuracy: 0.4238 -----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "\n",
            "Epoch 00007: saving model to model_init_2021-12-2817_15_33.974604\\model-00007-1.36091-0.42383-1.64708-0.31000.h5\n",
            "34/34 [==============================] - 1009s 30s/step - loss: 1.3609 - categorical_accuracy: 0.4238 - val_loss: 1.6471 - val_categorical_accuracy: 0.3100 - lr: 1.0000e-04\n",
            "Epoch 8/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 19:36 - loss: 1.2375 - categorical_accuracy: 0.6500-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 19:07 - loss: 1.3370 - categorical_accuracy: 0.5250-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 18:35 - loss: 1.4133 - categorical_accuracy: 0.4500-----Batch4: size: 20\n",
            " 4/34 [==>...........................] - ETA: 18:08 - loss: 1.4286 - categorical_accuracy: 0.4125-----Batch5: size: 20\n",
            " 5/34 [===>..........................] - ETA: 17:35 - loss: 1.3926 - categorical_accuracy: 0.4300-----Batch6: size: 20\n",
            " 6/34 [====>.........................] - ETA: 16:58 - loss: 1.3722 - categorical_accuracy: 0.4333-----Batch7: size: 20\n",
            " 7/34 [=====>........................] - ETA: 16:21 - loss: 1.3471 - categorical_accuracy: 0.4571-----Batch8: size: 20\n",
            " 8/34 [======>.......................] - ETA: 15:43 - loss: 1.3476 - categorical_accuracy: 0.4625-----Batch9: size: 20\n",
            " 9/34 [======>.......................] - ETA: 15:06 - loss: 1.3727 - categorical_accuracy: 0.4556-----Batch10: size: 20\n",
            "10/34 [=======>......................] - ETA: 14:28 - loss: 1.3616 - categorical_accuracy: 0.4600-----Batch11: size: 20\n",
            "11/34 [========>.....................] - ETA: 13:52 - loss: 1.3666 - categorical_accuracy: 0.4591-----Batch12: size: 20\n",
            "12/34 [=========>....................] - ETA: 13:19 - loss: 1.3500 - categorical_accuracy: 0.4792-----Batch13: size: 20\n",
            "13/34 [==========>...................] - ETA: 12:34 - loss: 1.3457 - categorical_accuracy: 0.4808-----Batch14: size: 20\n",
            "14/34 [===========>..................] - ETA: 11:47 - loss: 1.3405 - categorical_accuracy: 0.4857-----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 11:06 - loss: 1.3360 - categorical_accuracy: 0.4800-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 10:30 - loss: 1.3269 - categorical_accuracy: 0.4844-----Batch17: size: 20\n",
            "17/34 [==============>...............] - ETA: 9:51 - loss: 1.3248 - categorical_accuracy: 0.4853 -----Batch18: size: 20\n",
            "18/34 [==============>...............] - ETA: 9:10 - loss: 1.3263 - categorical_accuracy: 0.4889-----Batch19: size: 20\n",
            "19/34 [===============>..............] - ETA: 8:30 - loss: 1.3394 - categorical_accuracy: 0.4868-----Batch20: size: 20\n",
            "20/34 [================>.............] - ETA: 7:52 - loss: 1.3242 - categorical_accuracy: 0.4975-----Batch21: size: 20\n",
            "21/34 [=================>............] - ETA: 7:15 - loss: 1.3259 - categorical_accuracy: 0.4929-----Batch22: size: 20\n",
            "22/34 [==================>...........] - ETA: 6:39 - loss: 1.3244 - categorical_accuracy: 0.4932-----Batch23: size: 20\n",
            "23/34 [===================>..........] - ETA: 6:03 - loss: 1.3263 - categorical_accuracy: 0.4870-----Batch24: size: 20\n",
            "24/34 [====================>.........] - ETA: 5:28 - loss: 1.3304 - categorical_accuracy: 0.4792-----Batch25: size: 20\n",
            "25/34 [=====================>........] - ETA: 4:54 - loss: 1.3269 - categorical_accuracy: 0.4800-----Batch26: size: 20\n",
            "26/34 [=====================>........] - ETA: 4:20 - loss: 1.3282 - categorical_accuracy: 0.4788-----Batch27: size: 20\n",
            "27/34 [======================>.......] - ETA: 3:46 - loss: 1.3260 - categorical_accuracy: 0.4796-----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 3:13 - loss: 1.3267 - categorical_accuracy: 0.4804-----Batch29: size: 20\n",
            "29/34 [========================>.....] - ETA: 2:40 - loss: 1.3153 - categorical_accuracy: 0.4914-----Batch30: size: 20\n",
            "30/34 [=========================>....] - ETA: 2:08 - loss: 1.3116 - categorical_accuracy: 0.4967-----Batch31: size: 20\n",
            "31/34 [==========================>...] - ETA: 1:35 - loss: 1.3107 - categorical_accuracy: 0.4935-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 1:03 - loss: 1.3118 - categorical_accuracy: 0.4922-----last Batch size: 3\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.3160 - categorical_accuracy: 0.4917 -----Batch0: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "\n",
            "Epoch 00008: saving model to model_init_2021-12-2817_15_33.974604\\model-00008-1.31601-0.49170-1.60545-0.31000.h5\n",
            "34/34 [==============================] - 1124s 33s/step - loss: 1.3160 - categorical_accuracy: 0.4917 - val_loss: 1.6054 - val_categorical_accuracy: 0.3100 - lr: 1.0000e-04\n",
            "Epoch 9/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 15:33 - loss: 1.4460 - categorical_accuracy: 0.2500-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 15:44 - loss: 1.3270 - categorical_accuracy: 0.4000-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 15:00 - loss: 1.3248 - categorical_accuracy: 0.4000-----Batch4: size: 20\n",
            " 4/34 [==>...........................] - ETA: 14:26 - loss: 1.3038 - categorical_accuracy: 0.4250-----Batch5: size: 20\n",
            " 5/34 [===>..........................] - ETA: 13:59 - loss: 1.3160 - categorical_accuracy: 0.4500-----Batch6: size: 20\n",
            " 6/34 [====>.........................] - ETA: 13:47 - loss: 1.3068 - categorical_accuracy: 0.4667-----Batch7: size: 20\n",
            " 7/34 [=====>........................] - ETA: 13:14 - loss: 1.3216 - categorical_accuracy: 0.4643-----Batch8: size: 20\n",
            " 8/34 [======>.......................] - ETA: 12:46 - loss: 1.3099 - categorical_accuracy: 0.4812-----Batch9: size: 20\n",
            " 9/34 [======>.......................] - ETA: 12:16 - loss: 1.3031 - categorical_accuracy: 0.4833-----Batch10: size: 20\n",
            "10/34 [=======>......................] - ETA: 11:46 - loss: 1.3151 - categorical_accuracy: 0.4750-----Batch11: size: 20\n",
            "11/34 [========>.....................] - ETA: 11:17 - loss: 1.3196 - categorical_accuracy: 0.4727-----Batch12: size: 20\n",
            "12/34 [=========>....................] - ETA: 10:46 - loss: 1.3136 - categorical_accuracy: 0.4750-----Batch13: size: 20\n",
            "13/34 [==========>...................] - ETA: 10:19 - loss: 1.3058 - categorical_accuracy: 0.4808-----Batch14: size: 20\n",
            "14/34 [===========>..................] - ETA: 9:50 - loss: 1.3027 - categorical_accuracy: 0.4857 -----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 9:20 - loss: 1.3044 - categorical_accuracy: 0.4767-----Batch16: size: 20\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/34 [=============>................] - ETA: 8:49 - loss: 1.3102 - categorical_accuracy: 0.4688-----Batch17: size: 20\n",
            "17/34 [==============>...............] - ETA: 8:19 - loss: 1.3048 - categorical_accuracy: 0.4706-----Batch18: size: 20\n",
            "18/34 [==============>...............] - ETA: 7:49 - loss: 1.3072 - categorical_accuracy: 0.4722-----Batch19: size: 20\n",
            "19/34 [===============>..............] - ETA: 7:19 - loss: 1.3146 - categorical_accuracy: 0.4684-----Batch20: size: 20\n",
            "20/34 [================>.............] - ETA: 6:49 - loss: 1.3131 - categorical_accuracy: 0.4700-----Batch21: size: 20\n",
            "21/34 [=================>............] - ETA: 6:20 - loss: 1.3033 - categorical_accuracy: 0.4738-----Batch22: size: 20\n",
            "22/34 [==================>...........] - ETA: 5:50 - loss: 1.3084 - categorical_accuracy: 0.4705-----Batch23: size: 20\n",
            "23/34 [===================>..........] - ETA: 5:21 - loss: 1.3112 - categorical_accuracy: 0.4674-----Batch24: size: 20\n",
            "24/34 [====================>.........] - ETA: 4:52 - loss: 1.3131 - categorical_accuracy: 0.4646-----Batch25: size: 20\n",
            "25/34 [=====================>........] - ETA: 4:22 - loss: 1.3167 - categorical_accuracy: 0.4640-----Batch26: size: 20\n",
            "26/34 [=====================>........] - ETA: 3:53 - loss: 1.3166 - categorical_accuracy: 0.4654-----Batch27: size: 20\n",
            "27/34 [======================>.......] - ETA: 3:24 - loss: 1.3157 - categorical_accuracy: 0.4667-----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 2:55 - loss: 1.3155 - categorical_accuracy: 0.4696-----Batch29: size: 20\n",
            "29/34 [========================>.....] - ETA: 2:25 - loss: 1.3211 - categorical_accuracy: 0.4672-----Batch30: size: 20\n",
            "30/34 [=========================>....] - ETA: 1:56 - loss: 1.3208 - categorical_accuracy: 0.4650-----Batch31: size: 20\n",
            "31/34 [==========================>...] - ETA: 1:27 - loss: 1.3112 - categorical_accuracy: 0.4726-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 58s - loss: 1.3128 - categorical_accuracy: 0.4750 -----last Batch size: 3\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.3128 - categorical_accuracy: 0.4751 -----Batch0: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "\n",
            "Epoch 00009: saving model to model_init_2021-12-2817_15_33.974604\\model-00009-1.31276-0.47511-1.40048-0.45000.h5\n",
            "34/34 [==============================] - 1040s 31s/step - loss: 1.3128 - categorical_accuracy: 0.4751 - val_loss: 1.4005 - val_categorical_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 10/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 15:26 - loss: 1.2002 - categorical_accuracy: 0.6000-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 15:07 - loss: 1.2533 - categorical_accuracy: 0.5500-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 15:09 - loss: 1.3231 - categorical_accuracy: 0.5000-----Batch4: size: 20\n",
            " 4/34 [==>...........................] - ETA: 14:41 - loss: 1.3693 - categorical_accuracy: 0.4750-----Batch5: size: 20\n",
            " 5/34 [===>..........................] - ETA: 14:05 - loss: 1.3728 - categorical_accuracy: 0.4500-----Batch6: size: 20\n",
            " 6/34 [====>.........................] - ETA: 13:32 - loss: 1.3480 - categorical_accuracy: 0.4667-----Batch7: size: 20\n",
            " 7/34 [=====>........................] - ETA: 13:12 - loss: 1.3582 - categorical_accuracy: 0.4500-----Batch8: size: 20\n",
            " 8/34 [======>.......................] - ETA: 12:46 - loss: 1.3648 - categorical_accuracy: 0.4812-----Batch9: size: 20\n",
            " 9/34 [======>.......................] - ETA: 12:22 - loss: 1.3439 - categorical_accuracy: 0.4889-----Batch10: size: 20\n",
            "10/34 [=======>......................] - ETA: 11:50 - loss: 1.3399 - categorical_accuracy: 0.4900-----Batch11: size: 20\n",
            "11/34 [========>.....................] - ETA: 11:21 - loss: 1.3324 - categorical_accuracy: 0.4955-----Batch12: size: 20\n",
            "12/34 [=========>....................] - ETA: 10:56 - loss: 1.3030 - categorical_accuracy: 0.5250-----Batch13: size: 20\n",
            "13/34 [==========>...................] - ETA: 10:25 - loss: 1.3005 - categorical_accuracy: 0.5192-----Batch14: size: 20\n",
            "14/34 [===========>..................] - ETA: 9:54 - loss: 1.2969 - categorical_accuracy: 0.5143 -----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 9:27 - loss: 1.2940 - categorical_accuracy: 0.5167-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 8:57 - loss: 1.2974 - categorical_accuracy: 0.5219-----Batch17: size: 20\n",
            "17/34 [==============>...............] - ETA: 8:25 - loss: 1.2920 - categorical_accuracy: 0.5206-----Batch18: size: 20\n",
            "18/34 [==============>...............] - ETA: 7:55 - loss: 1.2973 - categorical_accuracy: 0.5111-----Batch19: size: 20\n",
            "19/34 [===============>..............] - ETA: 7:26 - loss: 1.3005 - categorical_accuracy: 0.5105-----Batch20: size: 20\n",
            "20/34 [================>.............] - ETA: 6:58 - loss: 1.3028 - categorical_accuracy: 0.5075-----Batch21: size: 20\n",
            "21/34 [=================>............] - ETA: 6:27 - loss: 1.3142 - categorical_accuracy: 0.4976-----Batch22: size: 20\n",
            "22/34 [==================>...........] - ETA: 5:56 - loss: 1.3045 - categorical_accuracy: 0.5068-----Batch23: size: 20\n",
            "23/34 [===================>..........] - ETA: 5:26 - loss: 1.3127 - categorical_accuracy: 0.5022-----Batch24: size: 20\n",
            "24/34 [====================>.........] - ETA: 4:56 - loss: 1.3018 - categorical_accuracy: 0.5104-----Batch25: size: 20\n",
            "25/34 [=====================>........] - ETA: 4:26 - loss: 1.2993 - categorical_accuracy: 0.5120-----Batch26: size: 20\n",
            "26/34 [=====================>........] - ETA: 3:57 - loss: 1.3077 - categorical_accuracy: 0.5058-----Batch27: size: 20\n",
            "27/34 [======================>.......] - ETA: 3:27 - loss: 1.3034 - categorical_accuracy: 0.5093-----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 2:57 - loss: 1.2963 - categorical_accuracy: 0.5143-----Batch29: size: 20\n",
            "29/34 [========================>.....] - ETA: 2:28 - loss: 1.2914 - categorical_accuracy: 0.5155-----Batch30: size: 20\n",
            "30/34 [=========================>....] - ETA: 1:59 - loss: 1.2829 - categorical_accuracy: 0.5217-----Batch31: size: 20\n",
            "31/34 [==========================>...] - ETA: 1:29 - loss: 1.2799 - categorical_accuracy: 0.5258-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 59s - loss: 1.2761 - categorical_accuracy: 0.5281 -----last Batch size: 3\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.2763 - categorical_accuracy: 0.5279 -----Batch0: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "\n",
            "Epoch 00010: saving model to model_init_2021-12-2817_15_33.974604\\model-00010-1.27628-0.52790-1.33477-0.48000.h5\n",
            "34/34 [==============================] - 1058s 31s/step - loss: 1.2763 - categorical_accuracy: 0.5279 - val_loss: 1.3348 - val_categorical_accuracy: 0.4800 - lr: 1.0000e-04\n",
            "Epoch 11/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 15:54 - loss: 1.1906 - categorical_accuracy: 0.7000-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 15:04 - loss: 1.1867 - categorical_accuracy: 0.6250-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 14:40 - loss: 1.1380 - categorical_accuracy: 0.6333-----Batch4: size: 20\n",
            " 4/34 [==>...........................] - ETA: 14:33 - loss: 1.1537 - categorical_accuracy: 0.6125-----Batch5: size: 20\n",
            " 5/34 [===>..........................] - ETA: 14:04 - loss: 1.1108 - categorical_accuracy: 0.6400-----Batch6: size: 20\n",
            " 6/34 [====>.........................] - ETA: 13:33 - loss: 1.1422 - categorical_accuracy: 0.6000-----Batch7: size: 20\n",
            " 7/34 [=====>........................] - ETA: 13:09 - loss: 1.1955 - categorical_accuracy: 0.5643-----Batch8: size: 20\n",
            " 8/34 [======>.......................] - ETA: 12:46 - loss: 1.2398 - categorical_accuracy: 0.5312-----Batch9: size: 20\n",
            " 9/34 [======>.......................] - ETA: 12:21 - loss: 1.2519 - categorical_accuracy: 0.5167-----Batch10: size: 20\n",
            "10/34 [=======>......................] - ETA: 11:48 - loss: 1.2682 - categorical_accuracy: 0.4900-----Batch11: size: 20\n",
            "11/34 [========>.....................] - ETA: 11:20 - loss: 1.2851 - categorical_accuracy: 0.4773-----Batch12: size: 20\n",
            "12/34 [=========>....................] - ETA: 10:53 - loss: 1.3100 - categorical_accuracy: 0.4625-----Batch13: size: 20\n",
            "13/34 [==========>...................] - ETA: 10:22 - loss: 1.3310 - categorical_accuracy: 0.4500-----Batch14: size: 20\n",
            "14/34 [===========>..................] - ETA: 9:53 - loss: 1.3239 - categorical_accuracy: 0.4571 -----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 9:23 - loss: 1.3173 - categorical_accuracy: 0.4633-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 8:56 - loss: 1.3033 - categorical_accuracy: 0.4750-----Batch17: size: 20\n",
            "17/34 [==============>...............] - ETA: 8:24 - loss: 1.2966 - categorical_accuracy: 0.4824-----Batch18: size: 20\n",
            "18/34 [==============>...............] - ETA: 7:52 - loss: 1.2960 - categorical_accuracy: 0.4833-----Batch19: size: 20\n",
            "19/34 [===============>..............] - ETA: 7:20 - loss: 1.2864 - categorical_accuracy: 0.4921-----Batch20: size: 20\n",
            "20/34 [================>.............] - ETA: 6:50 - loss: 1.2818 - categorical_accuracy: 0.4975-----Batch21: size: 20\n",
            "21/34 [=================>............] - ETA: 6:20 - loss: 1.2808 - categorical_accuracy: 0.4976-----Batch22: size: 20\n",
            "22/34 [==================>...........] - ETA: 5:49 - loss: 1.2757 - categorical_accuracy: 0.5091-----Batch23: size: 20\n",
            "23/34 [===================>..........] - ETA: 5:19 - loss: 1.2800 - categorical_accuracy: 0.5065-----Batch24: size: 20\n",
            "24/34 [====================>.........] - ETA: 4:50 - loss: 1.2712 - categorical_accuracy: 0.5125-----Batch25: size: 20\n",
            "25/34 [=====================>........] - ETA: 4:21 - loss: 1.2703 - categorical_accuracy: 0.5140-----Batch26: size: 20\n",
            "26/34 [=====================>........] - ETA: 3:51 - loss: 1.2729 - categorical_accuracy: 0.5096-----Batch27: size: 20\n",
            "27/34 [======================>.......] - ETA: 3:22 - loss: 1.2812 - categorical_accuracy: 0.4981-----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 2:53 - loss: 1.2775 - categorical_accuracy: 0.5000-----Batch29: size: 20\n",
            "29/34 [========================>.....] - ETA: 2:24 - loss: 1.2797 - categorical_accuracy: 0.4948-----Batch30: size: 20\n",
            "30/34 [=========================>....] - ETA: 1:55 - loss: 1.2758 - categorical_accuracy: 0.5000-----Batch31: size: 20\n",
            "31/34 [==========================>...] - ETA: 1:26 - loss: 1.2722 - categorical_accuracy: 0.5032-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 57s - loss: 1.2648 - categorical_accuracy: 0.5078 -----last Batch size: 3\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.2630 - categorical_accuracy: 0.5098 -----Batch0: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "\n",
            "Epoch 00011: saving model to model_init_2021-12-2817_15_33.974604\\model-00011-1.26298-0.50980-1.44368-0.43000.h5\n",
            "34/34 [==============================] - 1014s 30s/step - loss: 1.2630 - categorical_accuracy: 0.5098 - val_loss: 1.4437 - val_categorical_accuracy: 0.4300 - lr: 1.0000e-04\n",
            "Epoch 12/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 14:59 - loss: 1.1609 - categorical_accuracy: 0.6000-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 15:06 - loss: 1.1315 - categorical_accuracy: 0.6000-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 14:29 - loss: 1.1521 - categorical_accuracy: 0.6000-----Batch4: size: 20\n",
            " 4/34 [==>...........................] - ETA: 13:55 - loss: 1.1328 - categorical_accuracy: 0.6000-----Batch5: size: 20\n",
            " 5/34 [===>..........................] - ETA: 13:22 - loss: 1.1702 - categorical_accuracy: 0.5900-----Batch6: size: 20\n",
            " 6/34 [====>.........................] - ETA: 12:56 - loss: 1.2233 - categorical_accuracy: 0.5417-----Batch7: size: 20\n",
            " 7/34 [=====>........................] - ETA: 12:30 - loss: 1.2278 - categorical_accuracy: 0.5571-----Batch8: size: 20\n",
            " 8/34 [======>.......................] - ETA: 12:00 - loss: 1.2165 - categorical_accuracy: 0.5562-----Batch9: size: 20\n",
            " 9/34 [======>.......................] - ETA: 11:31 - loss: 1.2104 - categorical_accuracy: 0.5667-----Batch10: size: 20\n",
            "10/34 [=======>......................] - ETA: 11:02 - loss: 1.2210 - categorical_accuracy: 0.5650-----Batch11: size: 20\n",
            "11/34 [========>.....................] - ETA: 10:36 - loss: 1.2093 - categorical_accuracy: 0.5773-----Batch12: size: 20\n",
            "12/34 [=========>....................] - ETA: 10:08 - loss: 1.2177 - categorical_accuracy: 0.5667-----Batch13: size: 20\n",
            "13/34 [==========>...................] - ETA: 9:39 - loss: 1.1998 - categorical_accuracy: 0.5846 -----Batch14: size: 20\n",
            "14/34 [===========>..................] - ETA: 9:11 - loss: 1.1981 - categorical_accuracy: 0.5821-----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 8:46 - loss: 1.1921 - categorical_accuracy: 0.5800-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 8:20 - loss: 1.1837 - categorical_accuracy: 0.5750-----Batch17: size: 20\n",
            "17/34 [==============>...............] - ETA: 7:53 - loss: 1.1933 - categorical_accuracy: 0.5735-----Batch18: size: 20\n",
            "18/34 [==============>...............] - ETA: 7:26 - loss: 1.2005 - categorical_accuracy: 0.5667-----Batch19: size: 20\n",
            "19/34 [===============>..............] - ETA: 7:00 - loss: 1.1912 - categorical_accuracy: 0.5737-----Batch20: size: 20\n",
            "20/34 [================>.............] - ETA: 6:32 - loss: 1.1922 - categorical_accuracy: 0.5700-----Batch21: size: 20\n",
            "21/34 [=================>............] - ETA: 6:05 - loss: 1.1987 - categorical_accuracy: 0.5714-----Batch22: size: 20\n",
            "22/34 [==================>...........] - ETA: 5:37 - loss: 1.2001 - categorical_accuracy: 0.5682-----Batch23: size: 20\n",
            "23/34 [===================>..........] - ETA: 5:09 - loss: 1.1930 - categorical_accuracy: 0.5739-----Batch24: size: 20\n",
            "24/34 [====================>.........] - ETA: 4:41 - loss: 1.1956 - categorical_accuracy: 0.5708-----Batch25: size: 20\n",
            "25/34 [=====================>........] - ETA: 4:13 - loss: 1.1953 - categorical_accuracy: 0.5700-----Batch26: size: 20\n",
            "26/34 [=====================>........] - ETA: 3:45 - loss: 1.1972 - categorical_accuracy: 0.5692-----Batch27: size: 20\n",
            "27/34 [======================>.......] - ETA: 3:16 - loss: 1.1910 - categorical_accuracy: 0.5722-----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 2:48 - loss: 1.1831 - categorical_accuracy: 0.5786-----Batch29: size: 20\n",
            "29/34 [========================>.....] - ETA: 2:21 - loss: 1.1789 - categorical_accuracy: 0.5810-----Batch30: size: 20\n",
            "30/34 [=========================>....] - ETA: 1:53 - loss: 1.1748 - categorical_accuracy: 0.5833-----Batch31: size: 20\n",
            "31/34 [==========================>...] - ETA: 1:24 - loss: 1.1812 - categorical_accuracy: 0.5839-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 56s - loss: 1.1850 - categorical_accuracy: 0.5797 -----last Batch size: 3\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.1858 - categorical_accuracy: 0.5822 -----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "\n",
            "Epoch 00012: saving model to model_init_2021-12-2817_15_33.974604\\model-00012-1.18581-0.58220-1.35331-0.48000.h5\n",
            "34/34 [==============================] - 1011s 30s/step - loss: 1.1858 - categorical_accuracy: 0.5822 - val_loss: 1.3533 - val_categorical_accuracy: 0.4800 - lr: 1.0000e-04\n",
            "Epoch 13/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 16:37 - loss: 1.1043 - categorical_accuracy: 0.6000-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 15:42 - loss: 1.1826 - categorical_accuracy: 0.5750-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 15:39 - loss: 1.2409 - categorical_accuracy: 0.6000-----Batch4: size: 20\n",
            " 4/34 [==>...........................] - ETA: 15:04 - loss: 1.2804 - categorical_accuracy: 0.5500-----Batch5: size: 20\n",
            " 5/34 [===>..........................] - ETA: 14:37 - loss: 1.2911 - categorical_accuracy: 0.5400-----Batch6: size: 20\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 6/34 [====>.........................] - ETA: 13:59 - loss: 1.3372 - categorical_accuracy: 0.4833-----Batch7: size: 20\n",
            " 7/34 [=====>........................] - ETA: 13:32 - loss: 1.3006 - categorical_accuracy: 0.5071-----Batch8: size: 20\n",
            " 8/34 [======>.......................] - ETA: 13:09 - loss: 1.3081 - categorical_accuracy: 0.5000-----Batch9: size: 20\n",
            " 9/34 [======>.......................] - ETA: 12:44 - loss: 1.2830 - categorical_accuracy: 0.5056-----Batch10: size: 20\n",
            "10/34 [=======>......................] - ETA: 12:13 - loss: 1.2703 - categorical_accuracy: 0.5150-----Batch11: size: 20\n",
            "11/34 [========>.....................] - ETA: 11:35 - loss: 1.2646 - categorical_accuracy: 0.5136-----Batch12: size: 20\n",
            "12/34 [=========>....................] - ETA: 11:01 - loss: 1.2432 - categorical_accuracy: 0.5292-----Batch13: size: 20\n",
            "13/34 [==========>...................] - ETA: 10:27 - loss: 1.2233 - categorical_accuracy: 0.5462-----Batch14: size: 20\n",
            "14/34 [===========>..................] - ETA: 9:54 - loss: 1.2102 - categorical_accuracy: 0.5536 -----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 9:21 - loss: 1.2015 - categorical_accuracy: 0.5600-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 8:49 - loss: 1.1990 - categorical_accuracy: 0.5562-----Batch17: size: 20\n",
            "17/34 [==============>...............] - ETA: 8:19 - loss: 1.1963 - categorical_accuracy: 0.5529-----Batch18: size: 20\n",
            "18/34 [==============>...............] - ETA: 7:47 - loss: 1.2075 - categorical_accuracy: 0.5472-----Batch19: size: 20\n",
            "19/34 [===============>..............] - ETA: 7:17 - loss: 1.1981 - categorical_accuracy: 0.5526-----Batch20: size: 20\n",
            "20/34 [================>.............] - ETA: 6:47 - loss: 1.1866 - categorical_accuracy: 0.5550-----Batch21: size: 20\n",
            "21/34 [=================>............] - ETA: 6:18 - loss: 1.1792 - categorical_accuracy: 0.5571-----Batch22: size: 20\n",
            "22/34 [==================>...........] - ETA: 5:48 - loss: 1.1802 - categorical_accuracy: 0.5568-----Batch23: size: 20\n",
            "23/34 [===================>..........] - ETA: 5:19 - loss: 1.1865 - categorical_accuracy: 0.5543-----Batch24: size: 20\n",
            "24/34 [====================>.........] - ETA: 4:49 - loss: 1.1853 - categorical_accuracy: 0.5562-----Batch25: size: 20\n",
            "25/34 [=====================>........] - ETA: 4:20 - loss: 1.1892 - categorical_accuracy: 0.5560-----Batch26: size: 20\n",
            "26/34 [=====================>........] - ETA: 3:50 - loss: 1.1966 - categorical_accuracy: 0.5519-----Batch27: size: 20\n",
            "27/34 [======================>.......] - ETA: 3:21 - loss: 1.1933 - categorical_accuracy: 0.5537-----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 2:52 - loss: 1.1823 - categorical_accuracy: 0.5607-----Batch29: size: 20\n",
            "29/34 [========================>.....] - ETA: 2:23 - loss: 1.1837 - categorical_accuracy: 0.5603-----Batch30: size: 20\n",
            "30/34 [=========================>....] - ETA: 1:55 - loss: 1.1826 - categorical_accuracy: 0.5600-----Batch31: size: 20\n",
            "31/34 [==========================>...] - ETA: 1:26 - loss: 1.1755 - categorical_accuracy: 0.5629-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 58s - loss: 1.1719 - categorical_accuracy: 0.5656 -----last Batch size: 3\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.1790 - categorical_accuracy: 0.5611 -----Batch0: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "\n",
            "Epoch 00013: saving model to model_init_2021-12-2817_15_33.974604\\model-00013-1.17896-0.56109-1.42652-0.39000.h5\n",
            "34/34 [==============================] - 1040s 31s/step - loss: 1.1790 - categorical_accuracy: 0.5611 - val_loss: 1.4265 - val_categorical_accuracy: 0.3900 - lr: 1.0000e-04\n",
            "Epoch 14/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 16:02 - loss: 0.8601 - categorical_accuracy: 0.7500-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 16:02 - loss: 0.9322 - categorical_accuracy: 0.7000-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 15:37 - loss: 0.9213 - categorical_accuracy: 0.7167-----Batch4: size: 20\n",
            " 4/34 [==>...........................] - ETA: 14:59 - loss: 1.0125 - categorical_accuracy: 0.6500-----Batch5: size: 20\n",
            " 5/34 [===>..........................] - ETA: 14:24 - loss: 1.0159 - categorical_accuracy: 0.6600-----Batch6: size: 20\n",
            " 6/34 [====>.........................] - ETA: 13:51 - loss: 0.9927 - categorical_accuracy: 0.6750-----Batch7: size: 20\n",
            " 7/34 [=====>........................] - ETA: 13:14 - loss: 1.0232 - categorical_accuracy: 0.6500-----Batch8: size: 20\n",
            " 8/34 [======>.......................] - ETA: 12:40 - loss: 1.0278 - categorical_accuracy: 0.6500-----Batch9: size: 20\n",
            " 9/34 [======>.......................] - ETA: 12:11 - loss: 1.0228 - categorical_accuracy: 0.6611-----Batch10: size: 20\n",
            "10/34 [=======>......................] - ETA: 11:41 - loss: 1.0341 - categorical_accuracy: 0.6600-----Batch11: size: 20\n",
            "11/34 [========>.....................] - ETA: 11:12 - loss: 1.0283 - categorical_accuracy: 0.6636-----Batch12: size: 20\n",
            "12/34 [=========>....................] - ETA: 10:42 - loss: 1.0539 - categorical_accuracy: 0.6375-----Batch13: size: 20\n",
            "13/34 [==========>...................] - ETA: 10:11 - loss: 1.0470 - categorical_accuracy: 0.6423-----Batch14: size: 20\n",
            "14/34 [===========>..................] - ETA: 9:43 - loss: 1.0451 - categorical_accuracy: 0.6500 -----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 9:13 - loss: 1.0513 - categorical_accuracy: 0.6367-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 8:45 - loss: 1.0616 - categorical_accuracy: 0.6281-----Batch17: size: 20\n",
            "17/34 [==============>...............] - ETA: 8:16 - loss: 1.0591 - categorical_accuracy: 0.6324-----Batch18: size: 20\n",
            "18/34 [==============>...............] - ETA: 7:47 - loss: 1.0545 - categorical_accuracy: 0.6361-----Batch19: size: 20\n",
            "19/34 [===============>..............] - ETA: 7:19 - loss: 1.0831 - categorical_accuracy: 0.6211-----Batch20: size: 20\n",
            "20/34 [================>.............] - ETA: 6:49 - loss: 1.0865 - categorical_accuracy: 0.6225-----Batch21: size: 20\n",
            "21/34 [=================>............] - ETA: 6:20 - loss: 1.0863 - categorical_accuracy: 0.6214-----Batch22: size: 20\n",
            "22/34 [==================>...........] - ETA: 5:51 - loss: 1.0872 - categorical_accuracy: 0.6250-----Batch23: size: 20\n",
            "23/34 [===================>..........] - ETA: 5:22 - loss: 1.0826 - categorical_accuracy: 0.6326-----Batch24: size: 20\n",
            "24/34 [====================>.........] - ETA: 4:53 - loss: 1.0750 - categorical_accuracy: 0.6354-----Batch25: size: 20\n",
            "25/34 [=====================>........] - ETA: 4:24 - loss: 1.0810 - categorical_accuracy: 0.6340-----Batch26: size: 20\n",
            "26/34 [=====================>........] - ETA: 3:54 - loss: 1.0744 - categorical_accuracy: 0.6365-----Batch27: size: 20\n",
            "27/34 [======================>.......] - ETA: 3:26 - loss: 1.0677 - categorical_accuracy: 0.6407-----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 2:56 - loss: 1.0701 - categorical_accuracy: 0.6411-----Batch29: size: 20\n",
            "29/34 [========================>.....] - ETA: 2:27 - loss: 1.0798 - categorical_accuracy: 0.6345-----Batch30: size: 20\n",
            "30/34 [=========================>....] - ETA: 1:57 - loss: 1.0823 - categorical_accuracy: 0.6317-----Batch31: size: 20\n",
            "31/34 [==========================>...] - ETA: 1:28 - loss: 1.0837 - categorical_accuracy: 0.6290-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 59s - loss: 1.0859 - categorical_accuracy: 0.6266 -----last Batch size: 3\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.0960 - categorical_accuracy: 0.6199 -----Batch0: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "\n",
            "Epoch 00014: saving model to model_init_2021-12-2817_15_33.974604\\model-00014-1.09601-0.61991-1.57793-0.35000.h5\n",
            "34/34 [==============================] - 1054s 31s/step - loss: 1.0960 - categorical_accuracy: 0.6199 - val_loss: 1.5779 - val_categorical_accuracy: 0.3500 - lr: 1.0000e-04\n",
            "Epoch 15/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 16:48 - loss: 1.2001 - categorical_accuracy: 0.6500-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 15:54 - loss: 1.1651 - categorical_accuracy: 0.6500-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 15:29 - loss: 1.0281 - categorical_accuracy: 0.7167-----Batch4: size: 20\n",
            " 4/34 [==>...........................] - ETA: 15:07 - loss: 1.0505 - categorical_accuracy: 0.7000-----Batch5: size: 20\n",
            " 5/34 [===>..........................] - ETA: 14:42 - loss: 1.0372 - categorical_accuracy: 0.6900-----Batch6: size: 20\n",
            " 6/34 [====>.........................] - ETA: 14:00 - loss: 1.0692 - categorical_accuracy: 0.6417-----Batch7: size: 20\n",
            " 7/34 [=====>........................] - ETA: 13:24 - loss: 1.0550 - categorical_accuracy: 0.6500-----Batch8: size: 20\n",
            " 8/34 [======>.......................] - ETA: 12:55 - loss: 1.0441 - categorical_accuracy: 0.6438-----Batch9: size: 20\n",
            " 9/34 [======>.......................] - ETA: 12:24 - loss: 1.0318 - categorical_accuracy: 0.6500-----Batch10: size: 20\n",
            "10/34 [=======>......................] - ETA: 11:52 - loss: 1.0506 - categorical_accuracy: 0.6250-----Batch11: size: 20\n",
            "11/34 [========>.....................] - ETA: 11:24 - loss: 1.0722 - categorical_accuracy: 0.6136-----Batch12: size: 20\n",
            "12/34 [=========>....................] - ETA: 10:55 - loss: 1.0629 - categorical_accuracy: 0.6125-----Batch13: size: 20\n",
            "13/34 [==========>...................] - ETA: 10:27 - loss: 1.0549 - categorical_accuracy: 0.6192-----Batch14: size: 20\n",
            "14/34 [===========>..................] - ETA: 9:58 - loss: 1.0648 - categorical_accuracy: 0.6214 -----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 9:26 - loss: 1.0631 - categorical_accuracy: 0.6267-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 8:57 - loss: 1.0569 - categorical_accuracy: 0.6344-----Batch17: size: 20\n",
            "17/34 [==============>...............] - ETA: 8:28 - loss: 1.0681 - categorical_accuracy: 0.6265-----Batch18: size: 20\n",
            "18/34 [==============>...............] - ETA: 7:59 - loss: 1.0861 - categorical_accuracy: 0.6222-----Batch19: size: 20\n",
            "19/34 [===============>..............] - ETA: 7:29 - loss: 1.0978 - categorical_accuracy: 0.6105-----Batch20: size: 20\n",
            "20/34 [================>.............] - ETA: 7:00 - loss: 1.0944 - categorical_accuracy: 0.6100-----Batch21: size: 20\n",
            "21/34 [=================>............] - ETA: 6:30 - loss: 1.0962 - categorical_accuracy: 0.6095-----Batch22: size: 20\n",
            "22/34 [==================>...........] - ETA: 6:00 - loss: 1.1024 - categorical_accuracy: 0.6045-----Batch23: size: 20\n",
            "23/34 [===================>..........] - ETA: 5:31 - loss: 1.1155 - categorical_accuracy: 0.5978-----Batch24: size: 20\n",
            "24/34 [====================>.........] - ETA: 5:01 - loss: 1.1249 - categorical_accuracy: 0.5917-----Batch25: size: 20\n",
            "25/34 [=====================>........] - ETA: 4:31 - loss: 1.1263 - categorical_accuracy: 0.5880-----Batch26: size: 20\n",
            "26/34 [=====================>........] - ETA: 4:00 - loss: 1.1210 - categorical_accuracy: 0.5885-----Batch27: size: 20\n",
            "27/34 [======================>.......] - ETA: 3:29 - loss: 1.1239 - categorical_accuracy: 0.5852-----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 2:59 - loss: 1.1235 - categorical_accuracy: 0.5821-----Batch29: size: 20\n",
            "29/34 [========================>.....] - ETA: 2:28 - loss: 1.1120 - categorical_accuracy: 0.5897-----Batch30: size: 20\n",
            "30/34 [=========================>....] - ETA: 1:58 - loss: 1.1097 - categorical_accuracy: 0.5917-----Batch31: size: 20\n",
            "31/34 [==========================>...] - ETA: 1:28 - loss: 1.1086 - categorical_accuracy: 0.5903-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 59s - loss: 1.1019 - categorical_accuracy: 0.5938 -----last Batch size: 3\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.0964 - categorical_accuracy: 0.6003 -----Batch0: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "\n",
            "Epoch 00015: saving model to model_init_2021-12-2817_15_33.974604\\model-00015-1.09643-0.60030-1.26150-0.52000.h5\n",
            "34/34 [==============================] - 1048s 31s/step - loss: 1.0964 - categorical_accuracy: 0.6003 - val_loss: 1.2615 - val_categorical_accuracy: 0.5200 - lr: 1.0000e-04\n",
            "Epoch 16/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 15:04 - loss: 0.9546 - categorical_accuracy: 0.7500-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 14:43 - loss: 0.9707 - categorical_accuracy: 0.7000-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 14:45 - loss: 0.9925 - categorical_accuracy: 0.7167-----Batch4: size: 20\n",
            " 4/34 [==>...........................] - ETA: 14:23 - loss: 1.0526 - categorical_accuracy: 0.6750-----Batch5: size: 20\n",
            " 5/34 [===>..........................] - ETA: 15:07 - loss: 1.0191 - categorical_accuracy: 0.6800-----Batch6: size: 20\n",
            " 6/34 [====>.........................] - ETA: 15:43 - loss: 1.0505 - categorical_accuracy: 0.6583-----Batch7: size: 20\n",
            " 7/34 [=====>........................] - ETA: 15:51 - loss: 1.0052 - categorical_accuracy: 0.6857-----Batch8: size: 20\n",
            " 8/34 [======>.......................] - ETA: 15:46 - loss: 1.0238 - categorical_accuracy: 0.6625-----Batch9: size: 20\n",
            " 9/34 [======>.......................] - ETA: 15:31 - loss: 1.0135 - categorical_accuracy: 0.6778-----Batch10: size: 20\n",
            "10/34 [=======>......................] - ETA: 15:10 - loss: 1.0404 - categorical_accuracy: 0.6500-----Batch11: size: 20\n",
            "11/34 [========>.....................] - ETA: 14:45 - loss: 1.0244 - categorical_accuracy: 0.6500-----Batch12: size: 20\n",
            "12/34 [=========>....................] - ETA: 14:17 - loss: 1.0034 - categorical_accuracy: 0.6625-----Batch13: size: 20\n",
            "13/34 [==========>...................] - ETA: 13:47 - loss: 0.9908 - categorical_accuracy: 0.6692-----Batch14: size: 20\n",
            "14/34 [===========>..................] - ETA: 13:15 - loss: 0.9806 - categorical_accuracy: 0.6786-----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 12:40 - loss: 0.9875 - categorical_accuracy: 0.6767-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 12:05 - loss: 0.9786 - categorical_accuracy: 0.6812-----Batch17: size: 20\n",
            "17/34 [==============>...............] - ETA: 11:28 - loss: 0.9781 - categorical_accuracy: 0.6853-----Batch18: size: 20\n",
            "18/34 [==============>...............] - ETA: 10:51 - loss: 0.9718 - categorical_accuracy: 0.6861-----Batch19: size: 20\n",
            "19/34 [===============>..............] - ETA: 10:13 - loss: 0.9796 - categorical_accuracy: 0.6763-----Batch20: size: 20\n",
            "20/34 [================>.............] - ETA: 9:34 - loss: 0.9919 - categorical_accuracy: 0.6725 -----Batch21: size: 20\n",
            "21/34 [=================>............] - ETA: 8:55 - loss: 0.9941 - categorical_accuracy: 0.6714-----Batch22: size: 20\n",
            "22/34 [==================>...........] - ETA: 8:15 - loss: 1.0045 - categorical_accuracy: 0.6659-----Batch23: size: 20\n",
            "23/34 [===================>..........] - ETA: 7:35 - loss: 1.0047 - categorical_accuracy: 0.6652-----Batch24: size: 20\n",
            "24/34 [====================>.........] - ETA: 6:54 - loss: 1.0117 - categorical_accuracy: 0.6625-----Batch25: size: 20\n",
            "25/34 [=====================>........] - ETA: 6:13 - loss: 1.0172 - categorical_accuracy: 0.6580-----Batch26: size: 20\n",
            "26/34 [=====================>........] - ETA: 5:32 - loss: 1.0126 - categorical_accuracy: 0.6635-----Batch27: size: 20\n",
            "27/34 [======================>.......] - ETA: 4:51 - loss: 1.0129 - categorical_accuracy: 0.6630-----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 4:10 - loss: 1.0100 - categorical_accuracy: 0.6643-----Batch29: size: 20\n",
            "29/34 [========================>.....] - ETA: 3:29 - loss: 1.0190 - categorical_accuracy: 0.6586-----Batch30: size: 20\n",
            "30/34 [=========================>....] - ETA: 2:47 - loss: 1.0340 - categorical_accuracy: 0.6483-----Batch31: size: 20\n",
            "31/34 [==========================>...] - ETA: 2:05 - loss: 1.0349 - categorical_accuracy: 0.6452-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 1:23 - loss: 1.0315 - categorical_accuracy: 0.6422-----last Batch size: 3\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34/34 [==============================] - ETA: 0s - loss: 1.0366 - categorical_accuracy: 0.6395 -----Batch0: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "\n",
            "Epoch 00016: saving model to model_init_2021-12-2817_15_33.974604\\model-00016-1.03660-0.63952-1.53218-0.41000.h5\n",
            "34/34 [==============================] - 1476s 44s/step - loss: 1.0366 - categorical_accuracy: 0.6395 - val_loss: 1.5322 - val_categorical_accuracy: 0.4100 - lr: 1.0000e-04\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1ee8d784e80>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_epochs = 16\n",
        "train_generator,val_generator,steps_per_epoch,validation_steps = sample_set(20,len(train_doc),(180,180))\n",
        "callbacks_list = save_model('categorical_accuracy')\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.0001) \n",
        "model = res_cnn_1()\n",
        "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['categorical_accuracy'])\n",
        "model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "                    callbacks=callbacks_list, validation_data=val_generator, \n",
        "                    validation_steps=validation_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSfKm6BrrcyL"
      },
      "source": [
        "Observations\n",
        "- Categorical accuracy at the end of epoch 16:  Train data: 0.63, validation data: 0.41 \n",
        "- Model accuracy on train data is comparatively less and is heavily overfitting. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36ejDxPJrcyL"
      },
      "source": [
        "#### Model#5: Retrain all layers of ResNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKGTu2BdrcyM"
      },
      "outputs": [],
      "source": [
        "# model 5\n",
        "def res_rnn():\n",
        "    resnet = ResNet50(include_top=False,weights='imagenet',input_shape=(180,180,3))\n",
        "    cnn =Sequential([resnet])\n",
        "    cnn.add(Conv2D(64,(2,2),strides=(1,1)))\n",
        "    cnn.add(Conv2D(128,(2,2),strides=(1,1)))\n",
        "    cnn.add(Conv2D(128,(2,2), strides= (1,1)))\n",
        "    cnn.add(Flatten())\n",
        "    print(cnn.summary())\n",
        "    model = Sequential()\n",
        "    model.add(TimeDistributed(cnn,input_shape=(15,180,180,3)))\n",
        "    model.add(GRU(32,input_shape=(None,15,1152),return_sequences=True))\n",
        "    model.add(GRU(64))\n",
        "    model.add(Dense(5,activation='softmax'))\n",
        "    print(model.summary())\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4fKUwWorcyM",
        "outputId": "5f611626-cb99-48a0-83f5-75376e2b4a0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 6, 6, 2048)        23587712  \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 5, 5, 64)          524352    \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 4, 4, 128)         32896     \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 3, 3, 128)         65664     \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1152)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,210,624\n",
            "Trainable params: 24,157,504\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " time_distributed_1 (TimeDis  (None, 15, 1152)         24210624  \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " gru_2 (GRU)                 (None, 15, 32)            113856    \n",
            "                                                                 \n",
            " gru_3 (GRU)                 (None, 64)                18816     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,343,621\n",
            "Trainable params: 24,290,501\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model = res_rnn()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8AHNYIFrcyM",
        "outputId": "0b8877da-8286-4b57-a6a2-ac233b8d701b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_train_sequences:150, num_val_sequences:100, steps_per_epoch:19, validation_steps:13\n",
            "-----Batch0: size: 8\n",
            "Epoch 1/5\n",
            "-----Batch1: size: 8\n",
            " 1/19 [>.............................] - ETA: 14:49 - loss: 1.7663 - categorical_accuracy: 0.1250-----Batch2: size: 8\n",
            " 2/19 [==>...........................] - ETA: 13:56 - loss: 1.6438 - categorical_accuracy: 0.2500-----Batch3: size: 8\n",
            " 3/19 [===>..........................] - ETA: 11:31 - loss: 1.6581 - categorical_accuracy: 0.2083-----Batch4: size: 8\n",
            " 4/19 [=====>........................] - ETA: 10:16 - loss: 1.7629 - categorical_accuracy: 0.1875-----Batch5: size: 8\n",
            " 5/19 [======>.......................] - ETA: 9:25 - loss: 1.6212 - categorical_accuracy: 0.2750 -----Batch6: size: 8\n",
            " 6/19 [========>.....................] - ETA: 8:55 - loss: 1.6636 - categorical_accuracy: 0.2500-----Batch7: size: 8\n",
            " 7/19 [==========>...................] - ETA: 8:04 - loss: 1.6197 - categorical_accuracy: 0.2679-----Batch8: size: 8\n",
            " 8/19 [===========>..................] - ETA: 7:24 - loss: 1.6018 - categorical_accuracy: 0.2656-----Batch9: size: 8\n",
            " 9/19 [=============>................] - ETA: 6:47 - loss: 1.5908 - categorical_accuracy: 0.2500-----Batch10: size: 8\n",
            "10/19 [==============>...............] - ETA: 6:02 - loss: 1.5546 - categorical_accuracy: 0.2875-----Batch11: size: 8\n",
            "11/19 [================>.............] - ETA: 5:24 - loss: 1.5238 - categorical_accuracy: 0.3068-----Batch12: size: 8\n",
            "12/19 [=================>............] - ETA: 4:46 - loss: 1.4934 - categorical_accuracy: 0.3333-----Batch13: size: 8\n",
            "13/19 [===================>..........] - ETA: 4:03 - loss: 1.4869 - categorical_accuracy: 0.3365-----Batch14: size: 8\n",
            "14/19 [=====================>........] - ETA: 3:22 - loss: 1.4779 - categorical_accuracy: 0.3482-----Batch15: size: 8\n",
            "15/19 [======================>.......] - ETA: 2:41 - loss: 1.4567 - categorical_accuracy: 0.3667-----Batch16: size: 8\n",
            "16/19 [========================>.....] - ETA: 2:01 - loss: 1.4149 - categorical_accuracy: 0.3984-----Batch17: size: 8\n",
            "17/19 [=========================>....] - ETA: 1:20 - loss: 1.4079 - categorical_accuracy: 0.4044-----last Batch size: 6\n",
            "18/19 [===========================>..] - ETA: 40s - loss: 1.3933 - categorical_accuracy: 0.4167 -----Batch0: size: 8\n",
            "19/19 [==============================] - ETA: 0s - loss: 1.3981 - categorical_accuracy: 0.4133 -----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "\n",
            "Epoch 00001: saving model to model_init_2021-12-2815_39_25.497505\\model-00001-1.39808-0.41333-1.71831-0.24000.h5\n",
            "19/19 [==============================] - 833s 44s/step - loss: 1.3981 - categorical_accuracy: 0.4133 - val_loss: 1.7183 - val_categorical_accuracy: 0.2400 - lr: 1.0000e-04\n",
            "Epoch 2/5\n",
            "-----Batch1: size: 8\n",
            " 1/19 [>.............................] - ETA: 11:23 - loss: 0.5977 - categorical_accuracy: 1.0000-----Batch2: size: 8\n",
            " 2/19 [==>...........................] - ETA: 12:37 - loss: 0.5269 - categorical_accuracy: 1.0000-----Batch3: size: 8\n",
            " 3/19 [===>..........................] - ETA: 11:26 - loss: 0.5533 - categorical_accuracy: 1.0000-----Batch4: size: 8\n",
            " 4/19 [=====>........................] - ETA: 10:49 - loss: 0.5866 - categorical_accuracy: 0.9688-----Batch5: size: 8\n",
            " 5/19 [======>.......................] - ETA: 9:44 - loss: 0.5560 - categorical_accuracy: 0.9750 -----Batch6: size: 8\n",
            " 6/19 [========>.....................] - ETA: 8:53 - loss: 0.5672 - categorical_accuracy: 0.9583-----Batch7: size: 8\n",
            " 7/19 [==========>...................] - ETA: 8:24 - loss: 0.5902 - categorical_accuracy: 0.9464-----Batch8: size: 8\n",
            " 8/19 [===========>..................] - ETA: 7:35 - loss: 0.5640 - categorical_accuracy: 0.9531-----Batch9: size: 8\n",
            " 9/19 [=============>................] - ETA: 6:57 - loss: 0.5753 - categorical_accuracy: 0.9444-----Batch10: size: 8\n",
            "10/19 [==============>...............] - ETA: 6:13 - loss: 0.5699 - categorical_accuracy: 0.9500-----Batch11: size: 8\n",
            "11/19 [================>.............] - ETA: 5:36 - loss: 0.5674 - categorical_accuracy: 0.9545-----Batch12: size: 8\n",
            "12/19 [=================>............] - ETA: 4:52 - loss: 0.5648 - categorical_accuracy: 0.9479-----Batch13: size: 8\n",
            "13/19 [===================>..........] - ETA: 4:13 - loss: 0.5610 - categorical_accuracy: 0.9519-----Batch14: size: 8\n",
            "14/19 [=====================>........] - ETA: 3:32 - loss: 0.5626 - categorical_accuracy: 0.9554-----Batch15: size: 8\n",
            "15/19 [======================>.......] - ETA: 2:50 - loss: 0.5499 - categorical_accuracy: 0.9583-----Batch16: size: 8\n",
            "16/19 [========================>.....] - ETA: 2:06 - loss: 0.5449 - categorical_accuracy: 0.9609-----Batch17: size: 8\n",
            "17/19 [=========================>....] - ETA: 1:24 - loss: 0.5387 - categorical_accuracy: 0.9632-----last Batch size: 6\n",
            "18/19 [===========================>..] - ETA: 42s - loss: 0.5313 - categorical_accuracy: 0.9653 -----Batch0: size: 8\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.5251 - categorical_accuracy: 0.9667 -----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "\n",
            "Epoch 00002: saving model to model_init_2021-12-2815_39_25.497505\\model-00002-0.52509-0.96667-1.63803-0.20000.h5\n",
            "19/19 [==============================] - 853s 45s/step - loss: 0.5251 - categorical_accuracy: 0.9667 - val_loss: 1.6380 - val_categorical_accuracy: 0.2000 - lr: 1.0000e-04\n",
            "Epoch 3/5\n",
            "-----Batch1: size: 8\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-20-4ee4a6250406>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'categorical_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n\u001b[0m\u001b[0;32m      8\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                     validation_steps=validation_steps)\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "## ABLATION\n",
        "num_epochs = 5\n",
        "train_generator,val_generator,steps_per_epoch,validation_steps = sample_set(8,150,(180,180))\n",
        "callbacks_list = save_model('categorical_accuracy')\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.0001) \n",
        "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['categorical_accuracy'])\n",
        "model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "                    callbacks=callbacks_list, validation_data=val_generator, \n",
        "                    validation_steps=validation_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfLGZmszrcyN"
      },
      "source": [
        "Model is able to learn well with a learning rate of 0.0001. However, the number of trainable parameters is very high causing large training time. Since good accuracy can be achieved by other models with less trainable parameters, no need to pursue this model further."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhEdGaAGrcyN"
      },
      "source": [
        "#### Include all available frames for training:\n",
        "Include all available frames of videos for training purpose and observe the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYUeoH8rrcyN"
      },
      "outputs": [],
      "source": [
        "def generator_frame(source_path, folder_list, batch_size, exp_img_shape):\n",
        "    #print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
        "    img_idx = np.arange(0,30)\n",
        "    #print(img_idx) #create a list of image numbers you want to use for a particular video\n",
        "    x = len(img_idx)\n",
        "    y,z = exp_img_shape\n",
        "    while True:\n",
        "        t = np.random.permutation(folder_list)\n",
        "        num_batches = len(t)//batch_size # calculate the number of batches\n",
        "        \n",
        "        # Take each batch of video for further processing \n",
        "        for batch in range(num_batches): # we iterate over the number of batches\n",
        "            \n",
        "            batch_data = np.zeros((batch_size,x,y,z,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
        "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
        "           \n",
        "        # treat the frames in each video\n",
        "            for folder in range(batch_size): # iterate over the batch_size\n",
        "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
        "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
        "                    image = io.imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
        "                    \n",
        "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
        "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
        "                    image = resize(image, (y,z))\n",
        "                    \n",
        "                    batch_data[folder,idx,:,:,0] = image[:,:,0]/255 #normalise and feed in the image\n",
        "                    batch_data[folder,idx,:,:,1] = image[:,:,1]/255 #normalise and feed in the image\n",
        "                    batch_data[folder,idx,:,:,2] = image[:,:,2]/255 #normalise and feed in the image\n",
        "                    \n",
        "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
        "            print(\"-----Batch{0}: size: {1}\".format(batch,batch_size))\n",
        "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
        "\n",
        "\n",
        "        if ((len(t) % batch_size) != 0) and (batch == num_batches-1):\n",
        "            bs = len(t) - (num_batches*batch_size)\n",
        "            batch_data = np.zeros((bs,x,y,z,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
        "            batch_labels = np.zeros((bs,5)) # batch_labels is the one hot representation of the output\n",
        "        # treat the frames in each video\n",
        "            for folder in range(bs): # iterate over the batch_size\n",
        "                imgs = os.listdir(source_path+'/'+ t[folder + num_batches*batch_size].split(';')[0]) # read all the images in the folder\n",
        "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
        "                    image = io.imread(source_path+'/'+ t[folder + (num_batches*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
        "                    \n",
        "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
        "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
        "                    image = resize(image, (y,z))\n",
        "                    \n",
        "                    batch_data[folder,idx,:,:,0] = image[:,:,0]/255 #normalise and feed in the image\n",
        "                    batch_data[folder,idx,:,:,1] = image[:,:,1]/255 #normalise and feed in the image\n",
        "                    batch_data[folder,idx,:,:,2] = image[:,:,2]/255 #normalise and feed in the image\n",
        "                    \n",
        "                batch_labels[folder, int(t[folder + (num_batches*batch_size)].strip().split(';')[2])] = 1\n",
        "            print(\"-----last Batch size: {0}\".format(bs))\n",
        "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
        "\n",
        "            \n",
        "        # write the code for the remaining data points which are left after full batches\n",
        "def sample_set_frame(batch_size, set_size,exp_img_shape):\n",
        "    if set_size!= len(train_doc):\n",
        "        data_set = np.random.permutation(train_doc)[:set_size]\n",
        "    else:\n",
        "        data_set = train_doc.copy()\n",
        "    train_generator = generator_frame(train_path, data_set, batch_size,exp_img_shape)\n",
        "    val_generator = generator_frame(val_path, val_doc, batch_size,exp_img_shape)\n",
        "    num_train_sequences = len(data_set)\n",
        "    if (num_train_sequences%batch_size) == 0:\n",
        "        steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "    else:\n",
        "        steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "    if (num_val_sequences%batch_size) == 0:\n",
        "        validation_steps = int(num_val_sequences/batch_size)\n",
        "    else:\n",
        "        validation_steps = (num_val_sequences//batch_size) + 1\n",
        "    print('num_train_sequences:{0}, num_val_sequences:{1}, steps_per_epoch:{2}, validation_steps:{3}'.format(num_train_sequences,num_val_sequences,steps_per_epoch, validation_steps))\n",
        "    return (train_generator,val_generator,steps_per_epoch,validation_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqxgahKGrcyN"
      },
      "source": [
        "#### Model#6: Retrain last 10 layers of ResNet, with GRU on top of it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGs7Af9UrcyO"
      },
      "outputs": [],
      "source": [
        "# model 6\n",
        "resnet = ResNet50(include_top=False,weights='imagenet',input_shape=(180,180,3))\n",
        "for layer in resnet.layers[:-10]:\n",
        "    layer.trainable=False\n",
        "cnn =Sequential([resnet])\n",
        "cnn.add(Flatten())\n",
        "model = Sequential()\n",
        "model.add(TimeDistributed(cnn,input_shape=(30,180,180,3)))\n",
        "model.add(GRU(32,input_shape=(None,30,73728),return_sequences=True))\n",
        "model.add(GRU(64))\n",
        "model.add(Dense(5,activation='softmax'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-iZce2ZrcyO"
      },
      "outputs": [],
      "source": [
        "## ABLATION\n",
        "num_epochs = 8\n",
        "train_generator,val_generator,steps_per_epoch,validation_steps = sample_set_frame(8,150,(180,180))\n",
        "callbacks_list = save_model('accuracy')\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.001) \n",
        "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "SjupN4OyrcyO"
      },
      "outputs": [],
      "source": [
        "model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "                    callbacks=callbacks_list, validation_data=val_generator, \n",
        "                    validation_steps=validation_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLmCkzHXrcyO"
      },
      "source": [
        "Model is unable to overfit on smaller dataset itself. Need to change model layers and experiment. Since similar performance can be achieved with less number of frames, no need to pursue further with all 30 frames for training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2_eiXQfrcyO"
      },
      "source": [
        "#### Model#7: ResNet with last 15 layers to be retrained, image shape = 130x130x3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgOUIhbTrcyO"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "def res_rnn_1():\n",
        "    resnet = ResNet50(include_top=False,weights='imagenet',input_shape=(130,130,3))\n",
        "    for layer in resnet.layers[:-15]:\n",
        "        layer.trainable=False\n",
        "    cnn =Sequential([resnet])\n",
        "    cnn.add(Conv2D(512,(2,2),strides=(1,1)))\n",
        "    cnn.add(Conv2D(512,(2,2),strides=(1,1)))\n",
        "    cnn.add(MaxPooling2D(2,2))\n",
        "    cnn.add(Dense(128, activation ='relu'))\n",
        "    cnn.add(Dense(128, activation ='relu'))\n",
        "    cnn.add(Flatten())\n",
        "    print(cnn.summary())\n",
        "    model = Sequential()\n",
        "    model.add(TimeDistributed(cnn,input_shape=(15,130,130,3)))\n",
        "    model.add(GRU(128,input_shape=(None,15,128),return_sequences=True))\n",
        "    model.add(GRU(128, return_sequences = True))\n",
        "    model.add(GRU(64))\n",
        "    model.add(Dense(5,activation='softmax'))\n",
        "    print(model.summary())\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbY7t9mHrcyP",
        "outputId": "80a697f1-6e6e-4f4c-90fc-222dfd966342"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 5, 5, 2048)        23587712  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 4, 4, 512)         4194816   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 3, 3, 512)         1049088   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 1, 1, 512)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1, 1, 128)         65664     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1, 1, 128)         16512     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 128)               0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28,913,792\n",
            "Trainable params: 10,846,464\n",
            "Non-trainable params: 18,067,328\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " time_distributed (TimeDistr  (None, 15, 128)          28913792  \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 15, 128)           99072     \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 15, 128)           99072     \n",
            "                                                                 \n",
            " gru_2 (GRU)                 (None, 64)                37248     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 29,149,509\n",
            "Trainable params: 11,082,181\n",
            "Non-trainable params: 18,067,328\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model = res_rnn_1()\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.001) \n",
        "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A18MMuJ5rcyP",
        "outputId": "442aa090-4e49-4082-a1f5-de91af496c54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_train_sequences:100, num_val_sequences:100, steps_per_epoch:13, validation_steps:13\n"
          ]
        }
      ],
      "source": [
        "## ABLATION\n",
        "num_epochs = 5\n",
        "train_generator,val_generator,steps_per_epoch,validation_steps = sample_set(8,100,(130,130))\n",
        "callbacks_list = save_model('accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVhDxYmdrcyP",
        "outputId": "8936027e-fbf8-4571-8c58-2d1bf9696ea3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----Batch0: size: 8\n",
            "Epoch 1/5\n",
            "-----Batch1: size: 8\n",
            " 1/13 [=>............................] - ETA: 4:04 - loss: 1.5353 - accuracy: 0.2500-----Batch2: size: 8\n",
            " 2/13 [===>..........................] - ETA: 2:09 - loss: 1.6554 - accuracy: 0.2500-----Batch3: size: 8\n",
            " 3/13 [=====>........................] - ETA: 1:57 - loss: 1.7009 - accuracy: 0.2083-----Batch4: size: 8\n",
            " 4/13 [========>.....................] - ETA: 1:45 - loss: 1.7111 - accuracy: 0.2188-----Batch5: size: 8\n",
            " 5/13 [==========>...................] - ETA: 1:34 - loss: 1.7263 - accuracy: 0.2000-----Batch6: size: 8\n",
            " 6/13 [============>.................] - ETA: 1:22 - loss: 1.7377 - accuracy: 0.1875-----Batch7: size: 8\n",
            " 7/13 [===============>..............] - ETA: 1:10 - loss: 1.7228 - accuracy: 0.1786-----Batch8: size: 8\n",
            " 8/13 [=================>............] - ETA: 59s - loss: 1.7177 - accuracy: 0.1719 -----Batch9: size: 8\n",
            " 9/13 [===================>..........] - ETA: 47s - loss: 1.7412 - accuracy: 0.1528-----Batch10: size: 8\n",
            "10/13 [======================>.......] - ETA: 35s - loss: 1.7414 - accuracy: 0.1625-----Batch11: size: 8\n",
            "11/13 [========================>.....] - ETA: 23s - loss: 1.7846 - accuracy: 0.1477-----last Batch size: 4\n",
            "12/13 [==========================>...] - ETA: 11s - loss: 1.7683 - accuracy: 0.1667-----Batch0: size: 8\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7666 - accuracy: 0.1800 -----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "\n",
            "Epoch 00001: saving model to model_init_2021-12-2908_20_25.120741\\model-00001-1.76656-0.18000-1.67474-0.22000.h5\n",
            "13/13 [==============================] - 234s 18s/step - loss: 1.7666 - accuracy: 0.1800 - val_loss: 1.6747 - val_accuracy: 0.2200 - lr: 0.0010\n",
            "Epoch 2/5\n",
            "-----Batch1: size: 8\n",
            " 1/13 [=>............................] - ETA: 2:12 - loss: 1.6763 - accuracy: 0.1250-----Batch2: size: 8\n",
            " 2/13 [===>..........................] - ETA: 2:10 - loss: 1.7476 - accuracy: 0.1250-----Batch3: size: 8\n",
            " 3/13 [=====>........................] - ETA: 1:57 - loss: 1.7416 - accuracy: 0.1250-----Batch4: size: 8\n",
            " 4/13 [========>.....................] - ETA: 1:46 - loss: 1.7487 - accuracy: 0.1250-----Batch5: size: 8\n",
            " 5/13 [==========>...................] - ETA: 1:34 - loss: 1.7377 - accuracy: 0.1500-----Batch6: size: 8\n",
            " 6/13 [============>.................] - ETA: 1:22 - loss: 1.7476 - accuracy: 0.1250-----Batch7: size: 8\n",
            " 7/13 [===============>..............] - ETA: 1:10 - loss: 1.7441 - accuracy: 0.1071-----Batch8: size: 8\n",
            " 8/13 [=================>............] - ETA: 58s - loss: 1.7467 - accuracy: 0.0938 -----Batch9: size: 8\n",
            " 9/13 [===================>..........] - ETA: 47s - loss: 1.7246 - accuracy: 0.1250-----Batch10: size: 8\n",
            "10/13 [======================>.......] - ETA: 35s - loss: 1.7197 - accuracy: 0.1250-----Batch11: size: 8\n",
            "11/13 [========================>.....] - ETA: 23s - loss: 1.7156 - accuracy: 0.1250-----last Batch size: 4\n",
            "12/13 [==========================>...] - ETA: 11s - loss: 1.7082 - accuracy: 0.1250-----Batch0: size: 8\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7068 - accuracy: 0.1200 -----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "\n",
            "Epoch 00002: saving model to model_init_2021-12-2908_20_25.120741\\model-00002-1.70684-0.12000-1.63553-0.21000.h5\n",
            "13/13 [==============================] - 220s 17s/step - loss: 1.7068 - accuracy: 0.1200 - val_loss: 1.6355 - val_accuracy: 0.2100 - lr: 0.0010\n",
            "Epoch 3/5\n",
            "-----Batch1: size: 8\n",
            " 1/13 [=>............................] - ETA: 2:16 - loss: 1.5925 - accuracy: 0.1250-----Batch2: size: 8\n",
            " 2/13 [===>..........................] - ETA: 2:04 - loss: 1.6522 - accuracy: 0.1875-----Batch3: size: 8\n",
            " 3/13 [=====>........................] - ETA: 1:54 - loss: 1.6116 - accuracy: 0.2500-----Batch4: size: 8\n",
            " 4/13 [========>.....................] - ETA: 1:43 - loss: 1.5277 - accuracy: 0.3125-----Batch5: size: 8\n",
            " 5/13 [==========>...................] - ETA: 1:32 - loss: 1.5791 - accuracy: 0.2750-----Batch6: size: 8\n",
            " 6/13 [============>.................] - ETA: 1:21 - loss: 1.6651 - accuracy: 0.2292-----Batch7: size: 8\n",
            " 7/13 [===============>..............] - ETA: 1:09 - loss: 1.6924 - accuracy: 0.2143-----Batch8: size: 8\n",
            " 8/13 [=================>............] - ETA: 58s - loss: 1.7137 - accuracy: 0.2031 -----Batch9: size: 8\n",
            " 9/13 [===================>..........] - ETA: 46s - loss: 1.7093 - accuracy: 0.2083-----Batch10: size: 8\n",
            "10/13 [======================>.......] - ETA: 34s - loss: 1.7205 - accuracy: 0.2000-----Batch11: size: 8\n",
            "11/13 [========================>.....] - ETA: 23s - loss: 1.7342 - accuracy: 0.1818-----last Batch size: 4\n",
            "12/13 [==========================>...] - ETA: 11s - loss: 1.7265 - accuracy: 0.1771-----Batch0: size: 8\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7256 - accuracy: 0.1800 -----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "\n",
            "Epoch 00003: saving model to model_init_2021-12-2908_20_25.120741\\model-00003-1.72564-0.18000-1.71436-0.19000.h5\n",
            "13/13 [==============================] - 217s 17s/step - loss: 1.7256 - accuracy: 0.1800 - val_loss: 1.7144 - val_accuracy: 0.1900 - lr: 0.0010\n",
            "Epoch 4/5\n",
            "-----Batch1: size: 8\n",
            " 1/13 [=>............................] - ETA: 2:19 - loss: 1.6732 - accuracy: 0.0000e+00-----Batch2: size: 8\n",
            " 2/13 [===>..........................] - ETA: 2:08 - loss: 1.7319 - accuracy: 0.1250    -----Batch3: size: 8\n",
            " 3/13 [=====>........................] - ETA: 1:56 - loss: 1.6766 - accuracy: 0.2083-----Batch4: size: 8\n",
            " 4/13 [========>.....................] - ETA: 1:44 - loss: 1.7350 - accuracy: 0.1875-----Batch5: size: 8\n",
            " 5/13 [==========>...................] - ETA: 1:33 - loss: 1.7969 - accuracy: 0.1500-----Batch6: size: 8\n",
            " 6/13 [============>.................] - ETA: 1:22 - loss: 1.8044 - accuracy: 0.1458-----Batch7: size: 8\n",
            " 7/13 [===============>..............] - ETA: 1:10 - loss: 1.7610 - accuracy: 0.1607-----Batch8: size: 8\n",
            " 8/13 [=================>............] - ETA: 58s - loss: 1.7267 - accuracy: 0.1719 -----Batch9: size: 8\n",
            " 9/13 [===================>..........] - ETA: 46s - loss: 1.7335 - accuracy: 0.1667-----Batch10: size: 8\n",
            "10/13 [======================>.......] - ETA: 35s - loss: 1.7235 - accuracy: 0.1750-----Batch11: size: 8\n",
            "11/13 [========================>.....] - ETA: 23s - loss: 1.7237 - accuracy: 0.1591-----last Batch size: 4\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.7367 - accuracy: 0.1500 -----Batch0: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "\n",
            "Epoch 00004: saving model to model_init_2021-12-2908_20_25.120741\\model-00004-1.73667-0.15000-1.63191-0.22000.h5\n",
            "13/13 [==============================] - 219s 17s/step - loss: 1.7367 - accuracy: 0.1500 - val_loss: 1.6319 - val_accuracy: 0.2200 - lr: 0.0010\n",
            "Epoch 5/5\n",
            "-----Batch1: size: 8\n",
            " 1/13 [=>............................] - ETA: 2:18 - loss: 1.6159 - accuracy: 0.2500-----Batch2: size: 8\n",
            " 2/13 [===>..........................] - ETA: 2:03 - loss: 1.6317 - accuracy: 0.1250-----Batch3: size: 8\n",
            " 3/13 [=====>........................] - ETA: 1:54 - loss: 1.6476 - accuracy: 0.1667-----Batch4: size: 8\n",
            " 4/13 [========>.....................] - ETA: 1:44 - loss: 1.6548 - accuracy: 0.1562-----Batch5: size: 8\n",
            " 5/13 [==========>...................] - ETA: 1:33 - loss: 1.6434 - accuracy: 0.1750-----Batch6: size: 8\n",
            " 6/13 [============>.................] - ETA: 1:21 - loss: 1.6375 - accuracy: 0.2292-----Batch7: size: 8\n",
            " 7/13 [===============>..............] - ETA: 1:09 - loss: 1.6379 - accuracy: 0.2321-----Batch8: size: 8\n",
            " 8/13 [=================>............] - ETA: 58s - loss: 1.6566 - accuracy: 0.2188 -----Batch9: size: 8\n",
            " 9/13 [===================>..........] - ETA: 46s - loss: 1.6602 - accuracy: 0.2083-----Batch10: size: 8\n",
            "10/13 [======================>.......] - ETA: 35s - loss: 1.6537 - accuracy: 0.2125-----Batch11: size: 8\n",
            "11/13 [========================>.....] - ETA: 23s - loss: 1.6579 - accuracy: 0.1932-----last Batch size: 4\n",
            "12/13 [==========================>...] - ETA: 11s - loss: 1.6669 - accuracy: 0.1771-----Batch0: size: 8\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6641 - accuracy: 0.1800 -----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "\n",
            "Epoch 00005: saving model to model_init_2021-12-2908_20_25.120741\\model-00005-1.66410-0.18000-1.63714-0.21000.h5\n",
            "13/13 [==============================] - 220s 17s/step - loss: 1.6641 - accuracy: 0.1800 - val_loss: 1.6371 - val_accuracy: 0.2100 - lr: 0.0010\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1ee8f298760>"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "                    callbacks=callbacks_list, validation_data=val_generator, \n",
        "                    validation_steps=validation_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGc86mzqrcyP"
      },
      "source": [
        "Observations:\n",
        "- Model is unable to overfit on sample dataset itself."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCMZoDPmrcyP"
      },
      "source": [
        "### Transfer learning: CNN (Resnet) + RNN (LSTM)\n",
        "#### Model#8: All Resnet layers to be retrained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jb0gL8ORrcyQ",
        "outputId": "23f0b0d1-ee00-46fe-a9c6-2ddd42e09f2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 6, 6, 2048)        23587712  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 5, 5, 32)          262176    \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 4, 4, 64)          8256      \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 3, 3, 128)         32896     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1152)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,891,040\n",
            "Trainable params: 23,837,920\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "def res_lstm():\n",
        "    res = ResNet50(include_top = False,weights = 'imagenet', input_shape = (180,180,3))\n",
        "    res_cnn = Sequential([res])\n",
        "    res_cnn.add(Conv2D(32, (2,2), strides = 1, activation = 'relu'))\n",
        "    res_cnn.add(Conv2D(64,(2,2), strides =1, activation = 'relu'))\n",
        "    res_cnn.add(Conv2D(128,(2,2),strides =1, activation ='relu'))\n",
        "    res_cnn.add(Flatten())\n",
        "    print(res_cnn.summary())\n",
        "    model = Sequential()\n",
        "    model.add(TimeDistributed(res_cnn,input_shape=(15,180,180,3)))\n",
        "    model.add(LSTM(32,input_shape=(None,15,1152),return_sequences=True))\n",
        "    model.add(LSTM(64))\n",
        "    model.add(Dense(5,activation='softmax'))\n",
        "    print(model.summary())\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaHmkqaJrcyQ"
      },
      "outputs": [],
      "source": [
        "model = res_lstm()\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.01) \n",
        "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbMq8ZsQrcyQ",
        "outputId": "2febc41c-d0f5-4891-e979-53fc85c84f72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_train_sequences:150, num_val_sequences:100, steps_per_epoch:19, validation_steps:13\n"
          ]
        }
      ],
      "source": [
        "## ABLATION\n",
        "num_epochs = 10\n",
        "train_generator,val_generator,steps_per_epoch,validation_steps = sample_set(8,150,(180,180))\n",
        "callbacks_list = save_model('accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKpN-K1SrcyQ",
        "outputId": "afbe0769-3cd6-4abd-b189-06a2378d84b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----Batch0: size: 8\n",
            "Epoch 1/10\n",
            "-----Batch1: size: 8\n",
            " 1/19 [>.............................] - ETA: 20:28 - loss: 1.6460 - accuracy: 0.1250-----Batch2: size: 8\n",
            " 2/19 [==>...........................] - ETA: 14:20 - loss: 1.9932 - accuracy: 0.0625-----Batch3: size: 8\n",
            " 3/19 [===>..........................] - ETA: 13:22 - loss: 1.9585 - accuracy: 0.0417-----Batch4: size: 8\n",
            " 4/19 [=====>........................] - ETA: 12:08 - loss: 1.8487 - accuracy: 0.0938-----Batch5: size: 8\n",
            " 5/19 [======>.......................] - ETA: 11:03 - loss: 1.8652 - accuracy: 0.0750-----Batch6: size: 8\n",
            " 6/19 [========>.....................] - ETA: 10:09 - loss: 1.8506 - accuracy: 0.0833-----Batch7: size: 8\n",
            " 7/19 [==========>...................] - ETA: 9:14 - loss: 1.7983 - accuracy: 0.1071 -----Batch8: size: 8\n",
            " 8/19 [===========>..................] - ETA: 8:21 - loss: 1.8094 - accuracy: 0.1094-----Batch9: size: 8\n",
            " 9/19 [=============>................] - ETA: 7:26 - loss: 1.8072 - accuracy: 0.1111-----Batch10: size: 8\n",
            "10/19 [==============>...............] - ETA: 6:34 - loss: 1.7968 - accuracy: 0.1125-----Batch11: size: 8\n",
            "11/19 [================>.............] - ETA: 5:50 - loss: 1.7764 - accuracy: 0.1364-----Batch12: size: 8\n",
            "12/19 [=================>............] - ETA: 5:06 - loss: 1.7591 - accuracy: 0.1354-----Batch13: size: 8\n",
            "13/19 [===================>..........] - ETA: 4:28 - loss: 1.7586 - accuracy: 0.1250-----Batch14: size: 8\n",
            "14/19 [=====================>........] - ETA: 3:42 - loss: 1.7534 - accuracy: 0.1250-----Batch15: size: 8\n",
            "15/19 [======================>.......] - ETA: 2:58 - loss: 1.7437 - accuracy: 0.1333-----Batch16: size: 8\n",
            "16/19 [========================>.....] - ETA: 2:13 - loss: 1.7343 - accuracy: 0.1406-----Batch17: size: 8\n",
            "17/19 [=========================>....] - ETA: 1:28 - loss: 1.7307 - accuracy: 0.1397-----last Batch size: 6\n",
            "18/19 [===========================>..] - ETA: 44s - loss: 1.7278 - accuracy: 0.1389 -----Batch0: size: 8\n",
            "19/19 [==============================] - ETA: 0s - loss: 1.7265 - accuracy: 0.1400 -----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "\n",
            "Epoch 00001: saving model to model_init_2021-12-2723_21_03.800788\\model-00001-1.72655-0.14000-1.63777-0.21000.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\veena\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19/19 [==============================] - 917s 47s/step - loss: 1.7265 - accuracy: 0.1400 - val_loss: 1.6378 - val_accuracy: 0.2100 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "-----Batch1: size: 8\n",
            " 1/19 [>.............................] - ETA: 13:33 - loss: 1.6751 - accuracy: 0.1250-----Batch2: size: 8\n",
            " 2/19 [==>...........................] - ETA: 12:13 - loss: 1.6359 - accuracy: 0.1250-----Batch3: size: 8\n",
            " 3/19 [===>..........................] - ETA: 10:40 - loss: 1.6729 - accuracy: 0.1250-----Batch4: size: 8\n",
            " 4/19 [=====>........................] - ETA: 9:41 - loss: 1.6650 - accuracy: 0.1250 -----Batch5: size: 8\n",
            " 5/19 [======>.......................] - ETA: 10:04 - loss: 1.6798 - accuracy: 0.1250-----Batch6: size: 8\n",
            " 6/19 [========>.....................] - ETA: 9:21 - loss: 1.6862 - accuracy: 0.1458 -----Batch7: size: 8\n",
            " 7/19 [==========>...................] - ETA: 8:34 - loss: 1.6781 - accuracy: 0.1250-----Batch8: size: 8\n",
            " 8/19 [===========>..................] - ETA: 7:51 - loss: 1.6734 - accuracy: 0.1406-----Batch9: size: 8\n",
            " 9/19 [=============>................] - ETA: 6:59 - loss: 1.6639 - accuracy: 0.1528-----Batch10: size: 8\n",
            "10/19 [==============>...............] - ETA: 6:17 - loss: 1.6595 - accuracy: 0.1625-----Batch11: size: 8\n",
            "11/19 [================>.............] - ETA: 5:39 - loss: 1.6583 - accuracy: 0.1705-----Batch12: size: 8\n",
            "12/19 [=================>............] - ETA: 4:55 - loss: 1.6563 - accuracy: 0.1667-----Batch13: size: 8\n",
            "13/19 [===================>..........] - ETA: 4:12 - loss: 1.6574 - accuracy: 0.1635-----Batch14: size: 8\n",
            "14/19 [=====================>........] - ETA: 3:29 - loss: 1.6568 - accuracy: 0.1696-----Batch15: size: 8\n",
            "15/19 [======================>.......] - ETA: 2:47 - loss: 1.6552 - accuracy: 0.1750-----Batch16: size: 8\n",
            "16/19 [========================>.....] - ETA: 2:05 - loss: 1.6537 - accuracy: 0.1719-----Batch17: size: 8\n",
            "17/19 [=========================>....] - ETA: 1:23 - loss: 1.6539 - accuracy: 0.1618-----last Batch size: 6\n",
            "18/19 [===========================>..] - ETA: 41s - loss: 1.6538 - accuracy: 0.1597 -----Batch0: size: 8\n",
            "19/19 [==============================] - ETA: 0s - loss: 1.6498 - accuracy: 0.1733 -----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "\n",
            "Epoch 00002: saving model to model_init_2021-12-2723_21_03.800788\\model-00002-1.64981-0.17333-1.61241-0.21000.h5\n",
            "19/19 [==============================] - 854s 45s/step - loss: 1.6498 - accuracy: 0.1733 - val_loss: 1.6124 - val_accuracy: 0.2100 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "-----Batch1: size: 8\n",
            " 1/19 [>.............................] - ETA: 13:28 - loss: 1.6593 - accuracy: 0.1250-----Batch2: size: 8\n",
            " 2/19 [==>...........................] - ETA: 12:49 - loss: 1.6303 - accuracy: 0.1875-----Batch3: size: 8\n",
            " 3/19 [===>..........................] - ETA: 11:52 - loss: 1.6119 - accuracy: 0.1667-----Batch4: size: 8\n",
            " 4/19 [=====>........................] - ETA: 11:16 - loss: 1.6152 - accuracy: 0.1562-----Batch5: size: 8\n",
            " 5/19 [======>.......................] - ETA: 10:25 - loss: 1.6053 - accuracy: 0.2250-----Batch6: size: 8\n",
            " 6/19 [========>.....................] - ETA: 9:28 - loss: 1.6006 - accuracy: 0.2292 -----Batch7: size: 8\n",
            " 7/19 [==========>...................] - ETA: 8:42 - loss: 1.5956 - accuracy: 0.2321-----Batch8: size: 8\n",
            " 8/19 [===========>..................] - ETA: 7:49 - loss: 1.5942 - accuracy: 0.2344-----Batch9: size: 8\n",
            " 9/19 [=============>................] - ETA: 7:08 - loss: 1.5795 - accuracy: 0.2639-----Batch10: size: 8\n",
            "10/19 [==============>...............] - ETA: 6:22 - loss: 1.5711 - accuracy: 0.3000-----Batch11: size: 8\n",
            "11/19 [================>.............] - ETA: 5:34 - loss: 1.5821 - accuracy: 0.2955-----Batch12: size: 8\n",
            "12/19 [=================>............] - ETA: 4:53 - loss: 1.6095 - accuracy: 0.2708-----Batch13: size: 8\n",
            "13/19 [===================>..........] - ETA: 4:13 - loss: 1.6155 - accuracy: 0.2596-----Batch14: size: 8\n",
            "14/19 [=====================>........] - ETA: 3:36 - loss: 1.6169 - accuracy: 0.2589-----Batch15: size: 8\n",
            "15/19 [======================>.......] - ETA: 2:53 - loss: 1.6215 - accuracy: 0.2500-----Batch16: size: 8\n",
            "16/19 [========================>.....] - ETA: 2:10 - loss: 1.6062 - accuracy: 0.2734-----Batch17: size: 8\n",
            "17/19 [=========================>....] - ETA: 1:26 - loss: 1.6130 - accuracy: 0.2647-----last Batch size: 6\n",
            "18/19 [===========================>..] - ETA: 43s - loss: 1.6179 - accuracy: 0.2569 -----Batch0: size: 8\n",
            "19/19 [==============================] - ETA: 0s - loss: 1.6258 - accuracy: 0.2467 -----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "\n",
            "Epoch 00003: saving model to model_init_2021-12-2723_21_03.800788\\model-00003-1.62583-0.24667-1.62223-0.23000.h5\n",
            "19/19 [==============================] - 873s 46s/step - loss: 1.6258 - accuracy: 0.2467 - val_loss: 1.6222 - val_accuracy: 0.2300 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "-----Batch1: size: 8\n",
            " 1/19 [>.............................] - ETA: 10:43 - loss: 1.7515 - accuracy: 0.0000e+00-----Batch2: size: 8\n",
            " 2/19 [==>...........................] - ETA: 11:05 - loss: 1.6420 - accuracy: 0.1875    -----Batch3: size: 8\n",
            " 3/19 [===>..........................] - ETA: 10:43 - loss: 1.6249 - accuracy: 0.2083-----Batch4: size: 8\n",
            " 4/19 [=====>........................] - ETA: 9:47 - loss: 1.6361 - accuracy: 0.1875 -----Batch5: size: 8\n",
            " 5/19 [======>.......................] - ETA: 9:21 - loss: 1.6010 - accuracy: 0.2750-----Batch6: size: 8\n",
            " 6/19 [========>.....................] - ETA: 9:25 - loss: 1.6157 - accuracy: 0.2292-----Batch7: size: 8\n",
            " 7/19 [==========>...................] - ETA: 8:55 - loss: 1.6150 - accuracy: 0.2321-----Batch8: size: 8\n",
            " 8/19 [===========>..................] - ETA: 8:16 - loss: 1.6196 - accuracy: 0.2188-----Batch9: size: 8\n",
            " 9/19 [=============>................] - ETA: 7:31 - loss: 1.6178 - accuracy: 0.2222-----Batch10: size: 8\n",
            "10/19 [==============>...............] - ETA: 6:45 - loss: 1.6109 - accuracy: 0.2375-----Batch11: size: 8\n",
            "11/19 [================>.............] - ETA: 5:59 - loss: 1.6094 - accuracy: 0.2386-----Batch12: size: 8\n",
            "12/19 [=================>............] - ETA: 5:13 - loss: 1.6067 - accuracy: 0.2396-----Batch13: size: 8\n",
            "13/19 [===================>..........] - ETA: 4:33 - loss: 1.6069 - accuracy: 0.2404-----Batch14: size: 8\n",
            "14/19 [=====================>........] - ETA: 3:49 - loss: 1.6103 - accuracy: 0.2411-----Batch15: size: 8\n",
            "15/19 [======================>.......] - ETA: 3:03 - loss: 1.6125 - accuracy: 0.2417-----Batch16: size: 8\n",
            "16/19 [========================>.....] - ETA: 2:16 - loss: 1.6112 - accuracy: 0.2500-----Batch17: size: 8\n",
            "17/19 [=========================>....] - ETA: 1:32 - loss: 1.6151 - accuracy: 0.2500-----last Batch size: 6\n",
            "18/19 [===========================>..] - ETA: 46s - loss: 1.6149 - accuracy: 0.2569 -----Batch0: size: 8\n",
            "19/19 [==============================] - ETA: 0s - loss: 1.6181 - accuracy: 0.2467 -----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "\n",
            "Epoch 00004: saving model to model_init_2021-12-2723_21_03.800788\\model-00004-1.61807-0.24667-1.62244-0.17000.h5\n",
            "19/19 [==============================] - 911s 49s/step - loss: 1.6181 - accuracy: 0.2467 - val_loss: 1.6224 - val_accuracy: 0.1700 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "-----Batch1: size: 8\n",
            " 1/19 [>.............................] - ETA: 10:37 - loss: 1.6066 - accuracy: 0.2500-----Batch2: size: 8\n",
            " 2/19 [==>...........................] - ETA: 10:50 - loss: 1.6111 - accuracy: 0.1250-----Batch3: size: 8\n",
            " 3/19 [===>..........................] - ETA: 10:45 - loss: 1.6187 - accuracy: 0.0833-----Batch4: size: 8\n",
            " 4/19 [=====>........................] - ETA: 9:58 - loss: 1.6041 - accuracy: 0.1875 -----Batch5: size: 8\n",
            " 5/19 [======>.......................] - ETA: 9:14 - loss: 1.5969 - accuracy: 0.2250-----Batch6: size: 8\n",
            " 6/19 [========>.....................] - ETA: 8:47 - loss: 1.6083 - accuracy: 0.2083-----Batch7: size: 8\n",
            " 7/19 [==========>...................] - ETA: 8:13 - loss: 1.6077 - accuracy: 0.2321-----Batch8: size: 8\n",
            " 8/19 [===========>..................] - ETA: 7:24 - loss: 1.6089 - accuracy: 0.2500-----Batch9: size: 8\n",
            " 9/19 [=============>................] - ETA: 6:48 - loss: 1.6093 - accuracy: 0.2639-----Batch10: size: 8\n",
            "10/19 [==============>...............] - ETA: 6:09 - loss: 1.6110 - accuracy: 0.2625-----Batch11: size: 8\n",
            "11/19 [================>.............] - ETA: 5:32 - loss: 1.6097 - accuracy: 0.2727-----Batch12: size: 8\n",
            "12/19 [=================>............] - ETA: 4:47 - loss: 1.6126 - accuracy: 0.2604-----Batch13: size: 8\n",
            "13/19 [===================>..........] - ETA: 4:07 - loss: 1.6124 - accuracy: 0.2596-----Batch14: size: 8\n",
            "14/19 [=====================>........] - ETA: 3:27 - loss: 1.6156 - accuracy: 0.2411-----Batch15: size: 8\n",
            "15/19 [======================>.......] - ETA: 2:45 - loss: 1.6142 - accuracy: 0.2417-----Batch16: size: 8\n",
            "16/19 [========================>.....] - ETA: 2:02 - loss: 1.6139 - accuracy: 0.2422-----Batch17: size: 8\n",
            "17/19 [=========================>....] - ETA: 1:23 - loss: 1.6104 - accuracy: 0.2574-----last Batch size: 6\n",
            "18/19 [===========================>..] - ETA: 41s - loss: 1.6102 - accuracy: 0.2569 -----Batch0: size: 8\n",
            "19/19 [==============================] - ETA: 0s - loss: 1.6135 - accuracy: 0.2467 -----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "\n",
            "Epoch 00005: saving model to model_init_2021-12-2723_21_03.800788\\model-00005-1.61351-0.24667-1.62218-0.18000.h5\n",
            "19/19 [==============================] - 832s 44s/step - loss: 1.6135 - accuracy: 0.2467 - val_loss: 1.6222 - val_accuracy: 0.1800 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "-----Batch1: size: 8\n",
            " 1/19 [>.............................] - ETA: 10:45 - loss: 1.6283 - accuracy: 0.1250-----Batch2: size: 8\n",
            " 2/19 [==>...........................] - ETA: 10:52 - loss: 1.5842 - accuracy: 0.2500-----Batch3: size: 8\n",
            " 3/19 [===>..........................] - ETA: 10:43 - loss: 1.5761 - accuracy: 0.2917-----Batch4: size: 8\n",
            " 4/19 [=====>........................] - ETA: 10:14 - loss: 1.5886 - accuracy: 0.2500-----Batch5: size: 8\n",
            " 5/19 [======>.......................] - ETA: 9:16 - loss: 1.5804 - accuracy: 0.3250 -----Batch6: size: 8\n",
            " 6/19 [========>.....................] - ETA: 8:35 - loss: 1.5833 - accuracy: 0.3125-----Batch7: size: 8\n",
            " 7/19 [==========>...................] - ETA: 7:55 - loss: 1.5729 - accuracy: 0.3571-----Batch8: size: 8\n",
            " 8/19 [===========>..................] - ETA: 7:08 - loss: 1.5743 - accuracy: 0.3438-----Batch9: size: 8\n",
            " 9/19 [=============>................] - ETA: 6:36 - loss: 1.5810 - accuracy: 0.3333-----Batch10: size: 8\n",
            "10/19 [==============>...............] - ETA: 6:02 - loss: 1.5898 - accuracy: 0.3125-----Batch11: size: 8\n",
            "11/19 [================>.............] - ETA: 5:21 - loss: 1.5954 - accuracy: 0.2955-----Batch12: size: 8\n",
            "12/19 [=================>............] - ETA: 4:41 - loss: 1.5991 - accuracy: 0.2917-----Batch13: size: 8\n",
            "13/19 [===================>..........] - ETA: 3:59 - loss: 1.6040 - accuracy: 0.2788-----Batch14: size: 8\n",
            "14/19 [=====================>........] - ETA: 3:21 - loss: 1.6082 - accuracy: 0.2679-----Batch15: size: 8\n",
            "15/19 [======================>.......] - ETA: 2:41 - loss: 1.6109 - accuracy: 0.2667-----Batch16: size: 8\n",
            "16/19 [========================>.....] - ETA: 2:01 - loss: 1.6112 - accuracy: 0.2578-----Batch17: size: 8\n",
            "17/19 [=========================>....] - ETA: 1:21 - loss: 1.6152 - accuracy: 0.2500-----last Batch size: 6\n",
            "18/19 [===========================>..] - ETA: 40s - loss: 1.6137 - accuracy: 0.2500 -----Batch0: size: 8\n",
            "19/19 [==============================] - ETA: 0s - loss: 1.6154 - accuracy: 0.2467 -----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "\n",
            "Epoch 00006: saving model to model_init_2021-12-2723_21_03.800788\\model-00006-1.61540-0.24667-1.58264-0.31000.h5\n",
            "19/19 [==============================] - 813s 43s/step - loss: 1.6154 - accuracy: 0.2467 - val_loss: 1.5826 - val_accuracy: 0.3100 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "-----Batch1: size: 8\n",
            " 1/19 [>.............................] - ETA: 11:30 - loss: 1.6766 - accuracy: 0.0000e+00-----Batch2: size: 8\n",
            " 2/19 [==>...........................] - ETA: 12:00 - loss: 1.6798 - accuracy: 0.0000e+00-----Batch3: size: 8\n",
            " 3/19 [===>..........................] - ETA: 10:50 - loss: 1.6476 - accuracy: 0.1250    -----Batch4: size: 8\n",
            " 4/19 [=====>........................] - ETA: 10:16 - loss: 1.6362 - accuracy: 0.1562-----Batch5: size: 8\n",
            " 5/19 [======>.......................] - ETA: 9:19 - loss: 1.6379 - accuracy: 0.1500 -----Batch6: size: 8\n",
            " 6/19 [========>.....................] - ETA: 8:30 - loss: 1.6363 - accuracy: 0.1458-----Batch7: size: 8\n",
            " 7/19 [==========>...................] - ETA: 7:59 - loss: 1.6320 - accuracy: 0.1429-----Batch8: size: 8\n",
            " 8/19 [===========>..................] - ETA: 7:15 - loss: 1.6277 - accuracy: 0.1719-----Batch9: size: 8\n",
            " 9/19 [=============>................] - ETA: 6:32 - loss: 1.6261 - accuracy: 0.1806-----Batch10: size: 8\n",
            "10/19 [==============>...............] - ETA: 5:57 - loss: 1.6248 - accuracy: 0.1875-----Batch11: size: 8\n",
            "11/19 [================>.............] - ETA: 5:14 - loss: 1.6208 - accuracy: 0.2159-----Batch12: size: 8\n",
            "12/19 [=================>............] - ETA: 4:41 - loss: 1.6215 - accuracy: 0.2083-----Batch13: size: 8\n",
            "13/19 [===================>..........] - ETA: 4:02 - loss: 1.6202 - accuracy: 0.2115-----Batch14: size: 8\n",
            "14/19 [=====================>........] - ETA: 3:23 - loss: 1.6188 - accuracy: 0.2054-----Batch15: size: 8\n",
            "15/19 [======================>.......] - ETA: 2:42 - loss: 1.6169 - accuracy: 0.2000-----Batch16: size: 8\n",
            "16/19 [========================>.....] - ETA: 2:02 - loss: 1.6169 - accuracy: 0.2031-----Batch17: size: 8\n",
            "17/19 [=========================>....] - ETA: 1:22 - loss: 1.6161 - accuracy: 0.2132-----last Batch size: 6\n",
            "18/19 [===========================>..] - ETA: 41s - loss: 1.6160 - accuracy: 0.2153 -----Batch0: size: 8\n",
            "19/19 [==============================] - ETA: 0s - loss: 1.6161 - accuracy: 0.2133 -----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "\n",
            "Epoch 00007: saving model to model_init_2021-12-2723_21_03.800788\\model-00007-1.61608-0.21333-1.60981-0.20000.h5\n",
            "19/19 [==============================] - 825s 44s/step - loss: 1.6161 - accuracy: 0.2133 - val_loss: 1.6098 - val_accuracy: 0.2000 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "-----Batch1: size: 8\n",
            " 1/19 [>.............................] - ETA: 10:55 - loss: 1.5322 - accuracy: 0.7500-----Batch2: size: 8\n",
            " 2/19 [==>...........................] - ETA: 13:09 - loss: 1.5671 - accuracy: 0.5000-----Batch3: size: 8\n",
            " 3/19 [===>..........................] - ETA: 12:07 - loss: 1.5891 - accuracy: 0.3750-----Batch4: size: 8\n",
            " 4/19 [=====>........................] - ETA: 11:29 - loss: 1.6010 - accuracy: 0.3125-----Batch5: size: 8\n",
            " 5/19 [======>.......................] - ETA: 10:21 - loss: 1.6127 - accuracy: 0.2750-----Batch6: size: 8\n",
            " 6/19 [========>.....................] - ETA: 9:39 - loss: 1.6142 - accuracy: 0.2500 -----Batch7: size: 8\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 7/19 [==========>...................] - ETA: 8:42 - loss: 1.6181 - accuracy: 0.2321-----Batch8: size: 8\n",
            " 8/19 [===========>..................] - ETA: 7:48 - loss: 1.6182 - accuracy: 0.2344-----Batch9: size: 8\n",
            " 9/19 [=============>................] - ETA: 7:05 - loss: 1.6139 - accuracy: 0.2500-----Batch10: size: 8\n",
            "10/19 [==============>...............] - ETA: 6:25 - loss: 1.6101 - accuracy: 0.2625-----Batch11: size: 8\n",
            "11/19 [================>.............] - ETA: 5:37 - loss: 1.6057 - accuracy: 0.2727-----Batch12: size: 8\n",
            "12/19 [=================>............] - ETA: 4:51 - loss: 1.6017 - accuracy: 0.2812-----Batch13: size: 8\n",
            "13/19 [===================>..........] - ETA: 4:09 - loss: 1.6032 - accuracy: 0.2788-----Batch14: size: 8\n",
            "14/19 [=====================>........] - ETA: 3:27 - loss: 1.6032 - accuracy: 0.2768-----Batch15: size: 8\n",
            "15/19 [======================>.......] - ETA: 2:46 - loss: 1.6055 - accuracy: 0.2667-----Batch16: size: 8\n",
            "16/19 [========================>.....] - ETA: 2:03 - loss: 1.6076 - accuracy: 0.2578-----Batch17: size: 8\n",
            "17/19 [=========================>....] - ETA: 1:21 - loss: 1.6098 - accuracy: 0.2500-----last Batch size: 6\n",
            "18/19 [===========================>..] - ETA: 40s - loss: 1.6103 - accuracy: 0.2500 -----Batch0: size: 8\n",
            "19/19 [==============================] - ETA: 0s - loss: 1.6119 - accuracy: 0.2467 -----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "\n",
            "Epoch 00008: saving model to model_init_2021-12-2723_21_03.800788\\model-00008-1.61188-0.24667-1.60980-0.23000.h5\n",
            "19/19 [==============================] - 824s 44s/step - loss: 1.6119 - accuracy: 0.2467 - val_loss: 1.6098 - val_accuracy: 0.2300 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "-----Batch1: size: 8\n",
            " 1/19 [>.............................] - ETA: 10:55 - loss: 1.6378 - accuracy: 0.1250-----Batch2: size: 8\n",
            " 2/19 [==>...........................] - ETA: 10:53 - loss: 1.6416 - accuracy: 0.1250-----Batch3: size: 8\n",
            " 3/19 [===>..........................] - ETA: 10:34 - loss: 1.6465 - accuracy: 0.1250-----Batch4: size: 8\n",
            " 4/19 [=====>........................] - ETA: 9:34 - loss: 1.6356 - accuracy: 0.1562 -----Batch5: size: 8\n",
            " 5/19 [======>.......................] - ETA: 9:13 - loss: 1.6226 - accuracy: 0.2000-----Batch6: size: 8\n",
            " 6/19 [========>.....................] - ETA: 9:14 - loss: 1.6188 - accuracy: 0.2083-----Batch7: size: 8\n",
            " 7/19 [==========>...................] - ETA: 8:32 - loss: 1.6210 - accuracy: 0.1964-----Batch8: size: 8\n",
            " 8/19 [===========>..................] - ETA: 7:41 - loss: 1.6216 - accuracy: 0.1875-----Batch9: size: 8\n",
            " 9/19 [=============>................] - ETA: 7:05 - loss: 1.6138 - accuracy: 0.2222-----Batch10: size: 8\n",
            "10/19 [==============>...............] - ETA: 6:16 - loss: 1.6116 - accuracy: 0.2375-----Batch11: size: 8\n",
            "11/19 [================>.............] - ETA: 5:38 - loss: 1.6141 - accuracy: 0.2273-----Batch12: size: 8\n",
            "12/19 [=================>............] - ETA: 5:00 - loss: 1.6141 - accuracy: 0.2188-----Batch13: size: 8\n",
            "13/19 [===================>..........] - ETA: 4:17 - loss: 1.6128 - accuracy: 0.2212-----Batch14: size: 8\n",
            "14/19 [=====================>........] - ETA: 3:33 - loss: 1.6145 - accuracy: 0.2143-----Batch15: size: 8\n",
            "15/19 [======================>.......] - ETA: 2:51 - loss: 1.6135 - accuracy: 0.2250-----Batch16: size: 8\n",
            "16/19 [========================>.....] - ETA: 2:08 - loss: 1.6181 - accuracy: 0.2109-----Batch17: size: 8\n",
            "17/19 [=========================>....] - ETA: 1:25 - loss: 1.6165 - accuracy: 0.2206-----last Batch size: 6\n",
            "18/19 [===========================>..] - ETA: 42s - loss: 1.6126 - accuracy: 0.2431 -----Batch0: size: 8\n",
            "19/19 [==============================] - ETA: 0s - loss: 1.6117 - accuracy: 0.2467 -----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "\n",
            "Epoch 00009: saving model to model_init_2021-12-2723_21_03.800788\\model-00009-1.61167-0.24667-1.61104-0.20000.h5\n",
            "19/19 [==============================] - 854s 45s/step - loss: 1.6117 - accuracy: 0.2467 - val_loss: 1.6110 - val_accuracy: 0.2000 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "-----Batch1: size: 8\n",
            " 1/19 [>.............................] - ETA: 10:44 - loss: 1.5902 - accuracy: 0.2500-----Batch2: size: 8\n",
            " 2/19 [==>...........................] - ETA: 11:03 - loss: 1.5674 - accuracy: 0.3750-----Batch3: size: 8\n",
            " 3/19 [===>..........................] - ETA: 10:59 - loss: 1.5704 - accuracy: 0.3750-----Batch4: size: 8\n",
            " 4/19 [=====>........................] - ETA: 10:28 - loss: 1.5712 - accuracy: 0.3750-----Batch5: size: 8\n",
            " 5/19 [======>.......................] - ETA: 9:44 - loss: 1.5767 - accuracy: 0.3500 -----Batch6: size: 8\n",
            " 6/19 [========>.....................] - ETA: 9:08 - loss: 1.5854 - accuracy: 0.3125-----Batch7: size: 8\n",
            " 7/19 [==========>...................] - ETA: 8:25 - loss: 1.5906 - accuracy: 0.3036-----Batch8: size: 8\n",
            " 8/19 [===========>..................] - ETA: 7:41 - loss: 1.5931 - accuracy: 0.2969-----Batch9: size: 8\n",
            " 9/19 [=============>................] - ETA: 6:51 - loss: 1.5975 - accuracy: 0.2778-----Batch10: size: 8\n",
            "10/19 [==============>...............] - ETA: 6:22 - loss: 1.5985 - accuracy: 0.2750-----Batch11: size: 8\n",
            "11/19 [================>.............] - ETA: 5:40 - loss: 1.5976 - accuracy: 0.2727-----Batch12: size: 8\n",
            "12/19 [=================>............] - ETA: 4:53 - loss: 1.6074 - accuracy: 0.2500-----Batch13: size: 8\n",
            "13/19 [===================>..........] - ETA: 4:13 - loss: 1.6068 - accuracy: 0.2500-----Batch14: size: 8\n",
            "14/19 [=====================>........] - ETA: 3:30 - loss: 1.6118 - accuracy: 0.2321-----Batch15: size: 8\n",
            "15/19 [======================>.......] - ETA: 2:49 - loss: 1.6170 - accuracy: 0.2167-----Batch16: size: 8\n",
            "16/19 [========================>.....] - ETA: 2:06 - loss: 1.6159 - accuracy: 0.2188-----Batch17: size: 8\n",
            "17/19 [=========================>....] - ETA: 1:23 - loss: 1.6155 - accuracy: 0.2206-----last Batch size: 6\n",
            "18/19 [===========================>..] - ETA: 41s - loss: 1.6134 - accuracy: 0.2292 -----Batch0: size: 8\n",
            "19/19 [==============================] - ETA: 0s - loss: 1.6092 - accuracy: 0.2467 -----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "\n",
            "Epoch 00010: saving model to model_init_2021-12-2723_21_03.800788\\model-00010-1.60920-0.24667-1.61756-0.18000.h5\n",
            "19/19 [==============================] - 831s 44s/step - loss: 1.6092 - accuracy: 0.2467 - val_loss: 1.6176 - val_accuracy: 0.1800 - lr: 0.0100\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x2e8acdeecd0>"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "                    callbacks=callbacks_list, validation_data=val_generator, \n",
        "                    validation_steps=validation_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVQx16Z7rcyQ"
      },
      "source": [
        "Observations:\n",
        "- Model is unable to overfit on smaller dataset with all the layers of resnet being retrained. Also, the trainable parameters is very high. No need to further proceed with this model considering the increased complexity required and less complex models are able to achieve better results for this case study."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31A2tnehrcyR"
      },
      "source": [
        "#### Model#9: VGGNet + RNN: Use VGGNet instead of ResNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ABNnGeIrcyR"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33hF3txprcyR",
        "outputId": "4ecc6ded-8a26-454c-dc3a-272ca579965b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 5, 5, 512)         14714688  \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 4, 4, 64)          131136    \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 3, 3, 128)         32896     \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 2, 2, 128)         65664     \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,944,384\n",
            "Trainable params: 14,944,384\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "vgg = VGG16(include_top=False,weights='imagenet',input_shape=(180,180,3))\n",
        "cnn =Sequential([vgg])\n",
        "cnn.add(Conv2D(64,(2,2),strides=(1,1)))\n",
        "cnn.add(Conv2D(128,(2,2),strides=(1,1)))\n",
        "cnn.add(Conv2D(128,(2,2), strides= (1,1)))\n",
        "cnn.add(Flatten())\n",
        "cnn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pHnnVBvrcyR",
        "outputId": "80f5d0ff-4678-488b-e8da-6ff50ff42495"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " time_distributed_1 (TimeDis  (None, 15, 512)          14944384  \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " gru_3 (GRU)                 (None, 15, 128)           246528    \n",
            "                                                                 \n",
            " gru_4 (GRU)                 (None, 15, 128)           99072     \n",
            "                                                                 \n",
            " gru_5 (GRU)                 (None, 64)                37248     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,327,557\n",
            "Trainable params: 15,327,557\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(TimeDistributed(cnn,input_shape=(15,180,180,3)))\n",
        "model.add(GRU(128,input_shape=(None,15,512),return_sequences=True))\n",
        "model.add(GRU(128, return_sequences = True))\n",
        "model.add(GRU(64))\n",
        "model.add(Dense(5,activation='softmax'))\n",
        "model.summary()\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.01) \n",
        "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LY-uyv2mrcyR",
        "outputId": "b40e46c8-b31e-4cb6-a0c6-33a2805a5a08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_train_sequences:200, num_val_sequences:100, steps_per_epoch:25, validation_steps:13\n",
            "-----Batch0: size: 8\n",
            "Epoch 1/10\n",
            "-----Batch1: size: 8\n",
            " 1/25 [>.............................] - ETA: 30:25 - loss: 1.7042 - accuracy: 0.2500-----Batch2: size: 8\n",
            " 2/25 [=>............................] - ETA: 22:55 - loss: 1.6336 - accuracy: 0.1875-----Batch3: size: 8\n",
            " 3/25 [==>...........................] - ETA: 22:23 - loss: 1.6866 - accuracy: 0.2500-----Batch4: size: 8\n",
            " 4/25 [===>..........................] - ETA: 21:30 - loss: 2.7715 - accuracy: 0.2188-----Batch5: size: 8\n",
            " 5/25 [=====>........................] - ETA: 20:21 - loss: 2.7934 - accuracy: 0.2000-----Batch6: size: 8\n",
            " 6/25 [======>.......................] - ETA: 19:17 - loss: 2.6832 - accuracy: 0.2083-----Batch7: size: 8\n",
            " 7/25 [=======>......................] - ETA: 18:12 - loss: 2.7098 - accuracy: 0.2143-----Batch8: size: 8\n",
            " 8/25 [========>.....................] - ETA: 17:07 - loss: 2.5936 - accuracy: 0.2031-----Batch9: size: 8\n",
            " 9/25 [=========>....................] - ETA: 16:04 - loss: 2.5698 - accuracy: 0.2083-----Batch10: size: 8\n",
            "10/25 [===========>..................] - ETA: 15:04 - loss: 2.5339 - accuracy: 0.2000-----Batch11: size: 8\n",
            "11/25 [============>.................] - ETA: 14:01 - loss: 2.4678 - accuracy: 0.2159-----Batch12: size: 8\n",
            "12/25 [=============>................] - ETA: 13:01 - loss: 2.4074 - accuracy: 0.2083-----Batch13: size: 8\n",
            "13/25 [==============>...............] - ETA: 12:01 - loss: 2.3699 - accuracy: 0.2019-----Batch14: size: 8\n",
            "14/25 [===============>..............] - ETA: 11:01 - loss: 2.2982 - accuracy: 0.2143-----Batch15: size: 8\n",
            "15/25 [=================>............] - ETA: 10:00 - loss: 2.2936 - accuracy: 0.2083-----Batch16: size: 8\n",
            "16/25 [==================>...........] - ETA: 9:01 - loss: 2.2641 - accuracy: 0.2188 -----Batch17: size: 8\n",
            "17/25 [===================>..........] - ETA: 8:01 - loss: 2.2402 - accuracy: 0.2059-----Batch18: size: 8\n",
            "18/25 [====================>.........] - ETA: 7:00 - loss: 2.2280 - accuracy: 0.2014-----Batch19: size: 8\n",
            "19/25 [=====================>........] - ETA: 6:00 - loss: 2.2067 - accuracy: 0.1974-----Batch20: size: 8\n",
            "20/25 [=======================>......] - ETA: 5:00 - loss: 2.1953 - accuracy: 0.1875-----Batch21: size: 8\n",
            "21/25 [========================>.....] - ETA: 4:00 - loss: 2.1611 - accuracy: 0.2024-----Batch22: size: 8\n",
            "22/25 [=========================>....] - ETA: 3:00 - loss: 2.1366 - accuracy: 0.2045-----Batch23: size: 8\n",
            "23/25 [==========================>...] - ETA: 2:00 - loss: 2.1159 - accuracy: 0.2011-----Batch24: size: 8\n",
            "24/25 [===========================>..] - ETA: 1:00 - loss: 2.0963 - accuracy: 0.1979-----Batch0: size: 8\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.0859 - accuracy: 0.1950  -----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "\n",
            "Epoch 00001: saving model to model_init_2021-12-2809_10_08.963919\\model-00001-2.08586-0.19500-1.63052-0.22000.h5\n",
            "25/25 [==============================] - 1736s 69s/step - loss: 2.0859 - accuracy: 0.1950 - val_loss: 1.6305 - val_accuracy: 0.2200 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "-----Batch1: size: 8\n",
            " 1/25 [>.............................] - ETA: 22:43 - loss: 1.6688 - accuracy: 0.2500-----Batch2: size: 8\n",
            " 2/25 [=>............................] - ETA: 22:35 - loss: 1.6342 - accuracy: 0.3125-----Batch3: size: 8\n",
            " 3/25 [==>...........................] - ETA: 21:57 - loss: 1.6063 - accuracy: 0.3333-----Batch4: size: 8\n",
            " 4/25 [===>..........................] - ETA: 21:49 - loss: 1.6163 - accuracy: 0.2812-----Batch5: size: 8\n",
            " 5/25 [=====>........................] - ETA: 20:24 - loss: 1.6068 - accuracy: 0.2750-----Batch6: size: 8\n",
            " 6/25 [======>.......................] - ETA: 19:19 - loss: 1.6142 - accuracy: 0.3125-----Batch7: size: 8\n",
            " 7/25 [=======>......................] - ETA: 18:12 - loss: 1.6768 - accuracy: 0.2679-----Batch8: size: 8\n",
            " 8/25 [========>.....................] - ETA: 17:18 - loss: 1.6777 - accuracy: 0.2656-----Batch9: size: 8\n",
            " 9/25 [=========>....................] - ETA: 16:20 - loss: 1.6968 - accuracy: 0.2500-----Batch10: size: 8\n",
            "10/25 [===========>..................] - ETA: 15:21 - loss: 1.6968 - accuracy: 0.2250-----Batch11: size: 8\n",
            "11/25 [============>.................] - ETA: 14:17 - loss: 1.6976 - accuracy: 0.2045-----Batch12: size: 8\n",
            "12/25 [=============>................] - ETA: 13:13 - loss: 1.6974 - accuracy: 0.1979-----Batch13: size: 8\n",
            "13/25 [==============>...............] - ETA: 12:11 - loss: 1.6868 - accuracy: 0.2019-----Batch14: size: 8\n",
            "14/25 [===============>..............] - ETA: 11:12 - loss: 1.6916 - accuracy: 0.1964-----Batch15: size: 8\n",
            "15/25 [=================>............] - ETA: 10:10 - loss: 1.6845 - accuracy: 0.1917-----Batch16: size: 8\n",
            "16/25 [==================>...........] - ETA: 9:08 - loss: 1.6966 - accuracy: 0.1875 -----Batch17: size: 8\n",
            "17/25 [===================>..........] - ETA: 8:05 - loss: 1.7023 - accuracy: 0.1765-----Batch18: size: 8\n",
            "18/25 [====================>.........] - ETA: 7:02 - loss: 1.7190 - accuracy: 0.1806-----Batch19: size: 8\n",
            "19/25 [=====================>........] - ETA: 6:01 - loss: 1.7105 - accuracy: 0.1711-----Batch20: size: 8\n",
            "20/25 [=======================>......] - ETA: 5:00 - loss: 1.7262 - accuracy: 0.1750-----Batch21: size: 8\n",
            "21/25 [========================>.....] - ETA: 4:00 - loss: 1.7335 - accuracy: 0.1786-----Batch22: size: 8\n",
            "22/25 [=========================>....] - ETA: 2:59 - loss: 1.7322 - accuracy: 0.1818-----Batch23: size: 8\n",
            "23/25 [==========================>...] - ETA: 2:00 - loss: 1.7276 - accuracy: 0.1848-----Batch24: size: 8\n",
            "24/25 [===========================>..] - ETA: 1:00 - loss: 1.7274 - accuracy: 0.1771-----Batch0: size: 8\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.7230 - accuracy: 0.1750  -----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "\n",
            "Epoch 00002: saving model to model_init_2021-12-2809_10_08.963919\\model-00002-1.72299-0.17500-1.63241-0.17000.h5\n",
            "25/25 [==============================] - 1723s 69s/step - loss: 1.7230 - accuracy: 0.1750 - val_loss: 1.6324 - val_accuracy: 0.1700 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "-----Batch1: size: 8\n",
            " 1/25 [>.............................] - ETA: 22:42 - loss: 1.6351 - accuracy: 0.1250-----Batch2: size: 8\n",
            " 2/25 [=>............................] - ETA: 21:19 - loss: 1.6683 - accuracy: 0.1250-----Batch3: size: 8\n",
            " 3/25 [==>...........................] - ETA: 18:37 - loss: 1.6417 - accuracy: 0.1667-----Batch4: size: 8\n",
            " 4/25 [===>..........................] - ETA: 16:52 - loss: 1.6211 - accuracy: 0.2188-----Batch5: size: 8\n",
            " 5/25 [=====>........................] - ETA: 15:37 - loss: 1.6217 - accuracy: 0.2250-----Batch6: size: 8\n",
            " 6/25 [======>.......................] - ETA: 14:42 - loss: 1.6070 - accuracy: 0.2292-----Batch7: size: 8\n",
            " 7/25 [=======>......................] - ETA: 13:51 - loss: 1.5787 - accuracy: 0.2679-----Batch8: size: 8\n",
            " 8/25 [========>.....................] - ETA: 12:58 - loss: 1.6263 - accuracy: 0.2344-----Batch9: size: 8\n",
            " 9/25 [=========>....................] - ETA: 12:10 - loss: 1.6385 - accuracy: 0.2361-----Batch10: size: 8\n",
            "10/25 [===========>..................] - ETA: 11:25 - loss: 1.6444 - accuracy: 0.2250-----Batch11: size: 8\n",
            "11/25 [============>.................] - ETA: 10:46 - loss: 1.6538 - accuracy: 0.2045-----Batch12: size: 8\n",
            "12/25 [=============>................] - ETA: 10:03 - loss: 1.6563 - accuracy: 0.1979-----Batch13: size: 8\n",
            "13/25 [==============>...............] - ETA: 9:21 - loss: 1.6512 - accuracy: 0.1827 -----Batch14: size: 8\n",
            "14/25 [===============>..............] - ETA: 8:39 - loss: 1.6486 - accuracy: 0.2143-----Batch15: size: 8\n",
            "15/25 [=================>............] - ETA: 7:58 - loss: 1.6495 - accuracy: 0.2083-----Batch16: size: 8\n",
            "16/25 [==================>...........] - ETA: 7:13 - loss: 1.6483 - accuracy: 0.2109-----Batch17: size: 8\n",
            "17/25 [===================>..........] - ETA: 6:29 - loss: 1.6544 - accuracy: 0.1985-----Batch18: size: 8\n",
            "18/25 [====================>.........] - ETA: 5:42 - loss: 1.6512 - accuracy: 0.2014-----Batch19: size: 8\n",
            "19/25 [=====================>........] - ETA: 4:53 - loss: 1.6572 - accuracy: 0.1908-----Batch20: size: 8\n",
            "20/25 [=======================>......] - ETA: 4:06 - loss: 1.6679 - accuracy: 0.1875-----Batch21: size: 8\n",
            "21/25 [========================>.....] - ETA: 3:17 - loss: 1.6706 - accuracy: 0.1905-----Batch22: size: 8\n",
            "22/25 [=========================>....] - ETA: 2:29 - loss: 1.6729 - accuracy: 0.1875-----Batch23: size: 8\n",
            "23/25 [==========================>...] - ETA: 1:39 - loss: 1.6743 - accuracy: 0.1793-----Batch24: size: 8\n",
            "24/25 [===========================>..] - ETA: 49s - loss: 1.6758 - accuracy: 0.1771 -----Batch0: size: 8\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.6762 - accuracy: 0.1800 -----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "\n",
            "Epoch 00003: saving model to model_init_2021-12-2809_10_08.963919\\model-00003-1.67619-0.18000-1.63075-0.19000.h5\n",
            "25/25 [==============================] - 1435s 57s/step - loss: 1.6762 - accuracy: 0.1800 - val_loss: 1.6308 - val_accuracy: 0.1900 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "-----Batch1: size: 8\n",
            " 1/25 [>.............................] - ETA: 21:05 - loss: 1.6895 - accuracy: 0.1250-----Batch2: size: 8\n",
            " 2/25 [=>............................] - ETA: 19:31 - loss: 1.6289 - accuracy: 0.2500-----Batch3: size: 8\n",
            " 3/25 [==>...........................] - ETA: 19:09 - loss: 1.6285 - accuracy: 0.2500-----Batch4: size: 8\n",
            " 4/25 [===>..........................] - ETA: 18:52 - loss: 1.6393 - accuracy: 0.2188-----Batch5: size: 8\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-47-9fbb502e4db0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m180\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m180\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcallbacks_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n\u001b[0m\u001b[0;32m      5\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                     validation_steps=validation_steps)\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "## ABLATION\n",
        "num_epochs = 5\n",
        "train_generator,val_generator,steps_per_epoch,validation_steps = sample_set(8,200,(180,180))\n",
        "callbacks_list = save_model('accuracy')\n",
        "model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "                    callbacks=callbacks_list, validation_data=val_generator, \n",
        "                    validation_steps=validation_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_W_-IePrcyS"
      },
      "source": [
        "Model doesn't show proper progress in learning over the epochs for small dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dU4OpmS0rcyS"
      },
      "source": [
        "#### Customized CNN + GRU\n",
        "- Implement a model without using any pretrained network\n",
        "#### Model #10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uZL5GeJrcyS"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "def cnn_gru():\n",
        "    \n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(TimeDistributed(Conv2D(16, (2, 2) , padding='same', activation='relu'),input_shape=(15,180,180,3)))\n",
        "    model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "        \n",
        "    model.add(TimeDistributed(Conv2D(32, (2, 2) , padding='same', activation='relu')))\n",
        "    model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "        \n",
        "    model.add(TimeDistributed(Conv2D(64, (2, 2) , padding='same', activation='relu')))\n",
        "    model.add(TimeDistributed(BatchNormalization()))\n",
        "    model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "        \n",
        "    model.add(TimeDistributed(Conv2D(128, (3, 3) , padding='same', activation='relu')))\n",
        "    model.add(TimeDistributed(BatchNormalization()))\n",
        "    model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "\n",
        "    model.add(TimeDistributed(Conv2D(128, (3, 3) , padding='same', activation='relu')))\n",
        "    model.add(TimeDistributed(Dropout(0.3)))\n",
        "\n",
        "    model.add(TimeDistributed(Flatten()))\n",
        "\n",
        "\n",
        "    model.add(GRU(128))\n",
        "        \n",
        "    model.add(Dense(64,activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "        \n",
        "    model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=0.01) \n",
        "    model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['categorical_accuracy'])\n",
        "    print(model.summary())\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNfJfOmyrcyS",
        "outputId": "7035f78d-42ef-4009-9c3c-16ac4feaacc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_train_sequences:150, num_val_sequences:100, steps_per_epoch:19, validation_steps:13\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " time_distributed (TimeDistr  (None, 15, 180, 180, 16)  208      \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDis  (None, 15, 90, 90, 16)   0         \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_2 (TimeDis  (None, 15, 90, 90, 32)   2080      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_3 (TimeDis  (None, 15, 45, 45, 32)   0         \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_4 (TimeDis  (None, 15, 45, 45, 64)   8256      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_5 (TimeDis  (None, 15, 45, 45, 64)   256       \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_6 (TimeDis  (None, 15, 22, 22, 64)   0         \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_7 (TimeDis  (None, 15, 22, 22, 128)  73856     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_8 (TimeDis  (None, 15, 22, 22, 128)  512       \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_9 (TimeDis  (None, 15, 11, 11, 128)  0         \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_10 (TimeDi  (None, 15, 11, 11, 128)  147584    \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_11 (TimeDi  (None, 15, 11, 11, 128)  0         \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_12 (TimeDi  (None, 15, 15488)        0         \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 128)               5997312   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,238,645\n",
            "Trainable params: 6,238,261\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n",
            "None\n",
            "-----Batch0: size: 8\n",
            "Epoch 1/5\n",
            " 1/19 [>.............................] - ETA: 1:04 - loss: 2.1889 - categorical_accuracy: 0.2500-----Batch1: size: 8\n",
            " 2/19 [==>...........................] - ETA: 37s - loss: 2.1553 - categorical_accuracy: 0.1875 -----Batch2: size: 8\n",
            " 3/19 [===>..........................] - ETA: 35s - loss: 1.8390 - categorical_accuracy: 0.3333-----Batch3: size: 8\n",
            " 4/19 [=====>........................] - ETA: 35s - loss: 1.9529 - categorical_accuracy: 0.3125-----Batch4: size: 8\n",
            " 5/19 [======>.......................] - ETA: 34s - loss: 2.0340 - categorical_accuracy: 0.2750-----Batch5: size: 8\n",
            " 6/19 [========>.....................] - ETA: 31s - loss: 2.0072 - categorical_accuracy: 0.2708-----Batch6: size: 8\n",
            " 7/19 [==========>...................] - ETA: 29s - loss: 1.9673 - categorical_accuracy: 0.2500-----Batch7: size: 8\n",
            " 8/19 [===========>..................] - ETA: 26s - loss: 1.9462 - categorical_accuracy: 0.2812-----Batch8: size: 8\n",
            " 9/19 [=============>................] - ETA: 24s - loss: 1.9636 - categorical_accuracy: 0.2639-----Batch9: size: 8\n",
            "10/19 [==============>...............] - ETA: 22s - loss: 1.9856 - categorical_accuracy: 0.2750-----Batch10: size: 8\n",
            "11/19 [================>.............] - ETA: 19s - loss: 1.9871 - categorical_accuracy: 0.2727-----Batch11: size: 8\n",
            "12/19 [=================>............] - ETA: 17s - loss: 1.9537 - categorical_accuracy: 0.2708-----Batch12: size: 8\n",
            "13/19 [===================>..........] - ETA: 14s - loss: 1.9477 - categorical_accuracy: 0.2692-----Batch13: size: 8\n",
            "14/19 [=====================>........] - ETA: 12s - loss: 1.9335 - categorical_accuracy: 0.2679-----Batch14: size: 8\n",
            "15/19 [======================>.......] - ETA: 9s - loss: 1.9308 - categorical_accuracy: 0.2583 -----Batch15: size: 8\n",
            "16/19 [========================>.....] - ETA: 7s - loss: 1.9276 - categorical_accuracy: 0.2656-----Batch16: size: 8\n",
            "17/19 [=========================>....] - ETA: 4s - loss: 1.9329 - categorical_accuracy: 0.2500-----Batch17: size: 8\n",
            "18/19 [===========================>..] - ETA: 2s - loss: 1.9062 - categorical_accuracy: 0.2500-----last Batch size: 6\n",
            "19/19 [==============================] - ETA: 0s - loss: 1.9045 - categorical_accuracy: 0.2400-----Batch0: size: 8\n",
            "-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "\n",
            "Epoch 00001: saving model to model_init_2021-12-2815_09_55.701508\\model-00001-1.90447-0.24000-1.62086-0.21000.h5\n",
            "19/19 [==============================] - 66s 3s/step - loss: 1.9045 - categorical_accuracy: 0.2400 - val_loss: 1.6209 - val_categorical_accuracy: 0.2100 - lr: 0.0100\n",
            "Epoch 2/5\n",
            " 1/19 [>.............................] - ETA: 30s - loss: 1.5786 - categorical_accuracy: 0.3750-----Batch1: size: 8\n",
            " 2/19 [==>...........................] - ETA: 39s - loss: 1.6092 - categorical_accuracy: 0.3750-----Batch2: size: 8\n",
            " 3/19 [===>..........................] - ETA: 36s - loss: 1.6501 - categorical_accuracy: 0.2917-----Batch3: size: 8\n",
            " 4/19 [=====>........................] - ETA: 34s - loss: 1.6787 - categorical_accuracy: 0.2188-----Batch4: size: 8\n",
            " 5/19 [======>.......................] - ETA: 31s - loss: 1.6641 - categorical_accuracy: 0.2500-----Batch5: size: 8\n",
            " 6/19 [========>.....................] - ETA: 28s - loss: 1.6735 - categorical_accuracy: 0.2292-----Batch6: size: 8\n",
            " 7/19 [==========>...................] - ETA: 26s - loss: 1.6651 - categorical_accuracy: 0.2143-----Batch7: size: 8\n",
            " 8/19 [===========>..................] - ETA: 24s - loss: 1.6576 - categorical_accuracy: 0.2188-----Batch8: size: 8\n",
            " 9/19 [=============>................] - ETA: 22s - loss: 1.6476 - categorical_accuracy: 0.1944-----Batch9: size: 8\n",
            "10/19 [==============>...............] - ETA: 20s - loss: 1.6535 - categorical_accuracy: 0.2000-----Batch10: size: 8\n",
            "11/19 [================>.............] - ETA: 18s - loss: 1.6526 - categorical_accuracy: 0.2045-----Batch11: size: 8\n",
            "12/19 [=================>............] - ETA: 16s - loss: 1.6780 - categorical_accuracy: 0.1875-----Batch12: size: 8\n",
            "13/19 [===================>..........] - ETA: 13s - loss: 1.6681 - categorical_accuracy: 0.2019-----Batch13: size: 8\n",
            "14/19 [=====================>........] - ETA: 11s - loss: 1.6546 - categorical_accuracy: 0.2054-----Batch14: size: 8\n",
            "15/19 [======================>.......] - ETA: 9s - loss: 1.6497 - categorical_accuracy: 0.2000 -----Batch15: size: 8\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/19 [========================>.....] - ETA: 6s - loss: 1.6389 - categorical_accuracy: 0.2109-----Batch16: size: 8\n",
            "17/19 [=========================>....] - ETA: 4s - loss: 1.6359 - categorical_accuracy: 0.2059-----Batch17: size: 8\n",
            "18/19 [===========================>..] - ETA: 2s - loss: 1.6361 - categorical_accuracy: 0.2014-----last Batch size: 6\n",
            "19/19 [==============================] - ETA: 0s - loss: 1.6324 - categorical_accuracy: 0.1933-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "\n",
            "Epoch 00002: saving model to model_init_2021-12-2815_09_55.701508\\model-00002-1.63242-0.19333-1.63936-0.21000.h5\n",
            "19/19 [==============================] - 60s 3s/step - loss: 1.6324 - categorical_accuracy: 0.1933 - val_loss: 1.6394 - val_categorical_accuracy: 0.2100 - lr: 0.0100\n",
            "Epoch 3/5\n",
            " 1/19 [>.............................] - ETA: 28s - loss: 1.8023 - categorical_accuracy: 0.3750-----Batch1: size: 8\n",
            " 2/19 [==>...........................] - ETA: 41s - loss: 1.8469 - categorical_accuracy: 0.1875-----Batch2: size: 8\n",
            " 3/19 [===>..........................] - ETA: 38s - loss: 1.8221 - categorical_accuracy: 0.1667-----Batch3: size: 8\n",
            " 4/19 [=====>........................] - ETA: 34s - loss: 1.8176 - categorical_accuracy: 0.1250-----Batch4: size: 8\n",
            " 5/19 [======>.......................] - ETA: 32s - loss: 1.7643 - categorical_accuracy: 0.1750-----Batch5: size: 8\n",
            " 6/19 [========>.....................] - ETA: 30s - loss: 1.7661 - categorical_accuracy: 0.1458-----Batch6: size: 8\n",
            " 7/19 [==========>...................] - ETA: 28s - loss: 1.7477 - categorical_accuracy: 0.1786-----Batch7: size: 8\n",
            " 8/19 [===========>..................] - ETA: 25s - loss: 1.7293 - categorical_accuracy: 0.1875-----Batch8: size: 8\n",
            " 9/19 [=============>................] - ETA: 23s - loss: 1.7027 - categorical_accuracy: 0.2083-----Batch9: size: 8\n",
            "10/19 [==============>...............] - ETA: 21s - loss: 1.7106 - categorical_accuracy: 0.2000-----Batch10: size: 8\n",
            "11/19 [================>.............] - ETA: 18s - loss: 1.7064 - categorical_accuracy: 0.1932-----Batch11: size: 8\n",
            "12/19 [=================>............] - ETA: 16s - loss: 1.6904 - categorical_accuracy: 0.2083-----Batch12: size: 8\n",
            "13/19 [===================>..........] - ETA: 13s - loss: 1.6959 - categorical_accuracy: 0.1923-----Batch13: size: 8\n",
            "14/19 [=====================>........] - ETA: 11s - loss: 1.6919 - categorical_accuracy: 0.1964-----Batch14: size: 8\n",
            "15/19 [======================>.......] - ETA: 9s - loss: 1.6981 - categorical_accuracy: 0.1833 -----Batch15: size: 8\n",
            "16/19 [========================>.....] - ETA: 6s - loss: 1.6949 - categorical_accuracy: 0.1797-----Batch16: size: 8\n",
            "17/19 [=========================>....] - ETA: 4s - loss: 1.6940 - categorical_accuracy: 0.1691-----Batch17: size: 8\n",
            "18/19 [===========================>..] - ETA: 2s - loss: 1.6905 - categorical_accuracy: 0.1736-----last Batch size: 6\n",
            "19/19 [==============================] - ETA: 0s - loss: 1.6886 - categorical_accuracy: 0.1733-----Batch0: size: 8\n",
            "-----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "\n",
            "Epoch 00003: saving model to model_init_2021-12-2815_09_55.701508\\model-00003-1.68862-0.17333-1.61523-0.18000.h5\n",
            "19/19 [==============================] - 61s 3s/step - loss: 1.6886 - categorical_accuracy: 0.1733 - val_loss: 1.6152 - val_categorical_accuracy: 0.1800 - lr: 0.0100\n",
            "Epoch 4/5\n",
            " 1/19 [>.............................] - ETA: 31s - loss: 1.5633 - categorical_accuracy: 0.2500-----Batch1: size: 8\n",
            " 2/19 [==>...........................] - ETA: 47s - loss: 1.5551 - categorical_accuracy: 0.3125-----Batch2: size: 8\n",
            " 3/19 [===>..........................] - ETA: 40s - loss: 1.5865 - categorical_accuracy: 0.2500-----Batch3: size: 8\n",
            " 4/19 [=====>........................] - ETA: 36s - loss: 1.6014 - categorical_accuracy: 0.2188-----Batch4: size: 8\n",
            " 5/19 [======>.......................] - ETA: 33s - loss: 1.6003 - categorical_accuracy: 0.1750-----Batch5: size: 8\n",
            " 6/19 [========>.....................] - ETA: 31s - loss: 1.6023 - categorical_accuracy: 0.1667-----Batch6: size: 8\n",
            " 7/19 [==========>...................] - ETA: 28s - loss: 1.6054 - categorical_accuracy: 0.1607-----Batch7: size: 8\n",
            " 8/19 [===========>..................] - ETA: 26s - loss: 1.6037 - categorical_accuracy: 0.1719-----Batch8: size: 8\n",
            " 9/19 [=============>................] - ETA: 23s - loss: 1.6017 - categorical_accuracy: 0.1806-----Batch9: size: 8\n",
            "10/19 [==============>...............] - ETA: 21s - loss: 1.6085 - categorical_accuracy: 0.1625-----Batch10: size: 8\n",
            "11/19 [================>.............] - ETA: 19s - loss: 1.6072 - categorical_accuracy: 0.1705-----Batch11: size: 8\n",
            "12/19 [=================>............] - ETA: 16s - loss: 1.6060 - categorical_accuracy: 0.1875-----Batch12: size: 8\n",
            "13/19 [===================>..........] - ETA: 14s - loss: 1.6008 - categorical_accuracy: 0.1923-----Batch13: size: 8\n",
            "14/19 [=====================>........] - ETA: 12s - loss: 1.6046 - categorical_accuracy: 0.1786-----Batch14: size: 8\n",
            "15/19 [======================>.......] - ETA: 9s - loss: 1.6070 - categorical_accuracy: 0.1750 -----Batch15: size: 8\n",
            "16/19 [========================>.....] - ETA: 7s - loss: 1.6088 - categorical_accuracy: 0.1719-----Batch16: size: 8\n",
            "17/19 [=========================>....] - ETA: 4s - loss: 1.6105 - categorical_accuracy: 0.1691-----Batch17: size: 8\n",
            "18/19 [===========================>..] - ETA: 2s - loss: 1.6122 - categorical_accuracy: 0.1667-----last Batch size: 6\n",
            "19/19 [==============================] - ETA: 0s - loss: 1.6112 - categorical_accuracy: 0.1667-----Batch0: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-14-6edc0a59ec61>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcallbacks_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'categorical_accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcnn_gru\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n\u001b[0m\u001b[0;32m      7\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                     validation_steps=validation_steps)\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1250\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1251\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[1;32m-> 1252\u001b[1;33m           val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m   1253\u001b[0m               \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1254\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1535\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1536\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1537\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1538\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1539\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    947\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 949\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    950\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#Ablation\n",
        "num_epochs = 5 \n",
        "train_generator,val_generator,steps_per_epoch,validation_steps = sample_set(8,150,(180,180))\n",
        "callbacks_list = save_model('categorical_accuracy')\n",
        "model = cnn_gru()\n",
        "model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "                    callbacks=callbacks_list, validation_data=val_generator, \n",
        "                    validation_steps=validation_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTxIMhBPrcyS"
      },
      "source": [
        "model is not able to overfit on sample data. so let's try to tweak model layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wrq_z0e9rcyS"
      },
      "source": [
        "#### Model#11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GD7aSwNLrcyT",
        "outputId": "680c01d1-a470-4528-91de-edaaff484a38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " time_distributed_36 (TimeDi  (None, 15, 180, 180, 16)  208      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_37 (TimeDi  (None, 15, 180, 180, 32)  2080     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_38 (TimeDi  (None, 15, 90, 90, 32)   0         \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_39 (TimeDi  (None, 15, 90, 90, 64)   8256      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_40 (TimeDi  (None, 15, 45, 45, 64)   0         \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_41 (TimeDi  (None, 15, 45, 45, 128)  32896     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_42 (TimeDi  (None, 15, 22, 22, 128)  0         \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_43 (TimeDi  (None, 15, 22, 22, 128)  65664     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_44 (TimeDi  (None, 15, 11, 11, 128)  0         \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_45 (TimeDi  (None, 15, 11, 11, 128)  147584    \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_46 (TimeDi  (None, 15, 11, 11, 128)  0         \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_47 (TimeDi  (None, 15, 15488)        0         \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " gru_3 (GRU)                 (None, 64)                2986368   \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,247,541\n",
            "Trainable params: 3,247,541\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def model_cnn_rnn_2():\n",
        "    \n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(TimeDistributed(Conv2D(16, (2, 2) , padding='same', activation='relu'),input_shape=(15,180,180,3)))      \n",
        "    model.add(TimeDistributed(Conv2D(32, (2, 2) , padding='same', activation='relu')))\n",
        "    model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "        \n",
        "    model.add(TimeDistributed(Conv2D(64, (2, 2) , padding='same', activation='relu')))\n",
        "    model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "        \n",
        "    model.add(TimeDistributed(Conv2D(128, (2, 2) , padding='same', activation='relu')))\n",
        "    model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "\n",
        "    model.add(TimeDistributed(Conv2D(128, (2, 2) , padding='same', activation='relu')))\n",
        "    model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "\n",
        "    model.add(TimeDistributed(Conv2D(128, (3, 3) , padding='same', activation='relu')))\n",
        "    model.add(TimeDistributed(Dropout(0.3)))\n",
        "\n",
        "    model.add(TimeDistributed(Flatten()))\n",
        "\n",
        "\n",
        "    model.add(GRU(64))\n",
        "        \n",
        "    model.add(Dense(64,activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "        \n",
        "    model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=0.0001) \n",
        "    model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['categorical_accuracy'])\n",
        "    model.summary()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dTIhAbjrcyT",
        "outputId": "0fb4c1ca-a816-4bbd-9a3e-0924323cf00b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_train_sequences:150, num_val_sequences:100, steps_per_epoch:19, validation_steps:13\n",
            "-----Batch0: size: 8\n",
            "Epoch 1/10\n",
            "-----Batch1: size: 8\n",
            " 1/19 [>.............................] - ETA: 1:42 - loss: 1.6009 - categorical_accuracy: 0.3750-----Batch2: size: 8\n",
            " 2/19 [==>...........................] - ETA: 1:05 - loss: 1.5920 - categorical_accuracy: 0.3125-----Batch3: size: 8\n",
            " 3/19 [===>..........................] - ETA: 1:01 - loss: 1.6229 - categorical_accuracy: 0.2500-----Batch4: size: 8\n",
            " 4/19 [=====>........................] - ETA: 57s - loss: 1.6333 - categorical_accuracy: 0.2188 -----Batch5: size: 8\n",
            " 5/19 [======>.......................] - ETA: 54s - loss: 1.6362 - categorical_accuracy: 0.1750-----Batch6: size: 8\n",
            " 7/19 [==========>...................] - ETA: 46s - loss: 1.6187 - categorical_accuracy: 0.1786-----Batch7: size: 8\n",
            " 8/19 [===========>..................] - ETA: 44s - loss: 1.6106 - categorical_accuracy: 0.2031-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "10/19 [==============>...............] - ETA: 37s - loss: 1.5972 - categorical_accuracy: 0.2125-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "11/19 [================>.............] - ETA: 32s - loss: 1.5958 - categorical_accuracy: 0.2273-----Batch12: size: 8\n",
            "12/19 [=================>............] - ETA: 28s - loss: 1.6050 - categorical_accuracy: 0.2188-----Batch13: size: 8\n",
            "14/19 [=====================>........] - ETA: 20s - loss: 1.6237 - categorical_accuracy: 0.2054-----Batch14: size: 8\n",
            "-----Batch15: size: 8\n",
            "15/19 [======================>.......] - ETA: 16s - loss: 1.6300 - categorical_accuracy: 0.2000-----Batch16: size: 8\n",
            "16/19 [========================>.....] - ETA: 12s - loss: 1.6289 - categorical_accuracy: 0.2109-----Batch17: size: 8\n",
            "17/19 [=========================>....] - ETA: 8s - loss: 1.6308 - categorical_accuracy: 0.2059 -----last Batch size: 6\n",
            "19/19 [==============================] - ETA: 0s - loss: 1.6230 - categorical_accuracy: 0.2333-----Batch0: size: 8\n",
            "-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "\n",
            "Epoch 00001: saving model to model_init_2021-12-2811_08_06.866220\\model-00001-1.62299-0.23333-1.62207-0.21000.h5\n",
            "19/19 [==============================] - 99s 5s/step - loss: 1.6230 - categorical_accuracy: 0.2333 - val_loss: 1.6221 - val_categorical_accuracy: 0.2100 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            " 1/19 [>.............................] - ETA: 1:06 - loss: 1.6521 - categorical_accuracy: 0.0000e+00-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            " 2/19 [==>...........................] - ETA: 1:06 - loss: 1.6292 - categorical_accuracy: 0.1875    -----Batch3: size: 8\n",
            " 3/19 [===>..........................] - ETA: 1:02 - loss: 1.6297 - categorical_accuracy: 0.2500-----Batch4: size: 8\n",
            " 5/19 [======>.......................] - ETA: 53s - loss: 1.6155 - categorical_accuracy: 0.2250-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            " 6/19 [========>.....................] - ETA: 49s - loss: 1.6053 - categorical_accuracy: 0.2500-----Batch7: size: 8\n",
            " 7/19 [==========>...................] - ETA: 45s - loss: 1.6112 - categorical_accuracy: 0.2321-----Batch8: size: 8\n",
            " 8/19 [===========>..................] - ETA: 41s - loss: 1.6074 - categorical_accuracy: 0.2344-----Batch9: size: 8\n",
            " 9/19 [=============>................] - ETA: 37s - loss: 1.5993 - categorical_accuracy: 0.2500-----Batch10: size: 8\n",
            "10/19 [==============>...............] - ETA: 33s - loss: 1.5949 - categorical_accuracy: 0.2500-----Batch11: size: 8\n",
            "11/19 [================>.............] - ETA: 29s - loss: 1.5914 - categorical_accuracy: 0.2727-----Batch12: size: 8\n",
            "12/19 [=================>............] - ETA: 26s - loss: 1.5980 - categorical_accuracy: 0.2604-----Batch13: size: 8\n",
            "13/19 [===================>..........] - ETA: 22s - loss: 1.6004 - categorical_accuracy: 0.2404-----Batch14: size: 8\n",
            "14/19 [=====================>........] - ETA: 18s - loss: 1.6016 - categorical_accuracy: 0.2321-----Batch15: size: 8\n",
            "15/19 [======================>.......] - ETA: 14s - loss: 1.6025 - categorical_accuracy: 0.2250-----Batch16: size: 8\n",
            "16/19 [========================>.....] - ETA: 11s - loss: 1.5976 - categorical_accuracy: 0.2422-----Batch17: size: 8\n",
            "17/19 [=========================>....] - ETA: 7s - loss: 1.5978 - categorical_accuracy: 0.2426 -----last Batch size: 6\n",
            "19/19 [==============================] - ETA: 0s - loss: 1.5988 - categorical_accuracy: 0.2600-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "\n",
            "Epoch 00002: saving model to model_init_2021-12-2811_08_06.866220\\model-00002-1.59877-0.26000-1.61138-0.24000.h5\n",
            "19/19 [==============================] - 92s 5s/step - loss: 1.5988 - categorical_accuracy: 0.2600 - val_loss: 1.6114 - val_categorical_accuracy: 0.2400 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            " 1/19 [>.............................] - ETA: 1:06 - loss: 1.5684 - categorical_accuracy: 0.2500-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            " 2/19 [==>...........................] - ETA: 1:05 - loss: 1.5818 - categorical_accuracy: 0.2500-----Batch3: size: 8\n",
            " 4/19 [=====>........................] - ETA: 56s - loss: 1.5684 - categorical_accuracy: 0.3438 -----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            " 6/19 [========>.....................] - ETA: 48s - loss: 1.5767 - categorical_accuracy: 0.3333-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            " 7/19 [==========>...................] - ETA: 45s - loss: 1.5711 - categorical_accuracy: 0.3393-----Batch8: size: 8\n",
            " 8/19 [===========>..................] - ETA: 41s - loss: 1.5817 - categorical_accuracy: 0.3281-----Batch9: size: 8\n",
            " 9/19 [=============>................] - ETA: 37s - loss: 1.5696 - categorical_accuracy: 0.3333-----Batch10: size: 8\n",
            "10/19 [==============>...............] - ETA: 33s - loss: 1.5760 - categorical_accuracy: 0.3375-----Batch11: size: 8\n",
            "11/19 [================>.............] - ETA: 29s - loss: 1.5824 - categorical_accuracy: 0.3182-----Batch12: size: 8\n",
            "12/19 [=================>............] - ETA: 26s - loss: 1.5870 - categorical_accuracy: 0.3229-----Batch13: size: 8\n",
            "13/19 [===================>..........] - ETA: 22s - loss: 1.5784 - categorical_accuracy: 0.3269-----Batch14: size: 8\n",
            "14/19 [=====================>........] - ETA: 18s - loss: 1.5759 - categorical_accuracy: 0.3125-----Batch15: size: 8\n",
            "16/19 [========================>.....] - ETA: 11s - loss: 1.5790 - categorical_accuracy: 0.3047-----Batch16: size: 8\n",
            "-----Batch17: size: 8\n",
            "17/19 [=========================>....] - ETA: 7s - loss: 1.5903 - categorical_accuracy: 0.2941 -----last Batch size: 6\n",
            "19/19 [==============================] - ETA: 0s - loss: 1.5855 - categorical_accuracy: 0.2933-----Batch0: size: 8\n",
            "-----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "\n",
            "Epoch 00003: saving model to model_init_2021-12-2811_08_06.866220\\model-00003-1.58550-0.29333-1.62540-0.20000.h5\n",
            "19/19 [==============================] - 92s 5s/step - loss: 1.5855 - categorical_accuracy: 0.2933 - val_loss: 1.6254 - val_categorical_accuracy: 0.2000 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "-----Batch1: size: 8\n",
            " 1/19 [>.............................] - ETA: 1:05 - loss: 1.6640 - categorical_accuracy: 0.1250-----Batch2: size: 8\n",
            " 3/19 [===>..........................] - ETA: 58s - loss: 1.6270 - categorical_accuracy: 0.2500 -----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            " 5/19 [======>.......................] - ETA: 51s - loss: 1.5989 - categorical_accuracy: 0.3000-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            " 6/19 [========>.....................] - ETA: 48s - loss: 1.5901 - categorical_accuracy: 0.3125-----Batch7: size: 8\n",
            " 7/19 [==========>...................] - ETA: 45s - loss: 1.5883 - categorical_accuracy: 0.3036-----Batch8: size: 8\n",
            " 8/19 [===========>..................] - ETA: 41s - loss: 1.5874 - categorical_accuracy: 0.2969-----Batch9: size: 8\n",
            " 9/19 [=============>................] - ETA: 37s - loss: 1.5801 - categorical_accuracy: 0.3056-----Batch10: size: 8\n",
            "10/19 [==============>...............] - ETA: 33s - loss: 1.5731 - categorical_accuracy: 0.3000-----Batch11: size: 8\n",
            "11/19 [================>.............] - ETA: 30s - loss: 1.5807 - categorical_accuracy: 0.2841-----Batch12: size: 8\n",
            "12/19 [=================>............] - ETA: 26s - loss: 1.5886 - categorical_accuracy: 0.2604-----Batch13: size: 8\n",
            "13/19 [===================>..........] - ETA: 22s - loss: 1.5974 - categorical_accuracy: 0.2500-----Batch14: size: 8\n",
            "14/19 [=====================>........] - ETA: 18s - loss: 1.5992 - categorical_accuracy: 0.2500-----Batch15: size: 8\n",
            "15/19 [======================>.......] - ETA: 15s - loss: 1.5997 - categorical_accuracy: 0.2500-----Batch16: size: 8\n",
            "16/19 [========================>.....] - ETA: 11s - loss: 1.5946 - categorical_accuracy: 0.2656-----Batch17: size: 8\n",
            "17/19 [=========================>....] - ETA: 7s - loss: 1.5918 - categorical_accuracy: 0.2721 -----last Batch size: 6\n",
            "19/19 [==============================] - ETA: 0s - loss: 1.5938 - categorical_accuracy: 0.2667-----Batch0: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "\n",
            "Epoch 00004: saving model to model_init_2021-12-2811_08_06.866220\\model-00004-1.59376-0.26667-1.59288-0.23000.h5\n",
            "19/19 [==============================] - 93s 5s/step - loss: 1.5938 - categorical_accuracy: 0.2667 - val_loss: 1.5929 - val_categorical_accuracy: 0.2300 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "-----Batch1: size: 8\n",
            " 1/19 [>.............................] - ETA: 1:06 - loss: 1.6333 - categorical_accuracy: 0.0000e+00-----Batch2: size: 8\n",
            " 2/19 [==>...........................] - ETA: 1:02 - loss: 1.6069 - categorical_accuracy: 0.1250    -----Batch3: size: 8\n",
            " 3/19 [===>..........................] - ETA: 59s - loss: 1.5796 - categorical_accuracy: 0.2500 -----Batch4: size: 8\n",
            " 4/19 [=====>........................] - ETA: 54s - loss: 1.6059 - categorical_accuracy: 0.2188-----Batch5: size: 8\n",
            " 5/19 [======>.......................] - ETA: 51s - loss: 1.6052 - categorical_accuracy: 0.2000-----Batch6: size: 8\n",
            " 6/19 [========>.....................] - ETA: 48s - loss: 1.5990 - categorical_accuracy: 0.2500-----Batch7: size: 8\n",
            " 7/19 [==========>...................] - ETA: 44s - loss: 1.5752 - categorical_accuracy: 0.3393-----Batch8: size: 8\n",
            " 9/19 [=============>................] - ETA: 36s - loss: 1.5621 - categorical_accuracy: 0.3889-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "10/19 [==============>...............] - ETA: 32s - loss: 1.5625 - categorical_accuracy: 0.3750-----Batch11: size: 8\n",
            "11/19 [================>.............] - ETA: 29s - loss: 1.5680 - categorical_accuracy: 0.3409-----Batch12: size: 8\n",
            "12/19 [=================>............] - ETA: 25s - loss: 1.5680 - categorical_accuracy: 0.3333-----Batch13: size: 8\n",
            "13/19 [===================>..........] - ETA: 21s - loss: 1.5660 - categorical_accuracy: 0.3365-----Batch14: size: 8\n",
            "14/19 [=====================>........] - ETA: 18s - loss: 1.5599 - categorical_accuracy: 0.3482-----Batch15: size: 8\n",
            "15/19 [======================>.......] - ETA: 14s - loss: 1.5607 - categorical_accuracy: 0.3417-----Batch16: size: 8\n",
            "17/19 [=========================>....] - ETA: 7s - loss: 1.5594 - categorical_accuracy: 0.3529 -----Batch17: size: 8\n",
            "-----last Batch size: 6\n",
            "19/19 [==============================] - ETA: 0s - loss: 1.5610 - categorical_accuracy: 0.3400-----Batch0: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "\n",
            "Epoch 00005: saving model to model_init_2021-12-2811_08_06.866220\\model-00005-1.56099-0.34000-1.59743-0.20000.h5\n",
            "19/19 [==============================] - 89s 5s/step - loss: 1.5610 - categorical_accuracy: 0.3400 - val_loss: 1.5974 - val_categorical_accuracy: 0.2000 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "-----Batch1: size: 8\n",
            " 1/19 [>.............................] - ETA: 1:00 - loss: 1.5907 - categorical_accuracy: 0.1250-----Batch2: size: 8\n",
            " 2/19 [==>...........................] - ETA: 59s - loss: 1.5913 - categorical_accuracy: 0.1875 -----Batch3: size: 8\n",
            " 3/19 [===>..........................] - ETA: 55s - loss: 1.5734 - categorical_accuracy: 0.2083-----Batch4: size: 8\n",
            " 4/19 [=====>........................] - ETA: 51s - loss: 1.5427 - categorical_accuracy: 0.2500-----Batch5: size: 8\n",
            " 5/19 [======>.......................] - ETA: 48s - loss: 1.5322 - categorical_accuracy: 0.2500-----Batch6: size: 8\n",
            " 6/19 [========>.....................] - ETA: 44s - loss: 1.5339 - categorical_accuracy: 0.2500-----Batch7: size: 8\n",
            " 7/19 [==========>...................] - ETA: 41s - loss: 1.5225 - categorical_accuracy: 0.2857-----Batch8: size: 8\n",
            " 8/19 [===========>..................] - ETA: 37s - loss: 1.4891 - categorical_accuracy: 0.3438-----Batch9: size: 8\n",
            " 9/19 [=============>................] - ETA: 34s - loss: 1.4880 - categorical_accuracy: 0.3750-----Batch10: size: 8\n",
            "10/19 [==============>...............] - ETA: 31s - loss: 1.4871 - categorical_accuracy: 0.3750-----Batch11: size: 8\n",
            "11/19 [================>.............] - ETA: 27s - loss: 1.4944 - categorical_accuracy: 0.3523-----Batch12: size: 8\n",
            "13/19 [===================>..........] - ETA: 21s - loss: 1.4795 - categorical_accuracy: 0.3558-----Batch13: size: 8\n",
            "-----Batch14: size: 8\n",
            "14/19 [=====================>........] - ETA: 17s - loss: 1.4774 - categorical_accuracy: 0.3482-----Batch15: size: 8\n",
            "15/19 [======================>.......] - ETA: 14s - loss: 1.4951 - categorical_accuracy: 0.3250-----Batch16: size: 8\n",
            "16/19 [========================>.....] - ETA: 10s - loss: 1.4962 - categorical_accuracy: 0.3203-----Batch17: size: 8\n",
            "17/19 [=========================>....] - ETA: 7s - loss: 1.5106 - categorical_accuracy: 0.3015 -----last Batch size: 6\n",
            "18/19 [===========================>..] - ETA: 3s - loss: 1.5064 - categorical_accuracy: 0.2986-----Batch0: size: 8\n",
            "19/19 [==============================] - ETA: 0s - loss: 1.5093 - categorical_accuracy: 0.2933-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "\n",
            "Epoch 00006: saving model to model_init_2021-12-2811_08_06.866220\\model-00006-1.50927-0.29333-1.52054-0.27000.h5\n",
            "19/19 [==============================] - 87s 5s/step - loss: 1.5093 - categorical_accuracy: 0.2933 - val_loss: 1.5205 - val_categorical_accuracy: 0.2700 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "-----Batch1: size: 8\n",
            " 1/19 [>.............................] - ETA: 1:03 - loss: 1.3545 - categorical_accuracy: 0.3750-----Batch2: size: 8\n",
            " 2/19 [==>...........................] - ETA: 58s - loss: 1.4488 - categorical_accuracy: 0.4375 -----Batch3: size: 8\n",
            " 3/19 [===>..........................] - ETA: 55s - loss: 1.4940 - categorical_accuracy: 0.3750-----Batch4: size: 8\n",
            " 4/19 [=====>........................] - ETA: 51s - loss: 1.5110 - categorical_accuracy: 0.4062-----Batch5: size: 8\n",
            " 6/19 [========>.....................] - ETA: 45s - loss: 1.5031 - categorical_accuracy: 0.3750-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            " 7/19 [==========>...................] - ETA: 42s - loss: 1.4875 - categorical_accuracy: 0.3750-----Batch8: size: 8\n",
            " 8/19 [===========>..................] - ETA: 38s - loss: 1.4773 - categorical_accuracy: 0.3906-----Batch9: size: 8\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 9/19 [=============>................] - ETA: 35s - loss: 1.4717 - categorical_accuracy: 0.4028-----Batch10: size: 8\n",
            "10/19 [==============>...............] - ETA: 31s - loss: 1.4734 - categorical_accuracy: 0.4125-----Batch11: size: 8\n",
            "11/19 [================>.............] - ETA: 27s - loss: 1.4663 - categorical_accuracy: 0.4318-----Batch12: size: 8\n",
            "12/19 [=================>............] - ETA: 24s - loss: 1.4546 - categorical_accuracy: 0.4479-----Batch13: size: 8\n",
            "14/19 [=====================>........] - ETA: 17s - loss: 1.4763 - categorical_accuracy: 0.4196-----Batch14: size: 8\n",
            "-----Batch15: size: 8\n",
            "15/19 [======================>.......] - ETA: 14s - loss: 1.4768 - categorical_accuracy: 0.4083-----Batch16: size: 8\n",
            "16/19 [========================>.....] - ETA: 10s - loss: 1.4885 - categorical_accuracy: 0.3906-----Batch17: size: 8\n",
            "17/19 [=========================>....] - ETA: 7s - loss: 1.4815 - categorical_accuracy: 0.3897 -----last Batch size: 6\n",
            "19/19 [==============================] - ETA: 0s - loss: 1.4672 - categorical_accuracy: 0.4067-----Batch0: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "\n",
            "Epoch 00007: saving model to model_init_2021-12-2811_08_06.866220\\model-00007-1.46723-0.40667-1.55872-0.34000.h5\n",
            "19/19 [==============================] - 88s 5s/step - loss: 1.4672 - categorical_accuracy: 0.4067 - val_loss: 1.5587 - val_categorical_accuracy: 0.3400 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "-----Batch1: size: 8\n",
            " 1/19 [>.............................] - ETA: 1:02 - loss: 1.5122 - categorical_accuracy: 0.2500-----Batch2: size: 8\n",
            " 2/19 [==>...........................] - ETA: 59s - loss: 1.2496 - categorical_accuracy: 0.5625 -----Batch3: size: 8\n",
            " 3/19 [===>..........................] - ETA: 55s - loss: 1.2818 - categorical_accuracy: 0.5417-----Batch4: size: 8\n",
            " 4/19 [=====>........................] - ETA: 52s - loss: 1.3368 - categorical_accuracy: 0.5000-----Batch5: size: 8\n",
            " 5/19 [======>.......................] - ETA: 48s - loss: 1.4644 - categorical_accuracy: 0.4250-----Batch6: size: 8\n",
            " 6/19 [========>.....................] - ETA: 45s - loss: 1.4319 - categorical_accuracy: 0.4167-----Batch7: size: 8\n",
            " 8/19 [===========>..................] - ETA: 38s - loss: 1.4439 - categorical_accuracy: 0.4062-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            " 9/19 [=============>................] - ETA: 34s - loss: 1.4459 - categorical_accuracy: 0.4028-----Batch10: size: 8\n",
            "10/19 [==============>...............] - ETA: 31s - loss: 1.4387 - categorical_accuracy: 0.4125-----Batch11: size: 8\n",
            "11/19 [================>.............] - ETA: 27s - loss: 1.4376 - categorical_accuracy: 0.4091-----Batch12: size: 8\n",
            "12/19 [=================>............] - ETA: 24s - loss: 1.4454 - categorical_accuracy: 0.4062-----Batch13: size: 8\n",
            "13/19 [===================>..........] - ETA: 20s - loss: 1.4373 - categorical_accuracy: 0.4135-----Batch14: size: 8\n",
            "14/19 [=====================>........] - ETA: 17s - loss: 1.4588 - categorical_accuracy: 0.3929-----Batch15: size: 8\n",
            "15/19 [======================>.......] - ETA: 13s - loss: 1.4597 - categorical_accuracy: 0.4000-----Batch16: size: 8\n",
            "16/19 [========================>.....] - ETA: 10s - loss: 1.4377 - categorical_accuracy: 0.4297-----Batch17: size: 8\n",
            "17/19 [=========================>....] - ETA: 6s - loss: 1.4426 - categorical_accuracy: 0.4191 -----last Batch size: 6\n",
            "19/19 [==============================] - ETA: 0s - loss: 1.4322 - categorical_accuracy: 0.4267-----Batch0: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "\n",
            "Epoch 00008: saving model to model_init_2021-12-2811_08_06.866220\\model-00008-1.43221-0.42667-1.51385-0.33000.h5\n",
            "19/19 [==============================] - 85s 5s/step - loss: 1.4322 - categorical_accuracy: 0.4267 - val_loss: 1.5138 - val_categorical_accuracy: 0.3300 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "-----Batch1: size: 8\n",
            " 1/19 [>.............................] - ETA: 1:02 - loss: 1.2599 - categorical_accuracy: 0.7500-----Batch2: size: 8\n",
            " 2/19 [==>...........................] - ETA: 59s - loss: 1.2306 - categorical_accuracy: 0.6875 -----Batch3: size: 8\n",
            " 3/19 [===>..........................] - ETA: 58s - loss: 1.2471 - categorical_accuracy: 0.6667-----Batch4: size: 8\n",
            " 4/19 [=====>........................] - ETA: 54s - loss: 1.3127 - categorical_accuracy: 0.5625-----Batch5: size: 8\n",
            " 5/19 [======>.......................] - ETA: 50s - loss: 1.3098 - categorical_accuracy: 0.5250-----Batch6: size: 8\n",
            " 6/19 [========>.....................] - ETA: 46s - loss: 1.3299 - categorical_accuracy: 0.5000-----Batch7: size: 8\n",
            " 7/19 [==========>...................] - ETA: 42s - loss: 1.3448 - categorical_accuracy: 0.4643-----Batch8: size: 8\n",
            " 8/19 [===========>..................] - ETA: 39s - loss: 1.3502 - categorical_accuracy: 0.4688-----Batch9: size: 8\n",
            " 9/19 [=============>................] - ETA: 35s - loss: 1.3266 - categorical_accuracy: 0.5000-----Batch10: size: 8\n",
            "10/19 [==============>...............] - ETA: 31s - loss: 1.3206 - categorical_accuracy: 0.4875-----Batch11: size: 8\n",
            "11/19 [================>.............] - ETA: 28s - loss: 1.2904 - categorical_accuracy: 0.5114-----Batch12: size: 8\n",
            "12/19 [=================>............] - ETA: 24s - loss: 1.2676 - categorical_accuracy: 0.5312-----Batch13: size: 8\n",
            "13/19 [===================>..........] - ETA: 21s - loss: 1.2581 - categorical_accuracy: 0.5481-----Batch14: size: 8\n",
            "14/19 [=====================>........] - ETA: 17s - loss: 1.2512 - categorical_accuracy: 0.5536-----Batch15: size: 8\n",
            "15/19 [======================>.......] - ETA: 14s - loss: 1.2209 - categorical_accuracy: 0.5750-----Batch16: size: 8\n",
            "16/19 [========================>.....] - ETA: 10s - loss: 1.2538 - categorical_accuracy: 0.5469-----Batch17: size: 8\n",
            "17/19 [=========================>....] - ETA: 7s - loss: 1.2634 - categorical_accuracy: 0.5368 -----last Batch size: 6\n",
            "19/19 [==============================] - ETA: 0s - loss: 1.2602 - categorical_accuracy: 0.5333-----Batch0: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "\n",
            "Epoch 00009: saving model to model_init_2021-12-2811_08_06.866220\\model-00009-1.26024-0.53333-1.33321-0.54000.h5\n",
            "19/19 [==============================] - 88s 5s/step - loss: 1.2602 - categorical_accuracy: 0.5333 - val_loss: 1.3332 - val_categorical_accuracy: 0.5400 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "-----Batch1: size: 8\n",
            " 1/19 [>.............................] - ETA: 1:01 - loss: 0.7884 - categorical_accuracy: 0.8750-----Batch2: size: 8\n",
            " 2/19 [==>...........................] - ETA: 59s - loss: 1.0307 - categorical_accuracy: 0.6250 -----Batch3: size: 8\n",
            " 3/19 [===>..........................] - ETA: 56s - loss: 1.1183 - categorical_accuracy: 0.5417-----Batch4: size: 8\n",
            " 4/19 [=====>........................] - ETA: 52s - loss: 1.1904 - categorical_accuracy: 0.4688-----Batch5: size: 8\n",
            " 5/19 [======>.......................] - ETA: 49s - loss: 1.1864 - categorical_accuracy: 0.4750-----Batch6: size: 8\n",
            " 6/19 [========>.....................] - ETA: 45s - loss: 1.1101 - categorical_accuracy: 0.5625-----Batch7: size: 8\n",
            " 7/19 [==========>...................] - ETA: 42s - loss: 1.0759 - categorical_accuracy: 0.5893-----Batch8: size: 8\n",
            " 8/19 [===========>..................] - ETA: 38s - loss: 1.0809 - categorical_accuracy: 0.5781-----Batch9: size: 8\n",
            " 9/19 [=============>................] - ETA: 35s - loss: 1.0602 - categorical_accuracy: 0.6111-----Batch10: size: 8\n",
            "10/19 [==============>...............] - ETA: 31s - loss: 1.0896 - categorical_accuracy: 0.5875-----Batch11: size: 8\n",
            "11/19 [================>.............] - ETA: 28s - loss: 1.1079 - categorical_accuracy: 0.5795-----Batch12: size: 8\n",
            "13/19 [===================>..........] - ETA: 21s - loss: 1.0934 - categorical_accuracy: 0.5962-----Batch13: size: 8\n",
            "-----Batch14: size: 8\n",
            "15/19 [======================>.......] - ETA: 14s - loss: 1.0915 - categorical_accuracy: 0.6000-----Batch15: size: 8\n",
            "-----Batch16: size: 8\n",
            "16/19 [========================>.....] - ETA: 10s - loss: 1.0922 - categorical_accuracy: 0.6094-----Batch17: size: 8\n",
            "17/19 [=========================>....] - ETA: 7s - loss: 1.0843 - categorical_accuracy: 0.6103 -----last Batch size: 6\n",
            "19/19 [==============================] - ETA: 0s - loss: 1.0899 - categorical_accuracy: 0.6067-----Batch0: size: 8\n",
            "-----Batch9: size: 8\n",
            "-----Batch10: size: 8\n",
            "-----Batch11: size: 8\n",
            "-----last Batch size: 4\n",
            "-----Batch0: size: 8\n",
            "-----Batch1: size: 8\n",
            "-----Batch2: size: 8\n",
            "-----Batch3: size: 8\n",
            "-----Batch4: size: 8\n",
            "-----Batch5: size: 8\n",
            "-----Batch6: size: 8\n",
            "-----Batch7: size: 8\n",
            "-----Batch8: size: 8\n",
            "-----Batch9: size: 8\n",
            "\n",
            "Epoch 00010: saving model to model_init_2021-12-2811_08_06.866220\\model-00010-1.08991-0.60667-1.36217-0.44000.h5\n",
            "19/19 [==============================] - 87s 5s/step - loss: 1.0899 - categorical_accuracy: 0.6067 - val_loss: 1.3622 - val_categorical_accuracy: 0.4400 - lr: 1.0000e-04\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x2e890575fd0>"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Ablation\n",
        "num_epochs = 10\n",
        "train_generator,val_generator,steps_per_epoch,validation_steps = sample_set(8,150,(180,180))\n",
        "callbacks_list = save_model('categorical_accuracy')\n",
        "model = model_cnn_rnn_2()\n",
        "model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "                    callbacks=callbacks_list, validation_data=val_generator, \n",
        "                    validation_steps=validation_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ry1q4tkNrcyT"
      },
      "source": [
        "model is able to overfit on small set of data. So let's train the model on complete dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwI1-bHrrcyT",
        "outputId": "64f39ce1-0a4a-4c2c-a8a4-c980dea0fe34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_train_sequences:663, num_val_sequences:100, steps_per_epoch:34, validation_steps:5\n",
            "-----Batch0: size: 20\n",
            "Epoch 1/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 7:18 - loss: 1.6148 - categorical_accuracy: 0.1500-----Batch2: size: 20\n",
            " 3/34 [=>............................] - ETA: 4:26 - loss: 1.6104 - categorical_accuracy: 0.1667-----Batch3: size: 20\n",
            " 4/34 [==>...........................] - ETA: 4:19 - loss: 1.6078 - categorical_accuracy: 0.2000-----Batch4: size: 20\n",
            " 5/34 [===>..........................] - ETA: 4:15 - loss: 1.6096 - categorical_accuracy: 0.1900-----Batch5: size: 20\n",
            "-----Batch6: size: 20\n",
            " 6/34 [====>.........................] - ETA: 4:19 - loss: 1.6094 - categorical_accuracy: 0.1833-----Batch7: size: 20\n",
            " 7/34 [=====>........................] - ETA: 4:07 - loss: 1.6122 - categorical_accuracy: 0.1786-----Batch8: size: 20\n",
            " 9/34 [======>.......................] - ETA: 3:43 - loss: 1.6123 - categorical_accuracy: 0.1722-----Batch9: size: 20\n",
            "10/34 [=======>......................] - ETA: 3:33 - loss: 1.6135 - categorical_accuracy: 0.1650-----Batch10: size: 20\n",
            "11/34 [========>.....................] - ETA: 3:22 - loss: 1.6135 - categorical_accuracy: 0.1727-----Batch11: size: 20\n",
            "12/34 [=========>....................] - ETA: 3:12 - loss: 1.6126 - categorical_accuracy: 0.1792-----Batch12: size: 20\n",
            "13/34 [==========>...................] - ETA: 3:03 - loss: 1.6113 - categorical_accuracy: 0.1846-----Batch13: size: 20\n",
            "14/34 [===========>..................] - ETA: 2:54 - loss: 1.6110 - categorical_accuracy: 0.1857-----Batch14: size: 20\n",
            "15/34 [============>.................] - ETA: 2:45 - loss: 1.6106 - categorical_accuracy: 0.1867-----Batch15: size: 20\n",
            "-----Batch16: size: 20\n",
            "17/34 [==============>...............] - ETA: 2:27 - loss: 1.6102 - categorical_accuracy: 0.1912-----Batch17: size: 20\n",
            "-----Batch18: size: 20\n",
            "18/34 [==============>...............] - ETA: 2:18 - loss: 1.6097 - categorical_accuracy: 0.1917-----Batch19: size: 20\n",
            "20/34 [================>.............] - ETA: 2:00 - loss: 1.6100 - categorical_accuracy: 0.1850-----Batch20: size: 20\n",
            "21/34 [=================>............] - ETA: 1:52 - loss: 1.6085 - categorical_accuracy: 0.1952-----Batch21: size: 20\n",
            "-----Batch22: size: 20\n",
            "23/34 [===================>..........] - ETA: 1:34 - loss: 1.6072 - categorical_accuracy: 0.2043-----Batch23: size: 20\n",
            "24/34 [====================>.........] - ETA: 1:26 - loss: 1.6062 - categorical_accuracy: 0.2104-----Batch24: size: 20\n",
            "-----Batch25: size: 20\n",
            "25/34 [=====================>........] - ETA: 1:17 - loss: 1.6056 - categorical_accuracy: 0.2100-----Batch26: size: 20\n",
            "26/34 [=====================>........] - ETA: 1:08 - loss: 1.6050 - categorical_accuracy: 0.2154-----Batch27: size: 20\n",
            "27/34 [======================>.......] - ETA: 59s - loss: 1.6058 - categorical_accuracy: 0.2148 -----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 51s - loss: 1.6063 - categorical_accuracy: 0.2089-----Batch29: size: 20\n",
            "30/34 [=========================>....] - ETA: 34s - loss: 1.6051 - categorical_accuracy: 0.2150-----Batch30: size: 20\n",
            "31/34 [==========================>...] - ETA: 25s - loss: 1.6044 - categorical_accuracy: 0.2145-----Batch31: size: 20\n",
            "-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 17s - loss: 1.6043 - categorical_accuracy: 0.2141-----last Batch size: 3\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.6045 - categorical_accuracy: 0.2112-----Batch0: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "\n",
            "Epoch 00001: saving model to model_init_2021-12-2811_28_45.676793\\model-00001-1.60453-0.21116-1.58117-0.28000.h5\n",
            "34/34 [==============================] - 320s 9s/step - loss: 1.6045 - categorical_accuracy: 0.2112 - val_loss: 1.5812 - val_categorical_accuracy: 0.2800 - lr: 1.0000e-04\n",
            "Epoch 2/16\n",
            " 1/34 [..............................] - ETA: 4:26 - loss: 1.5739 - categorical_accuracy: 0.3000-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            " 3/34 [=>............................] - ETA: 4:46 - loss: 1.5616 - categorical_accuracy: 0.4333-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            " 4/34 [==>...........................] - ETA: 4:32 - loss: 1.5717 - categorical_accuracy: 0.3500-----Batch5: size: 20\n",
            " 5/34 [===>..........................] - ETA: 4:17 - loss: 1.5783 - categorical_accuracy: 0.3100-----Batch6: size: 20\n",
            " 7/34 [=====>........................] - ETA: 3:54 - loss: 1.5739 - categorical_accuracy: 0.2857-----Batch7: size: 20\n",
            "-----Batch8: size: 20\n",
            " 8/34 [======>.......................] - ETA: 3:45 - loss: 1.5745 - categorical_accuracy: 0.2875-----Batch9: size: 20\n",
            " 9/34 [======>.......................] - ETA: 3:35 - loss: 1.5742 - categorical_accuracy: 0.2889-----Batch10: size: 20\n",
            "11/34 [========>.....................] - ETA: 3:17 - loss: 1.5720 - categorical_accuracy: 0.3136-----Batch11: size: 20\n",
            "-----Batch12: size: 20\n",
            "12/34 [=========>....................] - ETA: 3:08 - loss: 1.5713 - categorical_accuracy: 0.3125-----Batch13: size: 20\n",
            "14/34 [===========>..................] - ETA: 2:51 - loss: 1.5695 - categorical_accuracy: 0.3107-----Batch14: size: 20\n",
            "-----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 2:42 - loss: 1.5720 - categorical_accuracy: 0.3000-----Batch16: size: 20\n",
            "17/34 [==============>...............] - ETA: 2:24 - loss: 1.5697 - categorical_accuracy: 0.3059-----Batch17: size: 20\n",
            "-----Batch18: size: 20\n",
            "18/34 [==============>...............] - ETA: 2:15 - loss: 1.5693 - categorical_accuracy: 0.3083-----Batch19: size: 20\n",
            "19/34 [===============>..............] - ETA: 2:07 - loss: 1.5720 - categorical_accuracy: 0.3079-----Batch20: size: 20\n",
            "20/34 [================>.............] - ETA: 1:58 - loss: 1.5695 - categorical_accuracy: 0.3075-----Batch21: size: 20\n",
            "22/34 [==================>...........] - ETA: 1:41 - loss: 1.5596 - categorical_accuracy: 0.3136-----Batch22: size: 20\n",
            "23/34 [===================>..........] - ETA: 1:32 - loss: 1.5616 - categorical_accuracy: 0.3065-----Batch23: size: 20\n",
            "24/34 [====================>.........] - ETA: 1:24 - loss: 1.5688 - categorical_accuracy: 0.3000-----Batch24: size: 20\n",
            "-----Batch25: size: 20\n",
            "26/34 [=====================>........] - ETA: 1:07 - loss: 1.5633 - categorical_accuracy: 0.3000-----Batch26: size: 20\n",
            "27/34 [======================>.......] - ETA: 59s - loss: 1.5614 - categorical_accuracy: 0.3019 -----Batch27: size: 20\n",
            "-----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 50s - loss: 1.5558 - categorical_accuracy: 0.3071-----Batch29: size: 20\n",
            "30/34 [=========================>....] - ETA: 33s - loss: 1.5498 - categorical_accuracy: 0.3083-----Batch30: size: 20\n",
            "-----Batch31: size: 20\n",
            "32/34 [===========================>..] - ETA: 16s - loss: 1.5466 - categorical_accuracy: 0.3047-----Batch32: size: 20\n",
            "-----last Batch size: 3\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.5432 - categorical_accuracy: 0.3062-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "\n",
            "Epoch 00002: saving model to model_init_2021-12-2811_28_45.676793\\model-00002-1.54320-0.30618-1.45830-0.38000.h5\n",
            "34/34 [==============================] - 315s 9s/step - loss: 1.5432 - categorical_accuracy: 0.3062 - val_loss: 1.4583 - val_categorical_accuracy: 0.3800 - lr: 1.0000e-04\n",
            "Epoch 3/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 4:27 - loss: 1.4166 - categorical_accuracy: 0.5000-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 4:20 - loss: 1.3844 - categorical_accuracy: 0.47-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 4:14 - loss: 1.3516 - categorical_accuracy: 0.5333-----Batch4: size: 20\n",
            " 5/34 [===>..........................] - ETA: 4:01 - loss: 1.3672 - categorical_accuracy: 0.5100-----Batch5: size: 20\n",
            "-----Batch6: size: 20\n",
            " 7/34 [=====>........................] - ETA: 3:45 - loss: 1.3696 - categorical_accuracy: 0.5143-----Batch7: size: 20\n",
            " 8/34 [======>.......................] - ETA: 3:37 - loss: 1.3639 - categorical_accuracy: 0.5000-----Batch8: size: 20\n",
            " 9/34 [======>.......................] - ETA: 3:30 - loss: 1.3745 - categorical_accuracy: 0.4889-----Batch9: size: 20\n",
            "-----Batch10: size: 20\n",
            "10/34 [=======>......................] - ETA: 3:21 - loss: 1.3903 - categorical_accuracy: 0.4750-----Batch11: size: 20\n",
            "11/34 [========>.....................] - ETA: 3:12 - loss: 1.3724 - categorical_accuracy: 0.4773-----Batch12: size: 20\n",
            "12/34 [=========>....................] - ETA: 3:03 - loss: 1.3670 - categorical_accuracy: 0.4708-----Batch13: size: 20\n",
            "14/34 [===========>..................] - ETA: 2:46 - loss: 1.3469 - categorical_accuracy: 0.4821-----Batch14: size: 20\n",
            "-----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 2:38 - loss: 1.3447 - categorical_accuracy: 0.4767-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 2:30 - loss: 1.3509 - categorical_accuracy: 0.4719-----Batch17: size: 20\n",
            "17/34 [==============>...............] - ETA: 2:21 - loss: 1.3389 - categorical_accuracy: 0.4735-----Batch18: size: 20\n",
            "18/34 [==============>...............] - ETA: 2:13 - loss: 1.3621 - categorical_accuracy: 0.4611-----Batch19: size: 20\n",
            "19/34 [===============>..............] - ETA: 2:04 - loss: 1.3661 - categorical_accuracy: 0.4553-----Batch20: size: 20\n",
            "21/34 [=================>............] - ETA: 1:48 - loss: 1.3693 - categorical_accuracy: 0.4619-----Batch21: size: 20\n",
            "22/34 [==================>...........] - ETA: 1:40 - loss: 1.3661 - categorical_accuracy: 0.4591-----Batch22: size: 20\n",
            "23/34 [===================>..........] - ETA: 1:32 - loss: 1.3638 - categorical_accuracy: 0.4565-----Batch23: size: 20\n",
            "-----Batch24: size: 20\n",
            "25/34 [=====================>........] - ETA: 1:15 - loss: 1.3635 - categorical_accuracy: 0.4560-----Batch25: size: 20\n",
            "-----Batch26: size: 20\n",
            "27/34 [======================>.......] - ETA: 58s - loss: 1.3671 - categorical_accuracy: 0.4537 -----Batch27: size: 20\n",
            "28/34 [=======================>......] - ETA: 50s - loss: 1.3655 - categorical_accuracy: 0.4589-----Batch28: size: 20\n",
            "29/34 [========================>.....] - ETA: 42s - loss: 1.3749 - categorical_accuracy: 0.4586-----Batch29: size: 20\n",
            "-----Batch30: size: 20\n",
            "31/34 [==========================>...] - ETA: 25s - loss: 1.3633 - categorical_accuracy: 0.4581-----Batch31: size: 20\n",
            "32/34 [===========================>..] - ETA: 16s - loss: 1.3684 - categorical_accuracy: 0.4531-----Batch32: size: 20\n",
            "-----last Batch size: 3\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.3691 - categorical_accuracy: 0.4540-----Batch0: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "\n",
            "Epoch 00003: saving model to model_init_2021-12-2811_28_45.676793\\model-00003-1.36915-0.45400-1.33814-0.46000.h5\n",
            "34/34 [==============================] - 304s 9s/step - loss: 1.3691 - categorical_accuracy: 0.4540 - val_loss: 1.3381 - val_categorical_accuracy: 0.4600 - lr: 1.0000e-04\n",
            "Epoch 4/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 4:30 - loss: 1.2048 - categorical_accuracy: 0.6500-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 4:22 - loss: 1.1756 - categorical_accuracy: 0.6750-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 4:12 - loss: 1.2044 - categorical_accuracy: 0.6333-----Batch4: size: 20\n",
            " 4/34 [==>...........................] - ETA: 4:03 - loss: 1.2307 - categorical_accuracy: 0.5875-----Batch5: size: 20\n",
            " 6/34 [====>.........................] - ETA: 3:50 - loss: 1.2321 - categorical_accuracy: 0.5750-----Batch6: size: 20\n",
            " 7/34 [=====>........................] - ETA: 3:45 - loss: 1.2605 - categorical_accuracy: 0.5571-----Batch7: size: 20\n",
            "-----Batch8: size: 20\n",
            " 9/34 [======>.......................] - ETA: 3:28 - loss: 1.2524 - categorical_accuracy: 0.5333-----Batch9: size: 20\n",
            "-----Batch10: size: 20\n",
            "10/34 [=======>......................] - ETA: 3:20 - loss: 1.2495 - categorical_accuracy: 0.5200-----Batch11: size: 20\n",
            "11/34 [========>.....................] - ETA: 3:11 - loss: 1.2579 - categorical_accuracy: 0.5182-----Batch12: size: 20\n",
            "12/34 [=========>....................] - ETA: 3:03 - loss: 1.2439 - categorical_accuracy: 0.5292-----Batch13: size: 20\n",
            "14/34 [===========>..................] - ETA: 2:46 - loss: 1.2438 - categorical_accuracy: 0.5321-----Batch14: size: 20\n",
            "-----Batch15: size: 20\n",
            "16/34 [=============>................] - ETA: 2:29 - loss: 1.2366 - categorical_accuracy: 0.5281-----Batch16: size: 20\n",
            "-----Batch17: size: 20\n",
            "17/34 [==============>...............] - ETA: 2:21 - loss: 1.2330 - categorical_accuracy: 0.5235-----Batch18: size: 20\n",
            "18/34 [==============>...............] - ETA: 2:12 - loss: 1.2119 - categorical_accuracy: 0.5361-----Batch19: size: 20\n",
            "19/34 [===============>..............] - ETA: 2:04 - loss: 1.2060 - categorical_accuracy: 0.5342-----Batch20: size: 20\n",
            "20/34 [================>.............] - ETA: 1:56 - loss: 1.2076 - categorical_accuracy: 0.5325-----Batch21: size: 20\n",
            "22/34 [==================>...........] - ETA: 1:40 - loss: 1.2273 - categorical_accuracy: 0.5273-----Batch22: size: 20\n",
            "-----Batch23: size: 20\n",
            "24/34 [====================>.........] - ETA: 1:23 - loss: 1.2330 - categorical_accuracy: 0.5250-----Batch24: size: 20\n",
            "-----Batch25: size: 20\n",
            "26/34 [=====================>........] - ETA: 1:06 - loss: 1.2361 - categorical_accuracy: 0.5269-----Batch26: size: 20\n",
            "-----Batch27: size: 20\n",
            "27/34 [======================>.......] - ETA: 58s - loss: 1.2476 - categorical_accuracy: 0.5204 -----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 50s - loss: 1.2500 - categorical_accuracy: 0.5161-----Batch29: size: 20\n",
            "30/34 [=========================>....] - ETA: 33s - loss: 1.2428 - categorical_accuracy: 0.5250-----Batch30: size: 20\n",
            "31/34 [==========================>...] - ETA: 25s - loss: 1.2418 - categorical_accuracy: 0.5274-----Batch31: size: 20\n",
            "32/34 [===========================>..] - ETA: 16s - loss: 1.2389 - categorical_accuracy: 0.5266-----Batch32: size: 20\n",
            "-----last Batch size: 3\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.2377 - categorical_accuracy: 0.5249-----Batch0: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "\n",
            "Epoch 00004: saving model to model_init_2021-12-2811_28_45.676793\\model-00004-1.23771-0.52489-1.32722-0.49000.h5\n",
            "34/34 [==============================] - 305s 9s/step - loss: 1.2377 - categorical_accuracy: 0.5249 - val_loss: 1.3272 - val_categorical_accuracy: 0.4900 - lr: 1.0000e-04\n",
            "Epoch 5/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 4:25 - loss: 1.0271 - categorical_accuracy: 0.5500-----Batch2: size: 20\n",
            " 3/34 [=>............................] - ETA: 4:13 - loss: 1.2925 - categorical_accuracy: 0.4167-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            " 4/34 [==>...........................] - ETA: 4:10 - loss: 1.2578 - categorical_accuracy: 0.4375-----Batch5: size: 20\n",
            " 6/34 [====>.........................] - ETA: 3:51 - loss: 1.2498 - categorical_accuracy: 0.4583-----Batch6: size: 20\n",
            "-----Batch7: size: 20\n",
            " 8/34 [======>.......................] - ETA: 3:35 - loss: 1.2310 - categorical_accuracy: 0.4625-----Batch8: size: 20\n",
            " 9/34 [======>.......................] - ETA: 3:28 - loss: 1.2190 - categorical_accuracy: 0.4667-----Batch9: size: 20\n",
            "-----Batch10: size: 20\n",
            "10/34 [=======>......................] - ETA: 3:21 - loss: 1.2015 - categorical_accuracy: 0.4800-----Batch11: size: 20\n",
            "12/34 [=========>....................] - ETA: 3:04 - loss: 1.1956 - categorical_accuracy: 0.4958-----Batch12: size: 20\n",
            "13/34 [==========>...................] - ETA: 2:56 - loss: 1.2087 - categorical_accuracy: 0.5000-----Batch13: size: 20\n",
            "14/34 [===========>..................] - ETA: 2:48 - loss: 1.1999 - categorical_accuracy: 0.5000-----Batch14: size: 20\n",
            "15/34 [============>.................] - ETA: 2:40 - loss: 1.1913 - categorical_accuracy: 0.5067-----Batch15: size: 20\n",
            "-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 2:31 - loss: 1.1923 - categorical_accuracy: 0.5125-----Batch17: size: 20\n",
            "17/34 [==============>...............] - ETA: 2:23 - loss: 1.1981 - categorical_accuracy: 0.5147-----Batch18: size: 20\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18/34 [==============>...............] - ETA: 2:14 - loss: 1.2022 - categorical_accuracy: 0.5167-----Batch19: size: 20\n",
            "20/34 [================>.............] - ETA: 1:57 - loss: 1.1854 - categorical_accuracy: 0.5250-----Batch20: size: 20\n",
            "-----Batch21: size: 20\n",
            "22/34 [==================>...........] - ETA: 1:40 - loss: 1.1875 - categorical_accuracy: 0.5295-----Batch22: size: 20\n",
            "-----Batch23: size: 20\n",
            "24/34 [====================>.........] - ETA: 1:23 - loss: 1.1816 - categorical_accuracy: 0.5354-----Batch24: size: 20\n",
            "-----Batch25: size: 20\n",
            "26/34 [=====================>........] - ETA: 1:06 - loss: 1.1649 - categorical_accuracy: 0.5500-----Batch26: size: 20\n",
            "-----Batch27: size: 20\n",
            "27/34 [======================>.......] - ETA: 58s - loss: 1.1725 - categorical_accuracy: 0.5519 -----Batch28: size: 20\n",
            "29/34 [========================>.....] - ETA: 41s - loss: 1.1656 - categorical_accuracy: 0.5569-----Batch29: size: 20\n",
            "-----Batch30: size: 20\n",
            "30/34 [=========================>....] - ETA: 33s - loss: 1.1554 - categorical_accuracy: 0.5650-----Batch31: size: 20\n",
            "31/34 [==========================>...] - ETA: 25s - loss: 1.1524 - categorical_accuracy: 0.5661-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 16s - loss: 1.1468 - categorical_accuracy: 0.5703-----last Batch size: 3\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.1417 - categorical_accuracy: 0.5671-----Batch0: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "\n",
            "Epoch 00005: saving model to model_init_2021-12-2811_28_45.676793\\model-00005-1.14172-0.56712-1.13465-0.57000.h5\n",
            "34/34 [==============================] - 300s 9s/step - loss: 1.1417 - categorical_accuracy: 0.5671 - val_loss: 1.1347 - val_categorical_accuracy: 0.5700 - lr: 1.0000e-04\n",
            "Epoch 6/16\n",
            "-----Batch1: size: 20\n",
            " 2/34 [>.............................] - ETA: 4:22 - loss: 1.0095 - categorical_accuracy: 0.6750-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 4:18 - loss: 1.0442 - categorical_accuracy: 0.6333-----Batch4: size: 20\n",
            " 4/34 [==>...........................] - ETA: 4:12 - loss: 1.0278 - categorical_accuracy: 0.6375-----Batch5: size: 20\n",
            " 5/34 [===>..........................] - ETA: 4:02 - loss: 1.0562 - categorical_accuracy: 0.6100-----Batch6: size: 20\n",
            " 6/34 [====>.........................] - ETA: 3:53 - loss: 1.0357 - categorical_accuracy: 0.6083-----Batch7: size: 20\n",
            " 8/34 [======>.......................] - ETA: 3:36 - loss: 1.0215 - categorical_accuracy: 0.6250-----Batch8: size: 20\n",
            "-----Batch9: size: 20\n",
            "10/34 [=======>......................] - ETA: 3:19 - loss: 1.0174 - categorical_accuracy: 0.6250-----Batch10: size: 20\n",
            "-----Batch11: size: 20\n",
            "12/34 [=========>....................] - ETA: 3:03 - loss: 1.0190 - categorical_accuracy: 0.6208-----Batch12: size: 20\n",
            "-----Batch13: size: 20\n",
            "13/34 [==========>...................] - ETA: 2:55 - loss: 1.0163 - categorical_accuracy: 0.6346-----Batch14: size: 20\n",
            "14/34 [===========>..................] - ETA: 2:46 - loss: 1.0187 - categorical_accuracy: 0.6357-----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 2:38 - loss: 1.0138 - categorical_accuracy: 0.6400-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 2:29 - loss: 1.0110 - categorical_accuracy: 0.6438-----Batch17: size: 20\n",
            "17/34 [==============>...............] - ETA: 2:21 - loss: 1.0152 - categorical_accuracy: 0.6441-----Batch18: size: 20\n",
            "18/34 [==============>...............] - ETA: 2:13 - loss: 1.0232 - categorical_accuracy: 0.6444-----Batch19: size: 20\n",
            "20/34 [================>.............] - ETA: 1:56 - loss: 1.0095 - categorical_accuracy: 0.6525-----Batch20: size: 20\n",
            "-----Batch21: size: 20\n",
            "21/34 [=================>............] - ETA: 1:48 - loss: 0.9983 - categorical_accuracy: 0.6548-----Batch22: size: 20\n",
            "22/34 [==================>...........] - ETA: 1:39 - loss: 0.9981 - categorical_accuracy: 0.6568-----Batch23: size: 20\n",
            "24/34 [====================>.........] - ETA: 1:23 - loss: 0.9997 - categorical_accuracy: 0.6500-----Batch24: size: 20\n",
            "-----Batch25: size: 20\n",
            "25/34 [=====================>........] - ETA: 1:14 - loss: 0.9957 - categorical_accuracy: 0.6540-----Batch26: size: 20\n",
            "27/34 [======================>.......] - ETA: 58s - loss: 0.9944 - categorical_accuracy: 0.6463 -----Batch27: size: 20\n",
            "28/34 [=======================>......] - ETA: 49s - loss: 1.0013 - categorical_accuracy: 0.6393-----Batch28: size: 20\n",
            "29/34 [========================>.....] - ETA: 41s - loss: 1.0011 - categorical_accuracy: 0.6362-----Batch29: size: 20\n",
            "30/34 [=========================>....] - ETA: 33s - loss: 1.0004 - categorical_accuracy: 0.6300-----Batch30: size: 20\n",
            "-----Batch31: size: 20\n",
            "31/34 [==========================>...] - ETA: 24s - loss: 1.0147 - categorical_accuracy: 0.6242-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 16s - loss: 1.0286 - categorical_accuracy: 0.6187-----last Batch size: 3\n",
            "34/34 [==============================] - ETA: 0s - loss: 1.0298 - categorical_accuracy: 0.6229-----Batch0: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "\n",
            "Epoch 00006: saving model to model_init_2021-12-2811_28_45.676793\\model-00006-1.02983-0.62293-1.03267-0.61000.h5\n",
            "34/34 [==============================] - 300s 9s/step - loss: 1.0298 - categorical_accuracy: 0.6229 - val_loss: 1.0327 - val_categorical_accuracy: 0.6100 - lr: 1.0000e-04\n",
            "Epoch 7/16\n",
            "-----Batch1: size: 20\n",
            " 2/34 [>.............................] - ETA: 4:25 - loss: 0.6707 - categorical_accuracy: 0.8250-----Batch2: size: 20\n",
            " 3/34 [=>............................] - ETA: 4:24 - loss: 0.7811 - categorical_accuracy: 0.7500-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            " 4/34 [==>...........................] - ETA: 4:17 - loss: 0.8718 - categorical_accuracy: 0.7000-----Batch5: size: 20\n",
            " 5/34 [===>..........................] - ETA: 4:06 - loss: 0.8861 - categorical_accuracy: 0.7000-----Batch6: size: 20\n",
            " 6/34 [====>.........................] - ETA: 3:56 - loss: 0.8865 - categorical_accuracy: 0.7083-----Batch7: size: 20\n",
            " 7/34 [=====>........................] - ETA: 3:46 - loss: 0.8886 - categorical_accuracy: 0.6929-----Batch8: size: 20\n",
            " 8/34 [======>.......................] - ETA: 3:37 - loss: 0.9145 - categorical_accuracy: 0.6687-----Batch9: size: 20\n",
            " 9/34 [======>.......................] - ETA: 3:29 - loss: 0.8955 - categorical_accuracy: 0.6944-----Batch10: size: 20\n",
            "10/34 [=======>......................] - ETA: 3:20 - loss: 0.8792 - categorical_accuracy: 0.7100-----Batch11: size: 20\n",
            "12/34 [=========>....................] - ETA: 3:03 - loss: 0.9081 - categorical_accuracy: 0.6917-----Batch12: size: 20\n",
            "-----Batch13: size: 20\n",
            "13/34 [==========>...................] - ETA: 2:55 - loss: 0.9097 - categorical_accuracy: 0.6923-----Batch14: size: 20\n",
            "14/34 [===========>..................] - ETA: 2:46 - loss: 0.9091 - categorical_accuracy: 0.6929-----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 2:38 - loss: 0.8986 - categorical_accuracy: 0.7033-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 2:29 - loss: 0.8957 - categorical_accuracy: 0.7031-----Batch17: size: 20\n",
            "17/34 [==============>...............] - ETA: 2:21 - loss: 0.8928 - categorical_accuracy: 0.7088-----Batch18: size: 20\n",
            "18/34 [==============>...............] - ETA: 2:13 - loss: 0.8969 - categorical_accuracy: 0.7056-----Batch19: size: 20\n",
            "20/34 [================>.............] - ETA: 1:56 - loss: 0.8964 - categorical_accuracy: 0.7125-----Batch20: size: 20\n",
            "21/34 [=================>............] - ETA: 1:48 - loss: 0.8916 - categorical_accuracy: 0.7167-----Batch21: size: 20\n",
            "-----Batch22: size: 20\n",
            "22/34 [==================>...........] - ETA: 1:40 - loss: 0.8908 - categorical_accuracy: 0.7182-----Batch23: size: 20\n",
            "23/34 [===================>..........] - ETA: 1:31 - loss: 0.9056 - categorical_accuracy: 0.7087-----Batch24: size: 20\n",
            "25/34 [=====================>........] - ETA: 1:14 - loss: 0.8879 - categorical_accuracy: 0.7100-----Batch25: size: 20\n",
            "26/34 [=====================>........] - ETA: 1:06 - loss: 0.8941 - categorical_accuracy: 0.7058-----Batch26: size: 20\n",
            "-----Batch27: size: 20\n",
            "27/34 [======================>.......] - ETA: 58s - loss: 0.9174 - categorical_accuracy: 0.6963 -----Batch28: size: 20\n",
            "29/34 [========================>.....] - ETA: 41s - loss: 0.9304 - categorical_accuracy: 0.6845-----Batch29: size: 20\n",
            "-----Batch30: size: 20\n",
            "30/34 [=========================>....] - ETA: 33s - loss: 0.9283 - categorical_accuracy: 0.6833-----Batch31: size: 20\n",
            "31/34 [==========================>...] - ETA: 25s - loss: 0.9203 - categorical_accuracy: 0.6871-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 16s - loss: 0.9244 - categorical_accuracy: 0.6828-----last Batch size: 3\n",
            "34/34 [==============================] - ETA: 0s - loss: 0.9155 - categorical_accuracy: 0.6848-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "\n",
            "Epoch 00007: saving model to model_init_2021-12-2811_28_45.676793\\model-00007-0.91546-0.68477-1.02796-0.63000.h5\n",
            "34/34 [==============================] - 306s 9s/step - loss: 0.9155 - categorical_accuracy: 0.6848 - val_loss: 1.0280 - val_categorical_accuracy: 0.6300 - lr: 1.0000e-04\n",
            "Epoch 8/16\n",
            " 1/34 [..............................] - ETA: 4:28 - loss: 0.7037 - categorical_accuracy: 0.7500-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 4:30 - loss: 0.7077 - categorical_accuracy: 0.7500-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 4:19 - loss: 0.8661 - categorical_accuracy: 0.7000-----Batch4: size: 20\n",
            " 4/34 [==>...........................] - ETA: 4:14 - loss: 0.8734 - categorical_accuracy: 0.6875-----Batch5: size: 20\n",
            " 6/34 [====>.........................] - ETA: 3:56 - loss: 0.8218 - categorical_accuracy: 0.7000-----Batch6: size: 20\n",
            "-----Batch7: size: 20\n",
            " 8/34 [======>.......................] - ETA: 3:40 - loss: 0.8449 - categorical_accuracy: 0.7063-----Batch8: size: 20\n",
            " 9/34 [======>.......................] - ETA: 3:33 - loss: 0.8685 - categorical_accuracy: 0.6889-----Batch9: size: 20\n",
            "-----Batch10: size: 20\n",
            "11/34 [========>.....................] - ETA: 3:15 - loss: 0.8516 - categorical_accuracy: 0.6955-----Batch11: size: 20\n",
            "-----Batch12: size: 20\n",
            "12/34 [=========>....................] - ETA: 3:07 - loss: 0.8410 - categorical_accuracy: 0.7042-----Batch13: size: 20\n",
            "13/34 [==========>...................] - ETA: 2:59 - loss: 0.8482 - categorical_accuracy: 0.7000-----Batch14: size: 20\n",
            "15/34 [============>.................] - ETA: 2:41 - loss: 0.8406 - categorical_accuracy: 0.7033-----Batch15: size: 20\n",
            "-----Batch16: size: 20\n",
            "17/34 [==============>...............] - ETA: 2:25 - loss: 0.8318 - categorical_accuracy: 0.7029-----Batch17: size: 20\n",
            "18/34 [==============>...............] - ETA: 2:16 - loss: 0.8372 - categorical_accuracy: 0.6972-----Batch18: size: 20\n",
            "-----Batch19: size: 20\n",
            "19/34 [===============>..............] - ETA: 2:08 - loss: 0.8307 - categorical_accuracy: 0.7053-----Batch20: size: 20\n",
            "21/34 [=================>............] - ETA: 1:51 - loss: 0.8154 - categorical_accuracy: 0.7095-----Batch21: size: 20\n",
            "-----Batch22: size: 20\n",
            "22/34 [==================>...........] - ETA: 1:42 - loss: 0.8063 - categorical_accuracy: 0.7114-----Batch23: size: 20\n",
            "23/34 [===================>..........] - ETA: 1:33 - loss: 0.8107 - categorical_accuracy: 0.7087-----Batch24: size: 20\n",
            "24/34 [====================>.........] - ETA: 1:25 - loss: 0.8141 - categorical_accuracy: 0.7063-----Batch25: size: 20\n",
            "25/34 [=====================>........] - ETA: 1:16 - loss: 0.8103 - categorical_accuracy: 0.7120-----Batch26: size: 20\n",
            "27/34 [======================>.......] - ETA: 59s - loss: 0.8320 - categorical_accuracy: 0.7074 -----Batch27: size: 20\n",
            "-----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 50s - loss: 0.8240 - categorical_accuracy: 0.7143-----Batch29: size: 20\n",
            "30/34 [=========================>....] - ETA: 33s - loss: 0.8350 - categorical_accuracy: 0.7100-----Batch30: size: 20\n",
            "-----Batch31: size: 20\n",
            "32/34 [===========================>..] - ETA: 16s - loss: 0.8300 - categorical_accuracy: 0.7109-----Batch32: size: 20\n",
            "-----last Batch size: 3\n",
            "34/34 [==============================] - ETA: 0s - loss: 0.8292 - categorical_accuracy: 0.7134-----Batch0: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "\n",
            "Epoch 00008: saving model to model_init_2021-12-2811_28_45.676793\\model-00008-0.82919-0.71342-0.84477-0.71000.h5\n",
            "34/34 [==============================] - 304s 9s/step - loss: 0.8292 - categorical_accuracy: 0.7134 - val_loss: 0.8448 - val_categorical_accuracy: 0.7100 - lr: 1.0000e-04\n",
            "Epoch 9/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 4:30 - loss: 0.6339 - categorical_accuracy: 0.7500-----Batch2: size: 20\n",
            " 3/34 [=>............................] - ETA: 4:16 - loss: 0.6210 - categorical_accuracy: 0.8167-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            " 4/34 [==>...........................] - ETA: 4:10 - loss: 0.5657 - categorical_accuracy: 0.8500-----Batch5: size: 20\n",
            " 5/34 [===>..........................] - ETA: 4:03 - loss: 0.6793 - categorical_accuracy: 0.7900-----Batch6: size: 20\n",
            " 6/34 [====>.........................] - ETA: 3:55 - loss: 0.6927 - categorical_accuracy: 0.7917-----Batch7: size: 20\n",
            " 7/34 [=====>........................] - ETA: 3:46 - loss: 0.6902 - categorical_accuracy: 0.8000-----Batch8: size: 20\n",
            " 8/34 [======>.......................] - ETA: 3:38 - loss: 0.7007 - categorical_accuracy: 0.7937-----Batch9: size: 20\n",
            "10/34 [=======>......................] - ETA: 3:20 - loss: 0.7054 - categorical_accuracy: 0.7900-----Batch10: size: 20\n",
            "11/34 [========>.....................] - ETA: 3:13 - loss: 0.7284 - categorical_accuracy: 0.7773-----Batch11: size: 20\n",
            "-----Batch12: size: 20\n",
            "13/34 [==========>...................] - ETA: 2:56 - loss: 0.7245 - categorical_accuracy: 0.7769-----Batch13: size: 20\n",
            "14/34 [===========>..................] - ETA: 2:47 - loss: 0.7454 - categorical_accuracy: 0.7679-----Batch14: size: 20\n",
            "-----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 2:39 - loss: 0.7323 - categorical_accuracy: 0.7767-----Batch16: size: 20\n",
            "17/34 [==============>...............] - ETA: 2:22 - loss: 0.7511 - categorical_accuracy: 0.7441-----Batch17: size: 20\n",
            "18/34 [==============>...............] - ETA: 2:14 - loss: 0.7405 - categorical_accuracy: 0.7528-----Batch18: size: 20\n",
            "19/34 [===============>..............] - ETA: 2:05 - loss: 0.7570 - categorical_accuracy: 0.7500-----Batch19: size: 20\n",
            "-----Batch20: size: 20\n",
            "21/34 [=================>............] - ETA: 1:49 - loss: 0.7463 - categorical_accuracy: 0.7595-----Batch21: size: 20\n",
            "-----Batch22: size: 20\n",
            "23/34 [===================>..........] - ETA: 1:32 - loss: 0.7509 - categorical_accuracy: 0.7543-----Batch23: size: 20\n",
            "-----Batch24: size: 20\n",
            "25/34 [=====================>........] - ETA: 1:15 - loss: 0.7669 - categorical_accuracy: 0.7500-----Batch25: size: 20\n",
            "26/34 [=====================>........] - ETA: 1:07 - loss: 0.7660 - categorical_accuracy: 0.7538-----Batch26: size: 20\n",
            "-----Batch27: size: 20\n",
            "27/34 [======================>.......] - ETA: 58s - loss: 0.7663 - categorical_accuracy: 0.7500 -----Batch28: size: 20\n",
            "29/34 [========================>.....] - ETA: 41s - loss: 0.7532 - categorical_accuracy: 0.7552-----Batch29: size: 20\n",
            "-----Batch30: size: 20\n",
            "31/34 [==========================>...] - ETA: 25s - loss: 0.7626 - categorical_accuracy: 0.7387-----Batch31: size: 20\n",
            "32/34 [===========================>..] - ETA: 16s - loss: 0.7588 - categorical_accuracy: 0.7375-----Batch32: size: 20\n",
            "-----last Batch size: 3\n",
            "34/34 [==============================] - ETA: 0s - loss: 0.7560 - categorical_accuracy: 0.7391-----Batch0: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "\n",
            "Epoch 00009: saving model to model_init_2021-12-2811_28_45.676793\\model-00009-0.75604-0.73906-0.89222-0.64000.h5\n",
            "34/34 [==============================] - 309s 9s/step - loss: 0.7560 - categorical_accuracy: 0.7391 - val_loss: 0.8922 - val_categorical_accuracy: 0.6400 - lr: 1.0000e-04\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/16\n",
            " 1/34 [..............................] - ETA: 4:29 - loss: 0.7366 - categorical_accuracy: 0.7500-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 4:34 - loss: 0.7419 - categorical_accuracy: 0.7250-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 4:25 - loss: 0.7676 - categorical_accuracy: 0.7500-----Batch4: size: 20\n",
            " 5/34 [===>..........................] - ETA: 4:08 - loss: 0.7469 - categorical_accuracy: 0.7700-----Batch5: size: 20\n",
            "-----Batch6: size: 20\n",
            " 7/34 [=====>........................] - ETA: 3:49 - loss: 0.7438 - categorical_accuracy: 0.7500-----Batch7: size: 20\n",
            "-----Batch8: size: 20\n",
            " 8/34 [======>.......................] - ETA: 3:40 - loss: 0.7668 - categorical_accuracy: 0.7437-----Batch9: size: 20\n",
            " 9/34 [======>.......................] - ETA: 3:31 - loss: 0.7502 - categorical_accuracy: 0.7611-----Batch10: size: 20\n",
            "11/34 [========>.....................] - ETA: 3:13 - loss: 0.7008 - categorical_accuracy: 0.7909-----Batch11: size: 20\n",
            "-----Batch12: size: 20\n",
            "12/34 [=========>....................] - ETA: 3:05 - loss: 0.6745 - categorical_accuracy: 0.8000-----Batch13: size: 20\n",
            "13/34 [==========>...................] - ETA: 2:56 - loss: 0.6683 - categorical_accuracy: 0.7962-----Batch14: size: 20\n",
            "14/34 [===========>..................] - ETA: 2:47 - loss: 0.6630 - categorical_accuracy: 0.7964-----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 2:38 - loss: 0.6545 - categorical_accuracy: 0.8000-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 2:30 - loss: 0.6654 - categorical_accuracy: 0.7969-----Batch17: size: 20\n",
            "17/34 [==============>...............] - ETA: 2:22 - loss: 0.6606 - categorical_accuracy: 0.7971-----Batch18: size: 20\n",
            "19/34 [===============>..............] - ETA: 2:05 - loss: 0.6568 - categorical_accuracy: 0.7947-----Batch19: size: 20\n",
            "-----Batch20: size: 20\n",
            "20/34 [================>.............] - ETA: 1:57 - loss: 0.6507 - categorical_accuracy: 0.7975-----Batch21: size: 20\n",
            "21/34 [=================>............] - ETA: 1:49 - loss: 0.6585 - categorical_accuracy: 0.7881-----Batch22: size: 20\n",
            "22/34 [==================>...........] - ETA: 1:40 - loss: 0.6436 - categorical_accuracy: 0.7955-----Batch23: size: 20\n",
            "23/34 [===================>..........] - ETA: 1:32 - loss: 0.6515 - categorical_accuracy: 0.7891-----Batch24: size: 20\n",
            "25/34 [=====================>........] - ETA: 1:15 - loss: 0.6502 - categorical_accuracy: 0.7880-----Batch25: size: 20\n",
            "-----Batch26: size: 20\n",
            "27/34 [======================>.......] - ETA: 58s - loss: 0.6513 - categorical_accuracy: 0.7870 -----Batch27: size: 20\n",
            "-----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 50s - loss: 0.6496 - categorical_accuracy: 0.7875-----Batch29: size: 20\n",
            "30/34 [=========================>....] - ETA: 33s - loss: 0.6376 - categorical_accuracy: 0.7883-----Batch30: size: 20\n",
            "31/34 [==========================>...] - ETA: 25s - loss: 0.6356 - categorical_accuracy: 0.7887-----Batch31: size: 20\n",
            "32/34 [===========================>..] - ETA: 16s - loss: 0.6338 - categorical_accuracy: 0.7906-----Batch32: size: 20\n",
            "-----last Batch size: 3\n",
            "34/34 [==============================] - ETA: 0s - loss: 0.6458 - categorical_accuracy: 0.7873-----Batch0: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "\n",
            "Epoch 00010: saving model to model_init_2021-12-2811_28_45.676793\\model-00010-0.64579-0.78733-0.78680-0.71000.h5\n",
            "34/34 [==============================] - 302s 9s/step - loss: 0.6458 - categorical_accuracy: 0.7873 - val_loss: 0.7868 - val_categorical_accuracy: 0.7100 - lr: 1.0000e-04\n",
            "Epoch 11/16\n",
            "-----Batch1: size: 20\n",
            " 2/34 [>.............................] - ETA: 4:25 - loss: 0.7998 - categorical_accuracy: 0.7250-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            " 4/34 [==>...........................] - ETA: 4:12 - loss: 0.6669 - categorical_accuracy: 0.7750-----Batch4: size: 20\n",
            "-----Batch5: size: 20\n",
            " 5/34 [===>..........................] - ETA: 4:02 - loss: 0.6911 - categorical_accuracy: 0.7400-----Batch6: size: 20\n",
            " 6/34 [====>.........................] - ETA: 3:53 - loss: 0.6820 - categorical_accuracy: 0.7583-----Batch7: size: 20\n",
            " 7/34 [=====>........................] - ETA: 3:45 - loss: 0.6582 - categorical_accuracy: 0.7714-----Batch8: size: 20\n",
            " 9/34 [======>.......................] - ETA: 3:29 - loss: 0.6461 - categorical_accuracy: 0.7778-----Batch9: size: 20\n",
            "-----Batch10: size: 20\n",
            "11/34 [========>.....................] - ETA: 3:13 - loss: 0.6309 - categorical_accuracy: 0.7864-----Batch11: size: 20\n",
            "-----Batch12: size: 20\n",
            "12/34 [=========>....................] - ETA: 3:05 - loss: 0.6379 - categorical_accuracy: 0.7792-----Batch13: size: 20\n",
            "13/34 [==========>...................] - ETA: 2:56 - loss: 0.6518 - categorical_accuracy: 0.7692-----Batch14: size: 20\n",
            "15/34 [============>.................] - ETA: 2:39 - loss: 0.6428 - categorical_accuracy: 0.7733-----Batch15: size: 20\n",
            "-----Batch16: size: 20\n",
            "17/34 [==============>...............] - ETA: 2:22 - loss: 0.6376 - categorical_accuracy: 0.7794-----Batch17: size: 20\n",
            "-----Batch18: size: 20\n",
            "19/34 [===============>..............] - ETA: 2:05 - loss: 0.6521 - categorical_accuracy: 0.7711-----Batch19: size: 20\n",
            "-----Batch20: size: 20\n",
            "20/34 [================>.............] - ETA: 1:57 - loss: 0.6573 - categorical_accuracy: 0.7725-----Batch21: size: 20\n",
            "21/34 [=================>............] - ETA: 1:48 - loss: 0.6574 - categorical_accuracy: 0.7738-----Batch22: size: 20\n",
            "22/34 [==================>...........] - ETA: 1:40 - loss: 0.6445 - categorical_accuracy: 0.7818-----Batch23: size: 20\n",
            "23/34 [===================>..........] - ETA: 1:32 - loss: 0.6313 - categorical_accuracy: 0.7891-----Batch24: size: 20\n",
            "25/34 [=====================>........] - ETA: 1:15 - loss: 0.6299 - categorical_accuracy: 0.7900-----Batch25: size: 20\n",
            "26/34 [=====================>........] - ETA: 1:07 - loss: 0.6214 - categorical_accuracy: 0.7942-----Batch26: size: 20\n",
            "-----Batch27: size: 20\n",
            "27/34 [======================>.......] - ETA: 59s - loss: 0.6112 - categorical_accuracy: 0.8000 -----Batch28: size: 20\n",
            "29/34 [========================>.....] - ETA: 42s - loss: 0.6033 - categorical_accuracy: 0.8052-----Batch29: size: 20\n",
            "-----Batch30: size: 20\n",
            "31/34 [==========================>...] - ETA: 25s - loss: 0.6223 - categorical_accuracy: 0.7952-----Batch31: size: 20\n",
            "-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 16s - loss: 0.6197 - categorical_accuracy: 0.7969-----last Batch size: 3\n",
            "34/34 [==============================] - ETA: 0s - loss: 0.6168 - categorical_accuracy: 0.7994-----Batch0: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "\n",
            "Epoch 00011: saving model to model_init_2021-12-2811_28_45.676793\\model-00011-0.61682-0.79940-0.72875-0.73000.h5\n",
            "34/34 [==============================] - 304s 9s/step - loss: 0.6168 - categorical_accuracy: 0.7994 - val_loss: 0.7288 - val_categorical_accuracy: 0.7300 - lr: 1.0000e-04\n",
            "Epoch 12/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 4:33 - loss: 0.5730 - categorical_accuracy: 0.8000-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 4:35 - loss: 0.4516 - categorical_accuracy: 0.8750-----Batch3: size: 20\n",
            " 4/34 [==>...........................] - ETA: 4:19 - loss: 0.5113 - categorical_accuracy: 0.8500-----Batch4: size: 20\n",
            "-----Batch5: size: 20\n",
            " 5/34 [===>..........................] - ETA: 4:11 - loss: 0.5292 - categorical_accuracy: 0.8500-----Batch6: size: 20\n",
            " 6/34 [====>.........................] - ETA: 3:59 - loss: 0.6015 - categorical_accuracy: 0.8167-----Batch7: size: 20\n",
            " 8/34 [======>.......................] - ETA: 3:40 - loss: 0.5804 - categorical_accuracy: 0.8188-----Batch8: size: 20\n",
            "-----Batch9: size: 20\n",
            "10/34 [=======>......................] - ETA: 3:22 - loss: 0.5639 - categorical_accuracy: 0.8300-----Batch10: size: 20\n",
            "-----Batch11: size: 20\n",
            "12/34 [=========>....................] - ETA: 3:04 - loss: 0.5598 - categorical_accuracy: 0.8333-----Batch12: size: 20\n",
            "-----Batch13: size: 20\n",
            "14/34 [===========>..................] - ETA: 2:47 - loss: 0.5461 - categorical_accuracy: 0.8357-----Batch14: size: 20\n",
            "15/34 [============>.................] - ETA: 2:39 - loss: 0.5339 - categorical_accuracy: 0.8400-----Batch15: size: 20\n",
            "-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 2:31 - loss: 0.5401 - categorical_accuracy: 0.8313-----Batch17: size: 20\n",
            "17/34 [==============>...............] - ETA: 2:22 - loss: 0.5319 - categorical_accuracy: 0.8324-----Batch18: size: 20\n",
            "18/34 [==============>...............] - ETA: 2:14 - loss: 0.5437 - categorical_accuracy: 0.8222-----Batch19: size: 20\n",
            "20/34 [================>.............] - ETA: 1:57 - loss: 0.5546 - categorical_accuracy: 0.8100-----Batch20: size: 20\n",
            "-----Batch21: size: 20\n",
            "22/34 [==================>...........] - ETA: 1:40 - loss: 0.5622 - categorical_accuracy: 0.8045-----Batch22: size: 20\n",
            "-----Batch23: size: 20\n",
            "23/34 [===================>..........] - ETA: 1:32 - loss: 0.5648 - categorical_accuracy: 0.8043-----Batch24: size: 20\n",
            "24/34 [====================>.........] - ETA: 1:23 - loss: 0.5603 - categorical_accuracy: 0.8083-----Batch25: size: 20\n",
            "26/34 [=====================>........] - ETA: 1:06 - loss: 0.5737 - categorical_accuracy: 0.8000-----Batch26: size: 20\n",
            "-----Batch27: size: 20\n",
            "27/34 [======================>.......] - ETA: 58s - loss: 0.5690 - categorical_accuracy: 0.8037 -----Batch28: size: 20\n",
            "29/34 [========================>.....] - ETA: 41s - loss: 0.5622 - categorical_accuracy: 0.8086-----Batch29: size: 20\n",
            "30/34 [=========================>....] - ETA: 33s - loss: 0.5662 - categorical_accuracy: 0.8083-----Batch30: size: 20\n",
            "31/34 [==========================>...] - ETA: 25s - loss: 0.5642 - categorical_accuracy: 0.8097-----Batch31: size: 20\n",
            "32/34 [===========================>..] - ETA: 16s - loss: 0.5628 - categorical_accuracy: 0.8109-----Batch32: size: 20\n",
            "-----last Batch size: 3\n",
            "34/34 [==============================] - ETA: 0s - loss: 0.5582 - categorical_accuracy: 0.8115-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "\n",
            "Epoch 00012: saving model to model_init_2021-12-2811_28_45.676793\\model-00012-0.55822-0.81146-0.74894-0.75000.h5\n",
            "34/34 [==============================] - 307s 9s/step - loss: 0.5582 - categorical_accuracy: 0.8115 - val_loss: 0.7489 - val_categorical_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 13/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 4:31 - loss: 0.2366 - categorical_accuracy: 1.0000-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 4:20 - loss: 0.2704 - categorical_accuracy: 0.9500-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 4:14 - loss: 0.3962 - categorical_accuracy: 0.9000-----Batch4: size: 20\n",
            " 5/34 [===>..........................] - ETA: 4:05 - loss: 0.4847 - categorical_accuracy: 0.8400-----Batch5: size: 20\n",
            "-----Batch6: size: 20\n",
            " 6/34 [====>.........................] - ETA: 3:58 - loss: 0.4863 - categorical_accuracy: 0.8417-----Batch7: size: 20\n",
            " 8/34 [======>.......................] - ETA: 3:41 - loss: 0.4726 - categorical_accuracy: 0.8562-----Batch8: size: 20\n",
            " 9/34 [======>.......................] - ETA: 3:33 - loss: 0.4748 - categorical_accuracy: 0.8667-----Batch9: size: 20\n",
            "10/34 [=======>......................] - ETA: 3:25 - loss: 0.4764 - categorical_accuracy: 0.8650-----Batch10: size: 20\n",
            "11/34 [========>.....................] - ETA: 3:16 - loss: 0.4702 - categorical_accuracy: 0.8727-----Batch11: size: 20\n",
            "12/34 [=========>....................] - ETA: 3:07 - loss: 0.4684 - categorical_accuracy: 0.8750-----Batch12: size: 20\n",
            "13/34 [==========>...................] - ETA: 2:58 - loss: 0.4559 - categorical_accuracy: 0.8808-----Batch13: size: 20\n",
            "14/34 [===========>..................] - ETA: 2:50 - loss: 0.4547 - categorical_accuracy: 0.8786-----Batch14: size: 20\n",
            "15/34 [============>.................] - ETA: 2:42 - loss: 0.4515 - categorical_accuracy: 0.8767-----Batch15: size: 20\n",
            "-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 2:33 - loss: 0.4592 - categorical_accuracy: 0.8719-----Batch17: size: 20\n",
            "18/34 [==============>...............] - ETA: 2:15 - loss: 0.4689 - categorical_accuracy: 0.8583-----Batch18: size: 20\n",
            "-----Batch19: size: 20\n",
            "19/34 [===============>..............] - ETA: 2:07 - loss: 0.4669 - categorical_accuracy: 0.8579-----Batch20: size: 20\n",
            "21/34 [=================>............] - ETA: 1:50 - loss: 0.4664 - categorical_accuracy: 0.8548-----Batch21: size: 20\n",
            "22/34 [==================>...........] - ETA: 1:43 - loss: 0.4646 - categorical_accuracy: 0.8545-----Batch22: size: 20\n",
            "23/34 [===================>..........] - ETA: 1:34 - loss: 0.4612 - categorical_accuracy: 0.8587-----Batch23: size: 20\n",
            "-----Batch24: size: 20\n",
            "24/34 [====================>.........] - ETA: 1:26 - loss: 0.4556 - categorical_accuracy: 0.8625-----Batch25: size: 20\n",
            "26/34 [=====================>........] - ETA: 1:08 - loss: 0.4733 - categorical_accuracy: 0.8558-----Batch26: size: 20\n",
            "27/34 [======================>.......] - ETA: 59s - loss: 0.4774 - categorical_accuracy: 0.8556 -----Batch27: size: 20\n",
            "-----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 51s - loss: 0.4826 - categorical_accuracy: 0.8571-----Batch29: size: 20\n",
            "29/34 [========================>.....] - ETA: 42s - loss: 0.4873 - categorical_accuracy: 0.8569-----Batch30: size: 20\n",
            "30/34 [=========================>....] - ETA: 34s - loss: 0.4826 - categorical_accuracy: 0.8600-----Batch31: size: 20\n",
            "31/34 [==========================>...] - ETA: 25s - loss: 0.4779 - categorical_accuracy: 0.8613-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 17s - loss: 0.4749 - categorical_accuracy: 0.8641-----last Batch size: 3\n",
            "34/34 [==============================] - ETA: 0s - loss: 0.4680 - categorical_accuracy: 0.8673-----Batch0: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "\n",
            "Epoch 00013: saving model to model_init_2021-12-2811_28_45.676793\\model-00013-0.46795-0.86727-0.59259-0.79000.h5\n",
            "34/34 [==============================] - 305s 9s/step - loss: 0.4680 - categorical_accuracy: 0.8673 - val_loss: 0.5926 - val_categorical_accuracy: 0.7900 - lr: 1.0000e-04\n",
            "Epoch 14/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 4:41 - loss: 0.3093 - categorical_accuracy: 0.9500-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 4:28 - loss: 0.3763 - categorical_accuracy: 0.9000-----Batch3: size: 20\n",
            " 4/34 [==>...........................] - ETA: 4:10 - loss: 0.4820 - categorical_accuracy: 0.8625-----Batch4: size: 20\n",
            "-----Batch5: size: 20\n",
            " 5/34 [===>..........................] - ETA: 4:07 - loss: 0.4896 - categorical_accuracy: 0.8600-----Batch6: size: 20\n",
            " 7/34 [=====>........................] - ETA: 3:49 - loss: 0.4897 - categorical_accuracy: 0.8571-----Batch7: size: 20\n",
            " 8/34 [======>.......................] - ETA: 3:41 - loss: 0.5244 - categorical_accuracy: 0.8313-----Batch8: size: 20\n",
            "-----Batch9: size: 20\n",
            " 9/34 [======>.......................] - ETA: 3:32 - loss: 0.5123 - categorical_accuracy: 0.8333-----Batch10: size: 20\n",
            "10/34 [=======>......................] - ETA: 3:24 - loss: 0.4989 - categorical_accuracy: 0.8450-----Batch11: size: 20\n",
            "11/34 [========>.....................] - ETA: 3:14 - loss: 0.4847 - categorical_accuracy: 0.8545-----Batch12: size: 20\n",
            "13/34 [==========>...................] - ETA: 2:57 - loss: 0.4708 - categorical_accuracy: 0.8615-----Batch13: size: 20\n",
            "-----Batch14: size: 20\n",
            "14/34 [===========>..................] - ETA: 2:49 - loss: 0.4595 - categorical_accuracy: 0.8714-----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 2:40 - loss: 0.4536 - categorical_accuracy: 0.8733-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 2:31 - loss: 0.4641 - categorical_accuracy: 0.8687-----Batch17: size: 20\n",
            "18/34 [==============>...............] - ETA: 2:14 - loss: 0.4605 - categorical_accuracy: 0.8583-----Batch18: size: 20\n",
            "-----Batch19: size: 20\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19/34 [===============>..............] - ETA: 2:05 - loss: 0.4602 - categorical_accuracy: 0.8579-----Batch20: size: 20\n",
            "20/34 [================>.............] - ETA: 1:57 - loss: 0.4579 - categorical_accuracy: 0.8575-----Batch21: size: 20\n",
            "21/34 [=================>............] - ETA: 1:49 - loss: 0.4581 - categorical_accuracy: 0.8524-----Batch22: size: 20\n",
            "23/34 [===================>..........] - ETA: 1:32 - loss: 0.4556 - categorical_accuracy: 0.8522-----Batch23: size: 20\n",
            "24/34 [====================>.........] - ETA: 1:24 - loss: 0.4542 - categorical_accuracy: 0.8500-----Batch24: size: 20\n",
            "25/34 [=====================>........] - ETA: 1:15 - loss: 0.4494 - categorical_accuracy: 0.8500-----Batch25: size: 20\n",
            "26/34 [=====================>........] - ETA: 1:07 - loss: 0.4482 - categorical_accuracy: 0.8500-----Batch26: size: 20\n",
            "27/34 [======================>.......] - ETA: 59s - loss: 0.4424 - categorical_accuracy: 0.8537 -----Batch27: size: 20\n",
            "-----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 50s - loss: 0.4359 - categorical_accuracy: 0.8554-----Batch29: size: 20\n",
            "29/34 [========================>.....] - ETA: 42s - loss: 0.4376 - categorical_accuracy: 0.8586-----Batch30: size: 20\n",
            "30/34 [=========================>....] - ETA: 33s - loss: 0.4411 - categorical_accuracy: 0.8600-----Batch31: size: 20\n",
            "31/34 [==========================>...] - ETA: 25s - loss: 0.4466 - categorical_accuracy: 0.8565-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 16s - loss: 0.4401 - categorical_accuracy: 0.8594-----last Batch size: 3\n",
            "34/34 [==============================] - ETA: 0s - loss: 0.4328 - categorical_accuracy: 0.8612-----Batch0: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "\n",
            "Epoch 00014: saving model to model_init_2021-12-2811_28_45.676793\\model-00014-0.43285-0.86124-0.53546-0.82000.h5\n",
            "34/34 [==============================] - 303s 9s/step - loss: 0.4328 - categorical_accuracy: 0.8612 - val_loss: 0.5355 - val_categorical_accuracy: 0.8200 - lr: 1.0000e-04\n",
            "Epoch 15/16\n",
            "-----Batch1: size: 20\n",
            " 2/34 [>.............................] - ETA: 4:25 - loss: 0.4576 - categorical_accuracy: 0.9000-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 4:26 - loss: 0.4895 - categorical_accuracy: 0.8833-----Batch4: size: 20\n",
            " 5/34 [===>..........................] - ETA: 4:12 - loss: 0.4124 - categorical_accuracy: 0.8900-----Batch5: size: 20\n",
            " 6/34 [====>.........................] - ETA: 4:01 - loss: 0.4078 - categorical_accuracy: 0.8833-----Batch6: size: 20\n",
            "-----Batch7: size: 20\n",
            " 8/34 [======>.......................] - ETA: 3:44 - loss: 0.3996 - categorical_accuracy: 0.8938-----Batch8: size: 20\n",
            " 9/34 [======>.......................] - ETA: 3:36 - loss: 0.3914 - categorical_accuracy: 0.9000-----Batch9: size: 20\n",
            "10/34 [=======>......................] - ETA: 3:27 - loss: 0.4113 - categorical_accuracy: 0.8800-----Batch10: size: 20\n",
            "-----Batch11: size: 20\n",
            "11/34 [========>.....................] - ETA: 3:18 - loss: 0.4025 - categorical_accuracy: 0.8818-----Batch12: size: 20\n",
            "12/34 [=========>....................] - ETA: 3:08 - loss: 0.4279 - categorical_accuracy: 0.8750-----Batch13: size: 20\n",
            "13/34 [==========>...................] - ETA: 3:00 - loss: 0.4240 - categorical_accuracy: 0.8808-----Batch14: size: 20\n",
            "14/34 [===========>..................] - ETA: 2:51 - loss: 0.4294 - categorical_accuracy: 0.8821-----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 2:42 - loss: 0.4289 - categorical_accuracy: 0.8867-----Batch16: size: 20\n",
            "17/34 [==============>...............] - ETA: 2:24 - loss: 0.4206 - categorical_accuracy: 0.8824-----Batch17: size: 20\n",
            "-----Batch18: size: 20\n",
            "19/34 [===============>..............] - ETA: 2:07 - loss: 0.4112 - categorical_accuracy: 0.8842-----Batch19: size: 20\n",
            "-----Batch20: size: 20\n",
            "20/34 [================>.............] - ETA: 1:58 - loss: 0.4016 - categorical_accuracy: 0.8875-----Batch21: size: 20\n",
            "21/34 [=================>............] - ETA: 1:50 - loss: 0.3974 - categorical_accuracy: 0.8857-----Batch22: size: 20\n",
            "22/34 [==================>...........] - ETA: 1:41 - loss: 0.4029 - categorical_accuracy: 0.8818-----Batch23: size: 20\n",
            "24/34 [====================>.........] - ETA: 1:24 - loss: 0.3962 - categorical_accuracy: 0.8854-----Batch24: size: 20\n",
            "-----Batch25: size: 20\n",
            "25/34 [=====================>........] - ETA: 1:16 - loss: 0.3915 - categorical_accuracy: 0.8880-----Batch26: size: 20\n",
            "26/34 [=====================>........] - ETA: 1:07 - loss: 0.3907 - categorical_accuracy: 0.8904-----Batch27: size: 20\n",
            "28/34 [=======================>......] - ETA: 50s - loss: 0.3866 - categorical_accuracy: 0.8893-----Batch28: size: 20\n",
            "29/34 [========================>.....] - ETA: 42s - loss: 0.3846 - categorical_accuracy: 0.8897-----Batch29: size: 20\n",
            "-----Batch30: size: 20\n",
            "30/34 [=========================>....] - ETA: 33s - loss: 0.3908 - categorical_accuracy: 0.8867-----Batch31: size: 20\n",
            "32/34 [===========================>..] - ETA: 16s - loss: 0.3887 - categorical_accuracy: 0.8891-----Batch32: size: 20\n",
            "-----last Batch size: 3\n",
            "34/34 [==============================] - ETA: 0s - loss: 0.3866 - categorical_accuracy: 0.8914-----Batch0: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "\n",
            "Epoch 00015: saving model to model_init_2021-12-2811_28_45.676793\\model-00015-0.38664-0.89140-0.67555-0.71000.h5\n",
            "34/34 [==============================] - 307s 9s/step - loss: 0.3866 - categorical_accuracy: 0.8914 - val_loss: 0.6756 - val_categorical_accuracy: 0.7100 - lr: 1.0000e-04\n",
            "Epoch 16/16\n",
            "-----Batch1: size: 20\n",
            " 1/34 [..............................] - ETA: 5:20 - loss: 0.5935 - categorical_accuracy: 0.8500-----Batch2: size: 20\n",
            " 2/34 [>.............................] - ETA: 5:08 - loss: 0.4407 - categorical_accuracy: 0.8750-----Batch3: size: 20\n",
            " 3/34 [=>............................] - ETA: 4:45 - loss: 0.3773 - categorical_accuracy: 0.8833-----Batch4: size: 20\n",
            " 5/34 [===>..........................] - ETA: 4:18 - loss: 0.3166 - categorical_accuracy: 0.9100-----Batch5: size: 20\n",
            "-----Batch6: size: 20\n",
            " 7/34 [=====>........................] - ETA: 3:57 - loss: 0.3249 - categorical_accuracy: 0.9071-----Batch7: size: 20\n",
            " 8/34 [======>.......................] - ETA: 3:47 - loss: 0.3587 - categorical_accuracy: 0.8875-----Batch8: size: 20\n",
            "-----Batch9: size: 20\n",
            " 9/34 [======>.......................] - ETA: 3:39 - loss: 0.3616 - categorical_accuracy: 0.8889-----Batch10: size: 20\n",
            "11/34 [========>.....................] - ETA: 3:31 - loss: 0.3607 - categorical_accuracy: 0.8864-----Batch11: size: 20\n",
            "12/34 [=========>....................] - ETA: 3:23 - loss: 0.3634 - categorical_accuracy: 0.8875-----Batch12: size: 20\n",
            "13/34 [==========>...................] - ETA: 3:15 - loss: 0.3599 - categorical_accuracy: 0.8923-----Batch13: size: 20\n",
            "-----Batch14: size: 20\n",
            "14/34 [===========>..................] - ETA: 3:06 - loss: 0.3521 - categorical_accuracy: 0.8964-----Batch15: size: 20\n",
            "15/34 [============>.................] - ETA: 2:56 - loss: 0.3604 - categorical_accuracy: 0.8900-----Batch16: size: 20\n",
            "16/34 [=============>................] - ETA: 2:46 - loss: 0.3465 - categorical_accuracy: 0.8969-----Batch17: size: 20\n",
            "18/34 [==============>...............] - ETA: 2:25 - loss: 0.3439 - categorical_accuracy: 0.8972-----Batch18: size: 20\n",
            "19/34 [===============>..............] - ETA: 2:19 - loss: 0.3412 - categorical_accuracy: 0.8895-----Batch19: size: 20\n",
            "-----Batch20: size: 20\n",
            "21/34 [=================>............] - ETA: 2:00 - loss: 0.3409 - categorical_accuracy: 0.8905-----Batch21: size: 20\n",
            "-----Batch22: size: 20\n",
            "22/34 [==================>...........] - ETA: 1:50 - loss: 0.3623 - categorical_accuracy: 0.8886-----Batch23: size: 20\n",
            "23/34 [===================>..........] - ETA: 1:40 - loss: 0.3682 - categorical_accuracy: 0.8848-----Batch24: size: 20\n",
            "24/34 [====================>.........] - ETA: 1:31 - loss: 0.3681 - categorical_accuracy: 0.8854-----Batch25: size: 20\n",
            "25/34 [=====================>........] - ETA: 1:22 - loss: 0.3655 - categorical_accuracy: 0.8880-----Batch26: size: 20\n",
            "27/34 [======================>.......] - ETA: 1:03 - loss: 0.3624 - categorical_accuracy: 0.8907-----Batch27: size: 20\n",
            "-----Batch28: size: 20\n",
            "28/34 [=======================>......] - ETA: 54s - loss: 0.3633 - categorical_accuracy: 0.8911 -----Batch29: size: 20\n",
            "29/34 [========================>.....] - ETA: 45s - loss: 0.3674 - categorical_accuracy: 0.8897-----Batch30: size: 20\n",
            "30/34 [=========================>....] - ETA: 36s - loss: 0.3666 - categorical_accuracy: 0.8900-----Batch31: size: 20\n",
            "31/34 [==========================>...] - ETA: 27s - loss: 0.3708 - categorical_accuracy: 0.8903-----Batch32: size: 20\n",
            "32/34 [===========================>..] - ETA: 18s - loss: 0.3678 - categorical_accuracy: 0.8922-----last Batch size: 3\n",
            "34/34 [==============================] - ETA: 0s - loss: 0.3669 - categorical_accuracy: 0.8929-----Batch0: size: 20\n",
            "-----Batch0: size: 20\n",
            "-----Batch1: size: 20\n",
            "-----Batch2: size: 20\n",
            "-----Batch3: size: 20\n",
            "-----Batch4: size: 20\n",
            "-----Batch0: size: 20\n",
            "\n",
            "Epoch 00016: saving model to model_init_2021-12-2811_28_45.676793\\model-00016-0.36686-0.89291-0.64924-0.78000.h5\n",
            "34/34 [==============================] - 323s 9s/step - loss: 0.3669 - categorical_accuracy: 0.8929 - val_loss: 0.6492 - val_categorical_accuracy: 0.7800 - lr: 1.0000e-04\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x2e8ace76130>"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Training on complete dataset\n",
        "num_epochs = 16\n",
        "train_generator,val_generator,steps_per_epoch,validation_steps = sample_set(20,len(train_doc),(180,180))\n",
        "callbacks_list = save_model('categorical_accuracy')\n",
        "model = model_cnn_rnn_2()\n",
        "model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "                    callbacks=callbacks_list, validation_data=val_generator, \n",
        "                    validation_steps=validation_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otT_MLM5rcyU"
      },
      "source": [
        "At the end of all epochs, model has a train accuracy of 0.89 and val accuracy of 0.78, which is good, but we can observe overfitting. However at the end of epoch 14, train accuracy is 0.86 and test accuracy is 0.82. This is a decent result."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RESULTS TABULATED:"
      ],
      "metadata": {
        "id": "T1NOP-jQrpfu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from prettytable import PrettyTable"
      ],
      "metadata": {
        "id": "Z2M7K2-Qriff"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = PrettyTable()\n",
        "x.field_names = ['Model', 'Train Accuracy','Val Accuracy']\n",
        "x.add_row(['Model 1 - Conv3D with 180*180 image','0.97','0.85'])\n",
        "x.add_row(['Model 2 - Conv3D with 130*130 image','0.98','0.86'])\n",
        "x.add_row(['Model 3 - ResNet50 with last 10 layers trained','0.31 (Ablation)','0.31 (Ablation)'])\n",
        "x.add_row(['Model 4 - ResNet50 with last 20 layers trained','0.63','0.41'])\n",
        "\n",
        "x.add_row(['Model 5 - ResNet50 with all layers trained','Not trained fully since # of weights is large',''])\n",
        "x.add_row(['Model 6 - ResNet50 with last 10 layers trained','Not trained fully since 30 frames are used and training time is large',''])\n",
        "\n",
        "x.add_row(['Model 7 - ResNet with last 15 layers trained with image shape = 130x130','0.18','0.21'])\n",
        "x.add_row(['Model 8 - CNN (ResNet50) + RNN (LSTM)','0.21','0.18'])\n",
        "\n",
        "x.add_row(['Model 9 - CNN (VGG16 with all layers trained) + RNN (GRU) ','Model doesnt show proper progress in learning over the epochs for small dataset',''])\n",
        "x.add_row(['Model 10 - Customized CNN + RNN (GRU)','Model is not able to overfit on sample data.',''])\n",
        "x.add_row(['Model 11 - Customized CNN + RNN (GRU)','0.86 (Epoch 14)','0.82 (Epoch 14)'])\n",
        "\n",
        "\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQ2nFVfKrt_t",
        "outputId": "aafda36a-4785-4346-cfa1-be0c469a13ed"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------------------------+---------------------------------------------------------------------------------+-----------------+\n",
            "|                                  Model                                  |                                  Train Accuracy                                 |   Val Accuracy  |\n",
            "+-------------------------------------------------------------------------+---------------------------------------------------------------------------------+-----------------+\n",
            "|                   Model 1 - Conv3D with 180*180 image                   |                                       0.97                                      |       0.85      |\n",
            "|                   Model 2 - Conv3D with 130*130 image                   |                                       0.98                                      |       0.86      |\n",
            "|              Model 3 - ResNet50 with last 10 layers trained             |                                 0.31 (Ablation)                                 | 0.31 (Ablation) |\n",
            "|              Model 4 - ResNet50 with last 20 layers trained             |                                       0.63                                      |       0.41      |\n",
            "|                Model 5 - ResNet50 with all layers trained               |                  Not trained fully since # of weights is large                  |                 |\n",
            "|              Model 6 - ResNet50 with last 10 layers trained             |      Not trained fully since 30 frames are used and training time is large      |                 |\n",
            "| Model 7 - ResNet with last 15 layers trained with image shape = 130x130 |                                       0.18                                      |       0.21      |\n",
            "|                  Model 8 - CNN (ResNet50) + RNN (LSTM)                  |                                       0.21                                      |       0.18      |\n",
            "|        Model 9 - CNN (VGG16 with all layers trained) + RNN (GRU)        | Model doesnt show proper progress in learning over the epochs for small dataset |                 |\n",
            "|                  Model 10 - Customized CNN + RNN (GRU)                  |                   Model is not able to overfit on sample data.                  |                 |\n",
            "|                  Model 11 - Customized CNN + RNN (GRU)                  |                                 0.86 (Epoch 14)                                 | 0.82 (Epoch 14) |\n",
            "+-------------------------------------------------------------------------+---------------------------------------------------------------------------------+-----------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXYpEftrrcyU"
      },
      "source": [
        "#### Final Model to use:\n",
        "- Taking into consideration of the number of trainable parameters for each model and overfitting of the model, Model 11 (obtained at the end pf epoch 14) is the best one to use for the given scenario.\n",
        "##### Model Details:\n",
        "- Training accuracy: 0.86, Validation accuracy: 0.82\n",
        "- Training loss:0.43, validation loss: 0.53\n",
        "- Trainable parameters: 3,247,541\n",
        "- To use this model for prediction, apply the following preprocessing on the input image\n",
        "    - Take only the alternate frames from video. Total number of frames to use for would be 15 for a single video\n",
        "    - Resize the frames to a shape of (180,180,3)\n",
        "    - Normalize each channel of the frame (RGB) - divide by 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4K3WvDrrcyU"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Neural_Nets_Project_Starter_Code_v4.0.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "LFxyZEMOrcyH",
        "kkoSrKDPrcyJ",
        "FZxdoFyDrcyK",
        "36ejDxPJrcyL",
        "QhEdGaAGrcyN",
        "sqxgahKGrcyN",
        "m2_eiXQfrcyO",
        "31A2tnehrcyR",
        "dU4OpmS0rcyS"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}